{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t\t    miniconda.sh  quick_start_pytorch.ipynb   wandb\n",
      "eliciting-latent-sentiment  miniconda3\t  quick_start_pytorch_images\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/eliciting-latent-sentiment\n"
     ]
    }
   ],
   "source": [
    "%cd eliciting-latent-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
      "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-f0jvc1wa\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-f0jvc1wa\n",
      "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 5afe6fed827592dd525490b81e213bc3e2241a4a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata<6.0.0,>=5.1.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Collecting torch<3.0,>=2.0\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.9/dist-packages (from circuitsvis==0.0.0) (1.23.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.11.0)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.9.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.4.0)\n",
      "Collecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<3.0,>=2.0->circuitsvis==0.0.0) (66.1.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<3.0,>=2.0->circuitsvis==0.0.0) (0.35.1)\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.27.2-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: circuitsvis, lit\n",
      "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6170635 sha256=18416d046391a417a819352fdc50227fc53f6bd4b4a79fa57c3ef379f1518948\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gczzl722/wheels/94/79/66/781b85e0732736078188d905010db6471f2787826da308336a\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=bb80d63bbe992396624bb19e3a04fb358d41b0e0cd63dd0c42675500f54c0a15\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/a1/9c/f4e974f934c7a715a884a029e8b2b0b438486e654058fe8c80\n",
      "Successfully built circuitsvis lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, importlib-metadata, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, circuitsvis\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 2.0.1 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed circuitsvis-0.0.0 cmake-3.27.2 importlib-metadata-5.2.0 lit-16.0.6 mpmath-1.3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformer_lens\n",
      "  Downloading transformer_lens-1.6.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from transformer_lens) (1.5.0)\n",
      "Collecting einops>=0.6.0\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fancy-einsum>=0.0.3\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wandb>=0.13.5\n",
      "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.9/dist-packages (from transformer_lens) (2.0.1)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.9/dist-packages (from transformer_lens) (13.2.0)\n",
      "Collecting datasets>=2.7.1\n",
      "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxtyping>=0.2.11\n",
      "  Downloading jaxtyping-0.2.21-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from transformer_lens) (1.23.4)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from transformer_lens) (4.64.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (5.4.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (3.8.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (3.2.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.5.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (10.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (2.28.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (23.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (4.4.0)\n",
      "Collecting typeguard>=2.13.3\n",
      "  Downloading typeguard-4.1.3-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer_lens) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer_lens) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer_lens) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (3.1.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (3.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (2.14.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.7.4.91)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.7.101)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->transformer_lens) (2.0.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10->transformer_lens) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10->transformer_lens) (66.1.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.10->transformer_lens) (16.0.6)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.10->transformer_lens) (3.27.2)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer_lens) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer_lens) (0.12.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (3.19.6)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (1.14.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (5.9.4)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.30)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (18.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.10)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2019.11.28)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.13.3->jaxtyping>=0.2.11->transformer_lens) (5.2.0)\n",
      "Collecting typing-extensions>=3.7.4.1\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.13.3->jaxtyping>=0.2.11->transformer_lens) (3.11.0)\n",
      "Installing collected packages: safetensors, appdirs, typing-extensions, fancy-einsum, einops, beartype, typeguard, huggingface-hub, wandb, transformers, jaxtyping, datasets, transformer_lens\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 beartype-0.14.1 datasets-2.14.4 einops-0.6.1 fancy-einsum-0.0.3 huggingface-hub-0.16.4 jaxtyping-0.2.21 safetensors-0.3.3 transformer_lens-1.6.0 transformers-4.32.0 typeguard-4.1.3 typing-extensions-4.7.1 wandb-0.15.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting jaxtyping==0.2.13\n",
      "  Downloading jaxtyping-0.2.13-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (4.7.1)\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (4.1.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (1.23.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.13.3->jaxtyping==0.2.13) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.13.3->jaxtyping==0.2.13) (3.11.0)\n",
      "Installing collected packages: jaxtyping\n",
      "  Attempting uninstall: jaxtyping\n",
      "    Found existing installation: jaxtyping 0.2.21\n",
      "    Uninstalling jaxtyping-0.2.21:\n",
      "      Successfully uninstalled jaxtyping-0.2.21\n",
      "Successfully installed jaxtyping-0.2.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (0.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting protobuf==3.20.*\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting plotly\n",
      "  Downloading plotly-5.16.1-py2.py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.16.1 tenacity-8.2.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchtyping\n",
      "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from torchtyping) (2.0.1)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.9/dist-packages (from torchtyping) (4.1.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.7.101)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.4.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.10.3.66)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (3.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (11.7.4.91)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->torchtyping) (66.1.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->torchtyping) (0.35.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->torchtyping) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7.0->torchtyping) (16.0.6)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.11.1->torchtyping) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.11.1->torchtyping) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n",
      "Installing collected packages: torchtyping\n",
      "Successfully installed torchtyping-0.1.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/neelnanda-io/neel-plotly.git\n",
      "  Cloning https://github.com/neelnanda-io/neel-plotly.git to /tmp/pip-req-build-p5ugvflc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/neel-plotly.git /tmp/pip-req-build-p5ugvflc\n",
      "  Resolved https://github.com/neelnanda-io/neel-plotly.git to commit 6dc24b26f8dec991908479d7445dae496b3430b7\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (0.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (1.23.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (2.0.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (5.16.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (4.64.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neel-plotly==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neel-plotly==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly->neel-plotly==0.0.0) (23.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->neel-plotly==0.0.0) (8.2.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.7.99)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (4.7.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (3.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->neel-plotly==0.0.0) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->neel-plotly==0.0.0) (66.1.1)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->neel-plotly==0.0.0) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->neel-plotly==0.0.0) (16.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->neel-plotly==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->neel-plotly==0.0.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->neel-plotly==0.0.0) (1.3.0)\n",
      "Building wheels for collected packages: neel-plotly\n",
      "  Building wheel for neel-plotly (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neel-plotly: filename=neel_plotly-0.0.0-py3-none-any.whl size=10186 sha256=acbc7bbb92987f5b192f46778db2d8bc6b1f44592ec2f13b2ea9313341d9f62d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-82lm1cbf/wheels/e1/3c/c0/b5897c402b85e7fc329feb205ad5948b518f0423d891a79f7f\n",
      "Successfully built neel-plotly\n",
      "Installing collected packages: neel-plotly\n",
      "Successfully installed neel-plotly-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
    "!pip install transformer_lens\n",
    "!pip install jaxtyping==0.2.13\n",
    "!pip install einops\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install plotly\n",
    "!pip install torchtyping\n",
    "!pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
    "# !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
    "# %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "# %pip install typeguard==2.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from typing import Dict, Iterable, List, Tuple, Union\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import get_dataset, tokenize_and_concatenate, get_act_name, test_prompt\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from utils.store import load_array, save_html, save_array, is_file, get_model_name, clean_label, save_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32d3aa9e9b14b658691eecebe47f456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384ae6327be542b99eb9567beda7ffcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0836ec0588c04ab4b567be37e54a2b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f975978fe3a7435fb0c94685ceb4ed6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1d1398d3ac40698394e816af068aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\"\n",
    "MODEL_NAME = \"EleutherAI/pythia-2.8b\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    device=device,\n",
    ")\n",
    "model.name = MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839f820f59914e9abe887fd0e129e0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6efd612d1274520985abcfff8b334d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aebbf7b3a5f4ef88186ee629709638b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/951 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3151ba24071d475e82ef1b2f1269dfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/datasets/download/download_manager.py:527: FutureWarning: 'num_proc' was deprecated in version 2.6.2 and will be removed in 3.0.0. Pass `DownloadConfig(num_proc=<num_proc>)` to the initializer instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6038150f49404787841ba110afdd7a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a21ac2f30541868dadb29e86d0a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03b2a4d1f2d4975aadf9d9f60f85b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 24\n",
    "owt_data = load_dataset(\"stas/openwebtext-10k\", split=\"train\")\n",
    "owt_dataset = tokenize_and_concatenate(owt_data, model.tokenizer)\n",
    "owt_data_loader = DataLoader(\n",
    "    owt_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([    0,    34, 11338,  ...,   773,   688,   247])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owt_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to read the text file and create a DataFrame\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read lines and create a DataFrame\n",
    "        lines = file.readlines()\n",
    "        df = pd.DataFrame({'text': lines})\n",
    "        return df\n",
    "\n",
    "# Path to your text file\n",
    "file_path = 'hp.txt'\n",
    "\n",
    "# Read the text file into a DataFrame\n",
    "text_df = read_text_file(file_path)\n",
    "\n",
    "# Convert the DataFrame to a HuggingFace Dataset\n",
    "text_dataset = Dataset.from_pandas(text_df)\n",
    "\n",
    "# Concatenate all items in the 'text' column and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "def tokenize_and_concatenate2(dataset, tokenizer, max_length=1024, column_name='text', add_bos_token=True):\n",
    "    token_buffer = []\n",
    "    final_batches = []\n",
    "    \n",
    "    for batch in dataset:\n",
    "        text = batch[column_name]\n",
    "        if add_bos_token:\n",
    "            text = tokenizer.bos_token + text\n",
    "        tokenized_text = tokenizer(text, add_special_tokens=False)['input_ids']\n",
    "        eos_token_id = tokenizer.eos_token_id\n",
    "        tokenized_text.append(eos_token_id)\n",
    "        token_buffer.extend(tokenized_text)\n",
    "        \n",
    "        while len(token_buffer) >= max_length:\n",
    "            final_batch = token_buffer[:max_length]\n",
    "            token_buffer = token_buffer[max_length:]\n",
    "            final_batches.append(final_batch)\n",
    "    \n",
    "    # Handle any remaining tokens\n",
    "    if len(token_buffer) > 0:\n",
    "        final_batches.append(token_buffer)\n",
    "    \n",
    "    # Convert list of batches to tensors\n",
    "    final_batches = [torch.tensor(batch) for batch in final_batches]\n",
    "    \n",
    "    # Create a new dataset with specified features\n",
    "    features = Features({\"tokens\": Sequence(Value(\"int64\"))})\n",
    "    final_dataset = Dataset.from_dict({\"tokens\": final_batches}, features=features)\n",
    "\n",
    "    final_dataset.set_format(type=\"torch\", columns=[\"tokens\"])\n",
    "    \n",
    "    return final_dataset\n",
    "\n",
    "# # Example usage\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # Make sure the tokenizer has bos_token_id and eos_token_id\n",
    "# text_dataset = Dataset.from_dict({\"text\": [\"This is a sample text.\", \"Another sample text.\"]})  # Example dataset\n",
    "# tokenized_dataset = tokenize_and_concatenate2(text_dataset, tokenizer, max_length=1024)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Define the batch size\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "# Load a tokenizer (you'll need to specify the appropriate model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-2.8b\")\n",
    "# set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#dataset = text_dataset.map(lambda x: tokenize_and_concatenate(x, tokenizer))\n",
    "\n",
    "dataset = tokenize_and_concatenate2(text_dataset, tokenizer, max_length=1024, column_name='text')\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "train_data_loader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True\n",
    ")\n",
    "\n",
    "# Now, train_data_loader is ready to be used for training or analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens'],\n",
       "    num_rows: 6\n",
       "})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_positions(tensor, token_ids=[11, 13]):\n",
    "    positions = []\n",
    "    for batch_item in tensor:\n",
    "        token_positions = {token_id: [] for token_id in token_ids}\n",
    "        for position, token in enumerate(batch_item):\n",
    "            if token.item() in token_ids:\n",
    "                token_positions[token.item()].append(position)\n",
    "        positions.append([token_positions[token_id] for token_id in token_ids])\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_attention_pos_hook(\n",
    "    pattern: Float[Tensor, \"batch head seq_Q seq_K\"], hook: HookPoint,\n",
    "    pos_by_batch: List[List[int]], layer: int = 0, head_idx: int = 0,\n",
    ") -> Float[Tensor, \"batch head seq_Q seq_K\"]:\n",
    "    \"\"\"Zero-ablates an attention pattern tensor at a particular position\"\"\"\n",
    "    assert 'pattern' in hook.name\n",
    "\n",
    "    batch_size = pattern.shape[0]\n",
    "    assert len(pos_by_batch) == batch_size\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        for p in pos_by_batch[i]:\n",
    "            pattern[i, head_idx, p, p] = 0\n",
    "            \n",
    "    return pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def names_filter(name: str):\n",
    "    \"\"\"Filter for the names of the activations we want to keep to study the resid stream.\"\"\"\n",
    "    return name.endswith('resid_post') or name == get_act_name('resid_pre', 0)\n",
    "\n",
    "def get_layerwise_token_mean_activations(model: HookedTransformer, data_loader: DataLoader, token_id: int = 13) -> Float[Tensor, \"layer d_model\"]:\n",
    "    \"\"\"Get the mean value of a token across layers\"\"\"\n",
    "    num_layers = model.cfg.n_layers\n",
    "    d_model = model.cfg.d_model\n",
    "    \n",
    "    activation_sums = torch.stack([torch.zeros(d_model) for _ in range(num_layers)]).to(device)\n",
    "    comma_counts = [0] * num_layers\n",
    "\n",
    "    print(activation_sums.shape)\n",
    "\n",
    "    token_mean_values = torch.zeros((num_layers, d_model))\n",
    "    for _, batch_value in tqdm(enumerate(data_loader), total=100):\n",
    "        \n",
    "        batch_tokens = batch_value['tokens'].to(device)\n",
    "\n",
    "        # get positions of all 11 and 13 token ids in batch\n",
    "        punct_pos = find_positions(batch_tokens, token_ids=[13])\n",
    "\n",
    "        _, cache = model.run_with_cache(\n",
    "            batch_tokens, \n",
    "            names_filter=names_filter\n",
    "        )\n",
    "\n",
    "        \n",
    "        for i in range(batch_tokens.shape[0]):\n",
    "            for p in punct_pos[i][0]:\n",
    "                for layer in range(num_layers):\n",
    "                    activation_sums[layer] += cache[f\"blocks.{layer}.hook_resid_post\"][i, p, :]\n",
    "                    comma_counts[layer] += 1\n",
    "\n",
    "    for layer in range(num_layers):\n",
    "        token_mean_values[layer] = activation_sums[layer] / comma_counts[layer]\n",
    "\n",
    "    return token_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/curttigges/proj/eliciting-latent-sentiment/owt_comma_ablation.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/curttigges/proj/eliciting-latent-sentiment/owt_comma_ablation.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m comma_mean_values \u001b[39m=\u001b[39m get_layerwise_token_mean_activations(model, data_loader, token_id\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# comma_mean_values = get_layerwise_token_mean_activations(model, data_loader, token_id=13)\n",
    "# save_array(comma_mean_values, 'comma_mean_values.npy', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2560])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e569974aac840889c62c4cd4309e1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'data/pythia-2.8b/period_mean_values.npy'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_mean_values = get_layerwise_token_mean_activations(model, train_data_loader, token_id=15)\n",
    "save_array(period_mean_values, 'period_mean_values.npy', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "comma_mean_values = torch.from_numpy(load_array('comma_mean_values.npy', model)).to(device)\n",
    "period_mean_values = torch.from_numpy(load_array('period_mean_values.npy', model)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neuroscope(\n",
    "    tokens: Int[Tensor, \"batch pos\"], centred: bool = False, activations: Float[Tensor, \"pos layer 1\"] = None,\n",
    "    verbose=False,\n",
    "):\n",
    "    \n",
    "    str_tokens = model.to_str_tokens(tokens, prepend_bos=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Tokens shape: {tokens.shape}\")\n",
    "  \n",
    "    if centred:\n",
    "        if verbose:\n",
    "            print(\"Centering activations\")\n",
    "        layer_means = einops.reduce(activations, \"pos layer 1 -> 1 layer 1\", reduction=\"mean\")\n",
    "        layer_means = einops.repeat(layer_means, \"1 layer 1 -> pos layer 1\", pos=activations.shape[0])\n",
    "        activations -= layer_means\n",
    "    elif verbose:\n",
    "        print(\"Activations already centered\")\n",
    "    assert (\n",
    "        activations.ndim == 3\n",
    "    ), f\"activations must be of shape [tokens x layers x neurons], found {activations.shape}\"\n",
    "    assert len(str_tokens) == activations.shape[0], (\n",
    "        f\"tokens and activations must have the same length, found tokens={len(str_tokens)} and acts={activations.shape[0]}, \"\n",
    "        f\"tokens={str_tokens}, \"\n",
    "        f\"activations={activations.shape}\"\n",
    "\n",
    "    )\n",
    "    return text_neuron_activations(\n",
    "        tokens=str_tokens, \n",
    "        activations=activations,\n",
    "        first_dimension_name=\"Layer (resid_pre)\",\n",
    "        second_dimension_name=\"Model\",\n",
    "        second_dimension_labels=[\"pythia-2.8b\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def compute_modified_loss(model: HookedTransformer, data_loader: DataLoader) -> float:\n",
    "#     total_loss = 0\n",
    "#     loss_list = []\n",
    "#     for _, batch_value in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "#         batch_tokens = batch_value['tokens'].to(device)\n",
    "\n",
    "#         # get positions of all 11 and 13 token ids in batch\n",
    "#         punct_pos = find_positions(batch_tokens, token_ids=[13])\n",
    "\n",
    "#         # get the loss for each token in the batch\n",
    "#         initial_loss = model(batch_tokens, return_type=\"loss\", prepend_bos=False, loss_per_token=True)\n",
    "        \n",
    "#         # add hooks for the activations of the 11 and 13 tokens\n",
    "#         for layer, head in heads_to_ablate:\n",
    "#             ablate_punct = partial(zero_attention_pos_hook, pos_by_batch=punct_pos, layer=layer, head_idx=head)\n",
    "#             model.blocks[layer].attn.hook_pattern.add_hook(ablate_punct)\n",
    "\n",
    "#         # get the loss for each token when run with hooks\n",
    "#         hooked_loss = model(batch_tokens, return_type=\"loss\", prepend_bos=False, loss_per_token=True)\n",
    "\n",
    "#         # compute the percent difference between the two losses\n",
    "#         loss_diff = (hooked_loss - initial_loss) / initial_loss\n",
    "\n",
    "#         loss_list.append(loss_diff)\n",
    "\n",
    "#     model.reset_hooks()\n",
    "#     return loss_list, batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ablation import ablate_resid_with_precalc_mean\n",
    "\n",
    "heads_to_ablate = [(layer, head) for layer in range(model.cfg.n_layers) for head in range(model.cfg.n_heads)]\n",
    "\n",
    "def compute_mean_ablation_modified_loss(model: HookedTransformer, data_loader: DataLoader, cached_means, target_token_ids) -> float:\n",
    "    total_loss = 0\n",
    "    loss_diff_list = []\n",
    "    orig_loss_list = []\n",
    "    for _, batch_value in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        if isinstance(batch_value['tokens'], list):\n",
    "            batch_tokens = torch.stack(batch_value['tokens']).to(device)\n",
    "        else:\n",
    "            batch_tokens = batch_value['tokens'].to(device)\n",
    "\n",
    "        # get positions of all 11 and 13 token ids in batch\n",
    "        punct_pos = find_positions(batch_tokens, token_ids=target_token_ids)\n",
    "\n",
    "        # get the loss for each token in the batch\n",
    "        initial_loss = model(batch_tokens, return_type=\"loss\", prepend_bos=False, loss_per_token=True)\n",
    "        orig_loss_list.append(initial_loss)\n",
    "        \n",
    "        # add hooks for the activations of the 11 and 13 tokens\n",
    "        for layer, head in heads_to_ablate:\n",
    "            mean_ablate_comma = partial(ablate_resid_with_precalc_mean, cached_means=cached_means, pos_by_batch=punct_pos, layer=layer)\n",
    "            model.blocks[layer].hook_resid_post.add_hook(mean_ablate_comma)\n",
    "\n",
    "        # get the loss for each token when run with hooks\n",
    "        hooked_loss = model(batch_tokens, return_type=\"loss\", prepend_bos=False, loss_per_token=True)\n",
    "\n",
    "        # compute the percent difference between the two losses\n",
    "        loss_diff = hooked_loss - initial_loss\n",
    "        loss_diff_list.append(loss_diff)\n",
    "\n",
    "    model.reset_hooks()\n",
    "    return loss_diff_list, orig_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate random indices\n",
    "n = 5  # Size of the random subset\n",
    "total_size = len(dataset)\n",
    "random_indices = random.sample(range(total_size), n)\n",
    "\n",
    "# Get a random subset of the dataset of a given size\n",
    "subset_dataset = dataset.select(random_indices)\n",
    "\n",
    "# Create a new dataloader from the subset, converting the data to tensors\n",
    "subset_data_loader = DataLoader(\n",
    "    subset_dataset, batch_size=5, shuffle=False, drop_last=True\n",
    ")\n",
    "len(subset_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676680cf1db445df82c6a8e0b712fac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_change_by_token, orig_loss = compute_mean_ablation_modified_loss(model, subset_data_loader, period_mean_values, target_token_ids=[15])\n",
    "#loss_change_by_token, batch_tokens = compute_modified_loss(model, data_loader)\n",
    "#loss_change_by_token[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(loss_change_by_token)):\n",
    "    # add one column of zeros to the loss change tensor\n",
    "    loss_change_by_token[i] = torch.cat([torch.zeros(loss_change_by_token[i].shape[0], 1).to(device), loss_change_by_token[i]], dim=1)\n",
    "\n",
    "loss_change_by_token = torch.stack(loss_change_by_token).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1024])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_change_by_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_change_by_token_by_row = einops.rearrange(loss_change_by_token, \"batch item token -> (batch item) token\")\n",
    "loss_change_by_token_by_row = loss_change_by_token_by_row.unsqueeze(2)\n",
    "loss_change_by_token_by_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/pythia-2.8b/loss_change_by_token_by_row_hp.npy'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_array(loss_change_by_token_by_row, 'loss_change_by_token_by_row_hp.npy', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1707.5492)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_change_by_token_by_row.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most positive examples:\n",
      "Example:  Yet, Activation: 9.7396, Batch: 0, Pos: 857\n",
      "Example:  Behind, Activation: 9.5325, Batch: 1, Pos: 493\n",
      "Example:  Only, Activation: 9.5094, Batch: 3, Pos: 98\n",
      "Example:  Every, Activation: 9.4173, Batch: 2, Pos: 628\n",
      "Example:  Until, Activation: 8.9469, Batch: 0, Pos: 641\n",
      "Example:  Slow, Activation: 8.7174, Batch: 1, Pos: 826\n",
      "Example:  She, Activation: 8.5215, Batch: 2, Pos: 556\n",
      "Example:  It, Activation: 8.4041, Batch: 1, Pos: 553\n",
      "Example:  They, Activation: 8.2850, Batch: 1, Pos: 391\n",
      "Example:  Sometimes, Activation: 8.0269, Batch: 0, Pos: 718\n",
      "Example:  They, Activation: 7.9306, Batch: 1, Pos: 878\n",
      "Example:  Then, Activation: 7.8307, Batch: 1, Pos: 866\n",
      "Example:  He, Activation: 7.4419, Batch: 3, Pos: 779\n",
      "Example:  He, Activation: 7.3941, Batch: 4, Pos: 264\n",
      "Example:  It, Activation: 7.3786, Batch: 3, Pos: 338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-6923652c-e77a\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-6923652c-e77a\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \" of\", \" some\", \" unknown\", \" relation\", \" coming\", \" to\", \" take\", \" him\", \" away\", \",\", \" but\", \" it\", \" had\", \" never\", \" happened\", \";\", \" the\", \" D\", \"urs\", \"leys\", \" were\", \" his\", \" only\", \" family\", \".\", \" Yet\", \" sometimes\", \" he\", \" thought\", \" (\", \"or\", \" maybe\", \" hoped\", \")\", \" that\", \" strangers\", \" in\", \" the\", \" street\", \" seemed\", \" to\", \" know\", \" him\", \".\", \" Very\", \" strange\", \" strangers\", \" they\", \" were\", \",\", \"\\n\", \" lunch\", \" they\", \" went\", \" to\", \" the\", \" rept\", \"ile\", \" house\", \".\", \" It\", \" was\", \" cool\", \" and\", \" dark\", \" in\", \" there\", \",\", \" with\", \" lit\", \" windows\", \" all\", \" along\", \" the\", \" walls\", \".\", \" Behind\", \" the\", \" glass\", \",\", \" all\", \" sorts\", \" of\", \" l\", \"izards\", \" and\", \" snakes\", \" were\", \" crawling\", \" and\", \" sl\", \"ither\", \"ing\", \" over\", \" bits\", \" of\", \" wood\", \" and\", \" stone\", \".\", \" Dud\", \"\\n\", \" as\", \" it\", \" had\", \" been\", \" on\", \" the\", \" night\", \" when\", \" Mr\", \".\", \" D\", \"urs\", \"ley\", \" had\", \" seen\", \" that\", \" fate\", \"ful\", \" news\", \" report\", \" about\", \" the\", \" ow\", \"ls\", \".\", \" Only\", \" the\", \" photographs\", \" on\", \" the\", \" mant\", \"el\", \"piece\", \" really\", \" showed\", \" how\", \" much\", \" time\", \" had\", \" passed\", \".\", \" Ten\", \" years\", \" ago\", \",\", \" there\", \" had\", \" been\", \" lots\", \" of\", \"\\n\", \" his\", \" parents\", \" took\", \" him\", \" and\", \" a\", \" friend\", \" out\", \" for\", \" the\", \" day\", \",\", \" to\", \" adventure\", \" parks\", \",\", \" h\", \"amb\", \"urger\", \" restaurants\", \",\", \" or\", \" the\", \" movies\", \".\", \" Every\", \" year\", \",\", \" Harry\", \" was\", \" left\", \" behind\", \" with\", \" Mrs\", \".\", \" Fig\", \"g\", \",\", \" a\", \" mad\", \" old\", \" lady\", \" who\", \" lived\", \" two\", \" streets\", \" away\", \".\", \" Harry\", \" hated\", \"\\n\", \" a\", \" watch\", \".\", \" He\", \" didn\", \"'t\", \" know\", \" what\", \" time\", \" it\", \" was\", \" and\", \" he\", \" couldn\", \"'t\", \" be\", \" sure\", \" the\", \" D\", \"urs\", \"leys\", \" were\", \" asleep\", \" yet\", \".\", \" Until\", \" they\", \" were\", \",\", \" he\", \" couldn\", \"'t\", \" risk\", \" sne\", \"aking\", \" to\", \" the\", \" kitchen\", \" for\", \" some\", \" food\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"He\", \"'d\", \"\\n\", \" he\", \" got\", \" to\", \" visit\", \" the\", \" rest\", \" of\", \" the\", \" house\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"The\", \" snake\", \" suddenly\", \" opened\", \" its\", \" be\", \"ady\", \" eyes\", \".\", \" Slow\", \"ly\", \",\", \" very\", \" slowly\", \",\", \" it\", \" raised\", \" its\", \" head\", \" until\", \" its\", \" eyes\", \" were\", \" on\", \" a\", \" level\", \" with\", \" Harry\", \"'s\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"\\n\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"Bad\", \" news\", \",\", \" Vernon\", \",\\\"\", \" she\", \" said\", \".\", \" \\\"\", \"Mrs\", \".\", \" Fig\", \"g\", \"'s\", \" broken\", \" her\", \" leg\", \".\", \" She\", \" can\", \"'t\", \" take\", \" him\", \".\\\"\", \" She\", \" jerked\", \" her\", \" head\", \" in\", \" Harry\", \"'s\", \" direction\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"D\", \"ud\", \"ley\", \"'s\", \"\\n\", \"ous\", \" cob\", \"ras\", \" and\", \" thick\", \",\", \" man\", \"-\", \"cr\", \"ushing\", \" py\", \"th\", \"ons\", \".\", \" Dud\", \"ley\", \" quickly\", \" found\", \" the\", \" largest\", \" snake\", \" in\", \" the\", \" place\", \".\", \" It\", \" could\", \" have\", \" wrapped\", \" its\", \" body\", \" twice\", \" around\", \" Uncle\", \" Vernon\", \"'s\", \" car\", \" and\", \" crushed\", \" it\", \" into\", \" a\", \" trash\", \" can\", \" -\", \" but\", \" at\", \" the\", \" moment\", \" it\", \"\\n\", \" who\", \" were\", \" starting\", \" to\", \" get\", \" bored\", \" with\", \" the\", \" animals\", \" by\", \" lunch\", \"time\", \",\", \" wouldn\", \"'t\", \" fall\", \" back\", \" on\", \" their\", \" favorite\", \" hobby\", \" of\", \" hitting\", \" him\", \".\", \" They\", \" ate\", \" in\", \" the\", \" zoo\", \" restaurant\", \",\", \" and\", \" when\", \" Dud\", \"ley\", \" had\", \" a\", \" tant\", \"rum\", \" because\", \" his\", \" kn\", \"icker\", \"b\", \"ocker\", \" glory\", \" didn\", \"'t\", \" have\", \"\\n\", \" baby\", \" and\", \" his\", \" parents\", \" had\", \" died\", \" in\", \" that\", \" car\", \" crash\", \".\", \" He\", \" couldn\", \"'t\", \" remember\", \" being\", \" in\", \" the\", \" car\", \" when\", \" his\", \" parents\", \" had\", \" died\", \".\", \" Sometimes\", \",\", \" when\", \" he\", \" strained\", \" his\", \" memory\", \" during\", \" long\", \" hours\", \" in\", \" his\", \" cup\", \"board\", \",\", \" he\", \" came\", \" up\", \" with\", \" a\", \" strange\", \" vision\", \":\", \" a\", \" blinding\", \"\\n\", \"It\", \" wink\", \"ed\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"Harry\", \" stared\", \".\", \" Then\", \" he\", \" looked\", \" quickly\", \" around\", \" to\", \" see\", \" if\", \" anyone\", \" was\", \" watching\", \".\", \" They\", \" weren\", \"'t\", \".\", \" He\", \" looked\", \" back\", \" at\", \" the\", \" snake\", \" and\", \" wink\", \"ed\", \",\", \" too\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"The\", \" snake\", \" jerked\", \"\\n\", \" a\", \" level\", \" with\", \" Harry\", \"'s\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"It\", \" wink\", \"ed\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"Harry\", \" stared\", \".\", \" Then\", \" he\", \" looked\", \" quickly\", \" around\", \" to\", \" see\", \" if\", \" anyone\", \" was\", \" watching\", \".\", \" They\", \" weren\", \"'t\", \".\", \" He\", \" looked\", \" back\", \" at\", \" the\", \" snake\", \" and\", \" wink\", \"ed\", \"\\n\", \" times\", \" bigger\", \" than\", \" he\", \" was\", \".\", \" Harry\", \" had\", \" a\", \" thin\", \" face\", \",\", \" kn\", \"obb\", \"ly\", \" knees\", \",\", \" black\", \" hair\", \",\", \" and\", \" bright\", \" green\", \" eyes\", \".\", \" He\", \" wore\", \" round\", \" glasses\", \" held\", \" together\", \" with\", \" a\", \" lot\", \" of\", \" Scot\", \"ch\", \" tape\", \" because\", \" of\", \" all\", \" the\", \" times\", \" Dud\", \"ley\", \" had\", \" punched\", \" him\", \" on\", \" the\", \"\\n\", \" Pol\", \"k\", \"iss\", \",\", \" walked\", \" in\", \" with\", \" his\", \" mother\", \".\", \" P\", \"iers\", \" was\", \" a\", \" scra\", \"wn\", \"y\", \" boy\", \" with\", \" a\", \" face\", \" like\", \" a\", \" rat\", \".\", \" He\", \" was\", \" usually\", \" the\", \" one\", \" who\", \" held\", \" people\", \"'s\", \" arms\", \" behind\", \" their\", \" backs\", \" while\", \" Dud\", \"ley\", \" hit\", \" them\", \".\", \" Dud\", \"ley\", \" stopped\", \" pretending\", \" to\", \" cry\", \"\\n\", \" the\", \" frying\", \" pan\", \" being\", \" put\", \" on\", \" the\", \" stove\", \".\", \" He\", \" rolled\", \" onto\", \" his\", \" back\", \" and\", \" tried\", \" to\", \" remember\", \" the\", \" dream\", \" he\", \" had\", \" been\", \" having\", \".\", \" It\", \" had\", \" been\", \" a\", \" good\", \" one\", \".\", \" There\", \" had\", \" been\", \" a\", \" flying\", \" motorcycle\", \" in\", \" it\", \".\", \" He\", \" had\", \" a\", \" funny\", \" feeling\", \" he\", \"'d\", \" had\", \" the\", \"\\n\"], \"activations\": [[[0.0]], [[0.6065038442611694]], [[-0.3540678024291992]], [[-0.7874951362609863]], [[-0.44657039642333984]], [[0.9738388061523438]], [[0.281122088432312]], [[0.10076475143432617]], [[0.513599693775177]], [[0.24172747135162354]], [[-0.10005474090576172]], [[-0.42099475860595703]], [[0.07160687446594238]], [[0.36273086071014404]], [[0.019942641258239746]], [[0.5199325084686279]], [[-0.6017961502075195]], [[0.21389102935791016]], [[0.19513511657714844]], [[0.19296887516975403]], [[-0.001191258430480957]], [[0.01895880699157715]], [[-0.06099343299865723]], [[-0.5924580097198486]], [[0.320197731256485]], [[-0.04311692714691162]], [[9.739568710327148]], [[-0.6770315170288086]], [[0.4420872926712036]], [[0.5792863368988037]], [[-0.7754693031311035]], [[0.4246373176574707]], [[0.00796651840209961]], [[-0.25174832344055176]], [[0.031051114201545715]], [[0.2532377243041992]], [[0.22853755950927734]], [[-0.3672676086425781]], [[0.1459282636642456]], [[0.5169317722320557]], [[0.16890382766723633]], [[0.5643644332885742]], [[0.7347269058227539]], [[0.04934656620025635]], [[0.24831604957580566]], [[5.579728603363037]], [[-0.22871661186218262]], [[0.04160737991333008]], [[-0.13210821151733398]], [[0.1332753300666809]], [[0.03287184238433838]], [[0.0]], [[0.21659374237060547]], [[0.575800895690918]], [[0.1344606876373291]], [[0.20203733444213867]], [[0.14977842569351196]], [[-0.3053112030029297]], [[0.021752946078777313]], [[0.6240993142127991]], [[0.18618130683898926]], [[6.296778678894043]], [[0.7821503281593323]], [[-0.08511686325073242]], [[0.03508484363555908]], [[0.7065820693969727]], [[0.25332796573638916]], [[0.4590868055820465]], [[-0.14454853534698486]], [[0.9631869792938232]], [[-0.664642333984375]], [[0.125929594039917]], [[-0.38352394104003906]], [[0.038010358810424805]], [[-0.036840587854385376]], [[0.17074060440063477]], [[0.1733723282814026]], [[9.532493591308594]], [[0.0500035285949707]], [[0.7259806394577026]], [[0.005700469017028809]], [[0.3792297840118408]], [[-0.6517384052276611]], [[0.019707761704921722]], [[0.18578052520751953]], [[0.2962505519390106]], [[-0.29698050022125244]], [[0.040225088596343994]], [[0.5487256646156311]], [[-0.16505050659179688]], [[-0.01830601692199707]], [[0.13190579414367676]], [[0.0017971438355743885]], [[0.006353048142045736]], [[0.4555501937866211]], [[0.44745349884033203]], [[0.052286870777606964]], [[0.43909239768981934]], [[0.16428077220916748]], [[-0.41284656524658203]], [[0.45802080631256104]], [[-0.2976951599121094]], [[0.0]], [[0.18931689858436584]], [[0.2871571481227875]], [[0.18664388358592987]], [[0.013163596391677856]], [[0.4774458408355713]], [[0.011643290519714355]], [[-0.18891990184783936]], [[0.04129457473754883]], [[0.05411338806152344]], [[0.07429739832878113]], [[5.373836517333984]], [[2.1575522422790527]], [[0.15674728155136108]], [[1.3265019655227661]], [[0.9745292663574219]], [[-0.2330760955810547]], [[3.01059627532959]], [[0.18063166737556458]], [[1.5893421173095703]], [[1.3308179378509521]], [[1.2898446321487427]], [[-0.14217036962509155]], [[-1.3821649551391602]], [[0.5873992443084717]], [[1.197120189666748]], [[9.50936508178711]], [[1.4659852981567383]], [[4.262355804443359]], [[1.9955004453659058]], [[0.2800448536872864]], [[1.528871774673462]], [[0.020231373608112335]], [[0.3070017695426941]], [[-2.740605354309082]], [[-0.7094111442565918]], [[0.34508562088012695]], [[1.4754772186279297]], [[3.368595600128174]], [[0.7640029788017273]], [[0.021615803241729736]], [[0.4908527135848999]], [[4.430600166320801]], [[1.1041932106018066]], [[0.13908684253692627]], [[0.08553960919380188]], [[1.9608969688415527]], [[0.7624764442443848]], [[0.1002662405371666]], [[-0.34642505645751953]], [[0.14160555601119995]], [[0.0]], [[0.8917598724365234]], [[0.558725118637085]], [[0.6513547897338867]], [[0.2253214716911316]], [[-0.5948796272277832]], [[0.09343957901000977]], [[0.22092247009277344]], [[-0.14226460456848145]], [[0.16704237461090088]], [[0.37904882431030273]], [[0.1425132155418396]], [[-0.5887501239776611]], [[0.48028814792633057]], [[-0.35653209686279297]], [[-0.8112030029296875]], [[-0.22149604558944702]], [[-0.26580333709716797]], [[-0.958045482635498]], [[0.9603570103645325]], [[0.3108396530151367]], [[0.0034391582012176514]], [[0.2582869529724121]], [[0.20322036743164062]], [[0.6442966461181641]], [[0.3038945198059082]], [[9.41734504699707]], [[0.15375395119190216]], [[1.1491459608078003]], [[0.15440189838409424]], [[0.6546521186828613]], [[0.0440363883972168]], [[0.5723458528518677]], [[0.4677248001098633]], [[0.24255037307739258]], [[0.09068300575017929]], [[13.510904312133789]], [[0.07433854043483734]], [[1.0343146324157715]], [[0.49048614501953125]], [[-0.3647589683532715]], [[0.4367375373840332]], [[0.19857919216156006]], [[0.4247938394546509]], [[0.29671525955200195]], [[0.3563222885131836]], [[-0.08108043670654297]], [[-0.19473659992218018]], [[0.31384748220443726]], [[3.097747802734375]], [[3.62943434715271]], [[0.0]], [[-0.027747154235839844]], [[0.653569221496582]], [[0.14792728424072266]], [[6.861716270446777]], [[0.6565437316894531]], [[0.24420340359210968]], [[-0.03218698501586914]], [[0.3544658422470093]], [[0.1000479906797409]], [[0.05527189373970032]], [[0.058103062212467194]], [[0.18318462371826172]], [[0.4284358024597168]], [[0.35580992698669434]], [[0.018516918644309044]], [[0.07552337646484375]], [[0.7405380010604858]], [[-0.16096997261047363]], [[-0.0568695068359375]], [[0.024583633989095688]], [[0.04148298501968384]], [[0.06982874870300293]], [[0.09568405151367188]], [[-0.12549161911010742]], [[0.35415443778038025]], [[8.94693660736084]], [[1.1942329406738281]], [[0.506321907043457]], [[0.038626015186309814]], [[2.4930238723754883]], [[1.4390528202056885]], [[0.020464520901441574]], [[1.2468698024749756]], [[-0.2896289825439453]], [[0.014048806391656399]], [[-0.4668240547180176]], [[0.08837798237800598]], [[0.6078240871429443]], [[0.4265139102935791]], [[-0.17645025253295898]], [[0.6229579448699951]], [[0.8839052319526672]], [[3.9858145713806152]], [[-4.544074058532715]], [[-0.4287128448486328]], [[0.055588483810424805]], [[-0.4282236099243164]], [[-0.37720298767089844]], [[0.25148773193359375]], [[0.49175214767456055]], [[0.0]], [[0.7897319793701172]], [[0.028320789337158203]], [[0.22745341062545776]], [[-0.303469181060791]], [[0.21682274341583252]], [[0.21683311462402344]], [[0.28437790274620056]], [[0.05925224721431732]], [[0.7940754890441895]], [[0.3289414644241333]], [[4.392209053039551]], [[-5.57882833480835]], [[-0.48516273498535156]], [[0.10686612129211426]], [[-0.6215720176696777]], [[-0.5086879730224609]], [[0.171220064163208]], [[0.26555919647216797]], [[2.258021354675293]], [[0.44880008697509766]], [[0.06719449162483215]], [[-0.3488931655883789]], [[1.317780613899231]], [[0.30879104137420654]], [[0.266430139541626]], [[8.717397689819336]], [[0.263871967792511]], [[0.7176071405410767]], [[-0.3174145221710205]], [[0.170872300863266]], [[0.025181666016578674]], [[0.7557093501091003]], [[0.7287629842758179]], [[0.19326359033584595]], [[0.26074567437171936]], [[0.3939962387084961]], [[0.466017484664917]], [[-0.1711418628692627]], [[0.20890849828720093]], [[-0.2536306381225586]], [[0.810484766960144]], [[0.16339990496635437]], [[0.044417642056941986]], [[-0.6533951759338379]], [[0.859836757183075]], [[0.499225378036499]], [[3.192890167236328]], [[-3.1310949325561523]], [[-0.4461393356323242]], [[0.03757357597351074]], [[0.0]], [[4.71002197265625]], [[-4.9480767250061035]], [[-0.3622398376464844]], [[0.027478694915771484]], [[-0.3852839469909668]], [[-0.34076690673828125]], [[-0.07448863983154297]], [[0.5664377212524414]], [[0.48306798934936523]], [[-0.0447918176651001]], [[1.1502656936645508]], [[0.3577711582183838]], [[0.4223489761352539]], [[0.2168048918247223]], [[0.13448375463485718]], [[5.025206565856934]], [[0.3481407165527344]], [[0.050085313618183136]], [[6.3749260902404785]], [[0.5471625328063965]], [[0.6491718292236328]], [[0.415895938873291]], [[0.6604598760604858]], [[-0.1765282154083252]], [[0.056009650230407715]], [[8.521463394165039]], [[0.642683744430542]], [[0.20644941926002502]], [[0.8154778480529785]], [[0.2824110984802246]], [[0.47725653648376465]], [[-0.918705940246582]], [[1.5593156814575195]], [[0.335138738155365]], [[0.3807300627231598]], [[0.1930384635925293]], [[0.5371336936950684]], [[0.3856477439403534]], [[0.15051165223121643]], [[0.3143885135650635]], [[3.0977120399475098]], [[-2.939021110534668]], [[-0.3332023620605469]], [[0.05306744575500488]], [[-0.2711939811706543]], [[-0.3318939208984375]], [[0.10719919204711914]], [[0.1067800521850586]], [[0.6827609539031982]], [[0.012242317199707031]], [[0.0]], [[0.00569535419344902]], [[0.22393369674682617]], [[0.6619431376457214]], [[-0.09047484397888184]], [[0.7564201354980469]], [[-0.29551005363464355]], [[0.4850797653198242]], [[0.39544299244880676]], [[-0.93695068359375]], [[0.37429773807525635]], [[0.4117405414581299]], [[0.023788271471858025]], [[0.0011012186296284199]], [[0.38926053047180176]], [[5.302743434906006]], [[0.015520462766289711]], [[0.2854776382446289]], [[1.1873669624328613]], [[1.1698405742645264]], [[0.9442782402038574]], [[-0.29491376876831055]], [[-0.3687417507171631]], [[0.14775504171848297]], [[0.8242685794830322]], [[0.08136439323425293]], [[8.404088020324707]], [[-1.296658992767334]], [[0.5546036958694458]], [[0.7978630065917969]], [[-0.19692182540893555]], [[0.5311440825462341]], [[-0.3263559341430664]], [[0.23997676372528076]], [[1.724013328552246]], [[-1.0286206007003784]], [[0.15265387296676636]], [[-0.2747917175292969]], [[0.4372936487197876]], [[-0.30631065368652344]], [[0.09097863733768463]], [[-0.10127472877502441]], [[0.33202916383743286]], [[-0.009909629821777344]], [[0.18602734804153442]], [[-0.5610561370849609]], [[0.39743709564208984]], [[0.4629940986633301]], [[0.5592578649520874]], [[0.492651104927063]], [[1.3331167697906494]], [[0.0]], [[0.40361714363098145]], [[0.34604567289352417]], [[0.08601665496826172]], [[0.09298041462898254]], [[0.09800684452056885]], [[0.33626842498779297]], [[0.01249074935913086]], [[0.0026111602783203125]], [[-0.12918758392333984]], [[-0.0032873153686523438]], [[-0.11819982528686523]], [[0.24870583415031433]], [[0.05018176883459091]], [[0.5771397948265076]], [[0.17537036538124084]], [[0.09508800506591797]], [[0.044873714447021484]], [[0.2444627285003662]], [[0.26071810722351074]], [[-0.7740235328674316]], [[-0.3718099594116211]], [[0.11400240659713745]], [[0.5451030731201172]], [[1.6645660400390625]], [[0.18880391120910645]], [[8.284965515136719]], [[-1.9974145889282227]], [[0.03048086166381836]], [[0.16837704181671143]], [[0.47397518157958984]], [[-1.0588953495025635]], [[0.22381865978240967]], [[0.20940613746643066]], [[0.4282810688018799]], [[0.3466329574584961]], [[0.004235051106661558]], [[0.5351247787475586]], [[-0.22713208198547363]], [[0.048201560974121094]], [[0.0026832539588212967]], [[0.8378324508666992]], [[-0.05762600898742676]], [[-0.2421131134033203]], [[0.9085128307342529]], [[0.7112301588058472]], [[0.6751458644866943]], [[0.6641457080841064]], [[1.014854907989502]], [[0.18966035544872284]], [[0.12308907508850098]], [[0.0]], [[0.48633790016174316]], [[0.09528493881225586]], [[-0.38563084602355957]], [[0.22561246156692505]], [[0.23881585896015167]], [[0.18122100830078125]], [[-0.16774123907089233]], [[0.1183023452758789]], [[0.861137866973877]], [[0.10606318712234497]], [[0.4123302698135376]], [[7.134771347045898]], [[1.0791356563568115]], [[0.10684845596551895]], [[0.3373839855194092]], [[-0.01964569091796875]], [[-0.16258621215820312]], [[0.2156085968017578]], [[0.09998703002929688]], [[-0.27166056632995605]], [[-0.23062705993652344]], [[0.42756837606430054]], [[-0.03399956226348877]], [[0.15014126896858215]], [[-0.38087522983551025]], [[8.026931762695312]], [[0.2072674036026001]], [[-0.38021421432495117]], [[0.17006170749664307]], [[0.23985576629638672]], [[-0.002629399299621582]], [[1.6636078357696533]], [[0.3495364189147949]], [[0.5725255012512207]], [[-0.2703227996826172]], [[0.42054080963134766]], [[-0.038884878158569336]], [[0.5180954933166504]], [[0.0023548640310764313]], [[0.4415244460105896]], [[0.5631704330444336]], [[-0.11358499526977539]], [[0.5304150581359863]], [[0.13303136825561523]], [[-0.03681313991546631]], [[-0.22826910018920898]], [[0.15736627578735352]], [[0.04604315757751465]], [[0.3707371950149536]], [[0.4703989028930664]], [[0.0]], [[0.28710269927978516]], [[-0.15997695922851562]], [[0.32933294773101807]], [[0.08567523956298828]], [[3.983084201812744]], [[1.706916332244873]], [[-0.47963619232177734]], [[-0.004657268524169922]], [[-0.6139841079711914]], [[-0.4940528869628906]], [[0.02175426483154297]], [[0.5124750137329102]], [[0.48239898681640625]], [[7.830748558044434]], [[1.7762694358825684]], [[0.723395586013794]], [[1.000755786895752]], [[-0.07819843292236328]], [[0.15584349632263184]], [[0.2738947868347168]], [[-0.0003954172134399414]], [[0.4618641138076782]], [[-0.08554291725158691]], [[0.3472723960876465]], [[0.3261692523956299]], [[7.930635452270508]], [[2.3565564155578613]], [[0.10835753381252289]], [[0.7538085579872131]], [[6.9970011711120605]], [[1.0115172863006592]], [[0.5502581596374512]], [[0.34486091136932373]], [[0.6333404779434204]], [[0.372572660446167]], [[0.2590353488922119]], [[-1.9007236957550049]], [[0.014082259498536587]], [[-1.0146360397338867]], [[3.6720824241638184]], [[0.9151251316070557]], [[4.249286651611328]], [[-4.215320110321045]], [[-0.5376071929931641]], [[0.10527729988098145]], [[-0.5580596923828125]], [[-0.5372371673583984]], [[0.1669003963470459]], [[0.08901786804199219]], [[2.304154396057129]], [[0.0]], [[0.810484766960144]], [[0.16339990496635437]], [[0.044417642056941986]], [[-0.6533951759338379]], [[0.859836757183075]], [[0.499225378036499]], [[3.192890167236328]], [[-3.1310949325561523]], [[-0.4461393356323242]], [[0.03757357597351074]], [[-0.5955023765563965]], [[-0.48235607147216797]], [[0.28710269927978516]], [[-0.15997695922851562]], [[0.32933294773101807]], [[0.08567523956298828]], [[3.983084201812744]], [[1.706916332244873]], [[-0.47963619232177734]], [[-0.004657268524169922]], [[-0.6139841079711914]], [[-0.4940528869628906]], [[0.02175426483154297]], [[0.5124750137329102]], [[0.48239898681640625]], [[7.830748558044434]], [[1.7762694358825684]], [[0.723395586013794]], [[1.000755786895752]], [[-0.07819843292236328]], [[0.15584349632263184]], [[0.2738947868347168]], [[-0.0003954172134399414]], [[0.4618641138076782]], [[-0.08554291725158691]], [[0.3472723960876465]], [[0.3261692523956299]], [[7.930635452270508]], [[2.3565564155578613]], [[0.10835753381252289]], [[0.7538085579872131]], [[6.9970011711120605]], [[1.0115172863006592]], [[0.5502581596374512]], [[0.34486091136932373]], [[0.6333404779434204]], [[0.372572660446167]], [[0.2590353488922119]], [[-1.9007236957550049]], [[0.014082259498536587]], [[0.0]], [[0.3999899625778198]], [[0.31276416778564453]], [[0.19050520658493042]], [[0.5544229745864868]], [[0.13189426064491272]], [[0.4827885031700134]], [[3.1361141204833984]], [[0.813514232635498]], [[0.3182082176208496]], [[2.334214210510254]], [[2.1614279747009277]], [[0.032982707023620605]], [[0.40584278106689453]], [[0.5988321304321289]], [[0.02114788070321083]], [[0.13263091444969177]], [[-0.1282300353050232]], [[0.9063053131103516]], [[0.4094218611717224]], [[-0.2513751983642578]], [[0.46492063999176025]], [[0.0674734115600586]], [[-0.26492249965667725]], [[0.1123819425702095]], [[0.12836217880249023]], [[7.441878795623779]], [[0.8837611675262451]], [[1.511735439300537]], [[0.38304761052131653]], [[-0.025877952575683594]], [[0.3221086859703064]], [[0.06589281558990479]], [[0.08147013187408447]], [[0.3808445930480957]], [[0.0442781001329422]], [[0.1160726547241211]], [[0.5580011606216431]], [[0.021654104813933372]], [[0.7077150344848633]], [[-1.1474629640579224]], [[-0.4236431121826172]], [[-0.0007828995585441589]], [[1.3148648738861084]], [[0.1834656000137329]], [[0.0016801093006506562]], [[0.8723245859146118]], [[0.19662714004516602]], [[0.1524379551410675]], [[-0.5780467987060547]], [[-0.04471643269062042]], [[0.0]], [[1.4798545837402344]], [[0.36828678846359253]], [[0.20486974716186523]], [[0.27514195442199707]], [[-0.0541834831237793]], [[-0.31738969683647156]], [[0.11782431602478027]], [[0.14025092124938965]], [[0.16382980346679688]], [[0.44798707962036133]], [[3.5735607147216797]], [[0.8465976715087891]], [[2.6136512756347656]], [[1.1479871273040771]], [[0.6837296485900879]], [[0.020235905423760414]], [[0.0067216213792562485]], [[0.5034154653549194]], [[0.23903411626815796]], [[-0.2600048780441284]], [[-0.2850375175476074]], [[-0.23008137941360474]], [[0.07854282855987549]], [[-0.046704769134521484]], [[0.2909271717071533]], [[7.394076824188232]], [[1.3299057483673096]], [[0.6814436912536621]], [[-0.5107152462005615]], [[0.002837061882019043]], [[0.16267120838165283]], [[0.19574975967407227]], [[-1.0662102699279785]], [[0.30829674005508423]], [[-0.03700113296508789]], [[-0.5072870254516602]], [[0.007197104394435883]], [[0.4169580042362213]], [[0.1302495002746582]], [[0.5073246955871582]], [[0.0034411409869790077]], [[0.6429929733276367]], [[0.07596968114376068]], [[0.7294708490371704]], [[5.636940956115723]], [[0.015362909063696861]], [[0.18099594116210938]], [[1.4534549713134766]], [[0.5219116806983948]], [[2.192805290222168]], [[0.0]], [[0.04723501205444336]], [[-0.819190502166748]], [[0.06586097925901413]], [[0.46017706394195557]], [[0.23505520820617676]], [[0.4641802906990051]], [[0.0878438800573349]], [[-0.006758511066436768]], [[0.25610077381134033]], [[6.796384811401367]], [[2.016988754272461]], [[0.06969165802001953]], [[0.1384536623954773]], [[-0.003150641918182373]], [[0.23756414651870728]], [[0.6026120185852051]], [[0.08750047534704208]], [[0.45563793182373047]], [[0.03434586524963379]], [[0.6505863666534424]], [[0.10180199146270752]], [[0.09028637409210205]], [[0.19784176349639893]], [[0.10919377207756042]], [[0.5072664022445679]], [[7.378564834594727]], [[0.6312640905380249]], [[0.1051296591758728]], [[0.08754312992095947]], [[-0.07887077331542969]], [[-0.005332648754119873]], [[0.8598822355270386]], [[6.773649215698242]], [[0.9975924491882324]], [[0.07842497527599335]], [[0.03666210174560547]], [[0.252347469329834]], [[0.6067309379577637]], [[-0.3267936706542969]], [[-0.1334206461906433]], [[0.8248159885406494]], [[7.061877250671387]], [[0.6588118076324463]], [[-0.9822211265563965]], [[-0.4330558776855469]], [[-0.020502090454101562]], [[0.6356587409973145]], [[-0.0333021879196167]], [[0.6136641502380371]], [[0.7281081676483154]], [[0.0]]], \"firstDimensionName\": \"Layer (resid_pre)\", \"secondDimensionName\": \"Model\", \"secondDimensionLabels\": [\"pythia-2.8b\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7ff8d671c5e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most negative examples:\n",
      "Example:  Harry, Activation: -4.3514, Batch: 0, Pos: 5\n",
      "Example:  Harry, Activation: -3.9012, Batch: 2, Pos: 231\n",
      "Example:  really, Activation: -2.7406, Batch: 3, Pos: 106\n",
      "Example:  Dud, Activation: -2.6939, Batch: 4, Pos: 803\n",
      "Example: d, Activation: -2.5267, Batch: 4, Pos: 100\n",
      "Example:  Harry, Activation: -2.2675, Batch: 3, Pos: 301\n",
      "Example: ss, Activation: -2.2039, Batch: 0, Pos: 346\n",
      "Example:  Uncle, Activation: -2.0734, Batch: 1, Pos: 638\n",
      "Example:  ate, Activation: -1.9974, Batch: 1, Pos: 392\n",
      "Example:  D, Activation: -1.9494, Batch: 4, Pos: 836\n",
      "Example:  wink, Activation: -1.9007, Batch: 1, Pos: 889\n",
      "Example:  Tib, Activation: -1.8830, Batch: 2, Pos: 747\n",
      "Example: \n",
      ", Activation: -1.7970, Batch: 1, Pos: 930\n",
      "Example:  could, Activation: -1.7771, Batch: 3, Pos: 848\n",
      "Example:  bag, Activation: -1.7767, Batch: 3, Pos: 666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b25dedad-bd0a\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b25dedad-bd0a\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \" next\", \" to\", \" the\", \" glass\", \".\", \" Harry\", \" peered\", \" at\", \" it\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"Bo\", \"a\", \" Const\", \"rict\", \"or\", \",\", \" Brazil\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"All\", \" right\", \",\", \" thirty\", \"-\", \"seven\", \" then\", \",\\\"\", \" said\", \" Dud\", \"ley\", \",\", \" going\", \" red\", \" in\", \" the\", \" face\", \".\", \" Harry\", \",\", \" who\", \" could\", \" see\", \" a\", \" huge\", \" Dud\", \"ley\", \" tant\", \"rum\", \" coming\", \" on\", \",\", \" began\", \" wolf\", \"ing\", \" down\", \" his\", \" bacon\", \" as\", \" fast\", \" as\", \" possible\", \" in\", \"\\n\", \" Mr\", \".\", \" D\", \"urs\", \"ley\", \" had\", \" seen\", \" that\", \" fate\", \"ful\", \" news\", \" report\", \" about\", \" the\", \" ow\", \"ls\", \".\", \" Only\", \" the\", \" photographs\", \" on\", \" the\", \" mant\", \"el\", \"piece\", \" really\", \" showed\", \" how\", \" much\", \" time\", \" had\", \" passed\", \".\", \" Ten\", \" years\", \" ago\", \",\", \" there\", \" had\", \" been\", \" lots\", \" of\", \" pictures\", \" of\", \" what\", \" looked\", \" like\", \" a\", \" large\", \" pink\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"On\", \" the\", \" other\", \" hand\", \",\", \" he\", \"'d\", \" gotten\", \" into\", \" terrible\", \" trouble\", \" for\", \" being\", \" found\", \" on\", \" the\", \" roof\", \" of\", \" the\", \" school\", \" kitchen\", \"s\", \".\", \" Dud\", \"ley\", \"'s\", \" gang\", \" had\", \" been\", \" chasing\", \" him\", \" as\", \" usual\", \" when\", \",\", \" as\", \" much\", \" to\", \" Harry\", \"'s\", \" surprise\", \" as\", \" anyone\", \" else\", \"'s\", \",\", \" there\", \" he\", \"\\n\", \" face\", \" and\", \" w\", \"ailed\", \",\", \" his\", \" mother\", \" would\", \" give\", \" him\", \" anything\", \" he\", \" wanted\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"D\", \"inky\", \" Dud\", \"dy\", \"d\", \"ums\", \",\", \" don\", \"'t\", \" cry\", \",\", \" M\", \"ummy\", \" won\", \"'t\", \" let\", \" him\", \" spoil\", \" your\", \" special\", \" day\", \"!\\\"\", \" she\", \" cried\", \",\", \" fl\", \"inging\", \" her\", \" arms\", \"\\n\", \" a\", \" start\", \".\", \" His\", \" aunt\", \" ra\", \"pped\", \" on\", \" the\", \" door\", \" again\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"Up\", \"!\\\"\", \" she\", \" scree\", \"ched\", \".\", \" Harry\", \" heard\", \" her\", \" walking\", \" toward\", \" the\", \" kitchen\", \" and\", \" then\", \" the\", \" sound\", \" of\", \" the\", \" frying\", \" pan\", \" being\", \" put\", \" on\", \" the\", \" stove\", \".\", \" He\", \" rolled\", \" onto\", \" his\", \"\\n\", \" him\", \",\", \" Harry\", \" could\", \" have\", \" sworn\", \" a\", \" low\", \",\", \" his\", \"sing\", \" voice\", \" said\", \",\", \" \\\"\", \"Brazil\", \",\", \" here\", \" I\", \" come\", \".\", \" .\", \" .\", \" .\", \" Thanks\", \"ss\", \",\", \" am\", \"igo\", \".\\\"\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"The\", \" keeper\", \" of\", \" the\", \" rept\", \"ile\", \" house\", \" was\", \" in\", \" shock\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \" the\", \" gl\", \"ist\", \"ening\", \" brown\", \" coils\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"Make\", \" it\", \" move\", \",\\\"\", \" he\", \" wh\", \"ined\", \" at\", \" his\", \" father\", \".\", \" Uncle\", \" Vernon\", \" tapped\", \" on\", \" the\", \" glass\", \",\", \" but\", \" the\", \" snake\", \" didn\", \"'t\", \" bud\", \"ge\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"Do\", \" it\", \" again\", \"\\n\", \" were\", \" starting\", \" to\", \" get\", \" bored\", \" with\", \" the\", \" animals\", \" by\", \" lunch\", \"time\", \",\", \" wouldn\", \"'t\", \" fall\", \" back\", \" on\", \" their\", \" favorite\", \" hobby\", \" of\", \" hitting\", \" him\", \".\", \" They\", \" ate\", \" in\", \" the\", \" zoo\", \" restaurant\", \",\", \" and\", \" when\", \" Dud\", \"ley\", \" had\", \" a\", \" tant\", \"rum\", \" because\", \" his\", \" kn\", \"icker\", \"b\", \"ocker\", \" glory\", \" didn\", \"'t\", \" have\", \" enough\", \"\\n\", \" as\", \" usual\", \" when\", \",\", \" as\", \" much\", \" to\", \" Harry\", \"'s\", \" surprise\", \" as\", \" anyone\", \" else\", \"'s\", \",\", \" there\", \" he\", \" was\", \" sitting\", \" on\", \" the\", \" chim\", \"ney\", \".\", \" The\", \" D\", \"urs\", \"leys\", \" had\", \" received\", \" a\", \" very\", \" angry\", \" letter\", \" from\", \" Harry\", \"'s\", \" head\", \"mist\", \"ress\", \" telling\", \" them\", \" Harry\", \" had\", \" been\", \" climbing\", \" school\", \" buildings\", \".\", \" But\", \"\\n\", \" stared\", \".\", \" Then\", \" he\", \" looked\", \" quickly\", \" around\", \" to\", \" see\", \" if\", \" anyone\", \" was\", \" watching\", \".\", \" They\", \" weren\", \"'t\", \".\", \" He\", \" looked\", \" back\", \" at\", \" the\", \" snake\", \" and\", \" wink\", \"ed\", \",\", \" too\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"The\", \" snake\", \" jerked\", \" its\", \" head\", \" toward\", \" Uncle\", \" Vernon\", \" and\", \" Dud\", \"ley\", \",\", \" then\", \" raised\", \"\\n\", \" broken\", \" her\", \" leg\", \",\", \" but\", \" it\", \" wasn\", \"'t\", \" easy\", \" when\", \" he\", \" reminded\", \" himself\", \" it\", \" would\", \" be\", \" a\", \" whole\", \" year\", \" before\", \" he\", \" had\", \" to\", \" look\", \" at\", \" Tib\", \"bles\", \",\", \" Snow\", \"y\", \",\", \" Mr\", \".\", \" P\", \"aws\", \",\", \" and\", \" T\", \"uf\", \"ty\", \" again\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"We\", \"\\n\", \" toward\", \" Uncle\", \" Vernon\", \" and\", \" Dud\", \"ley\", \",\", \" then\", \" raised\", \" its\", \" eyes\", \" to\", \" the\", \" ceiling\", \".\", \" It\", \" gave\", \" Harry\", \" a\", \" look\", \" that\", \" said\", \" quite\", \" plainly\", \":\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"I\", \" get\", \" that\", \" all\", \" the\", \" time\", \".\\\"\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"I\", \" know\", \",\\\"\", \" Harry\", \"\\n\", \" that\", \" was\", \" shaped\", \" like\", \" a\", \" bolt\", \" of\", \" lightning\", \".\", \" He\", \" had\", \" had\", \" it\", \" as\", \" long\", \" as\", \" he\", \" could\", \" remember\", \",\", \" and\", \" the\", \" first\", \" question\", \" he\", \" could\", \" ever\", \" remember\", \" asking\", \" his\", \" Aunt\", \" Pet\", \"un\", \"ia\", \" was\", \" how\", \" he\", \" had\", \" gotten\", \" it\", \".\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\n\", \"<|endoftext|>\", \"<|endoftext|>\", \"\\\"\", \"In\", \" the\", \"\\n\", \" as\", \" Dud\", \"ley\", \" was\", \" very\", \" fat\", \" and\", \" hated\", \" exercise\", \" -\", \" unless\", \" of\", \" course\", \" it\", \" involved\", \" punch\", \"ing\", \" somebody\", \".\", \" Dud\", \"ley\", \"'s\", \" favorite\", \" punch\", \"ing\", \" bag\", \" was\", \" Harry\", \",\", \" but\", \" he\", \" couldn\", \"'t\", \" often\", \" catch\", \" him\", \".\", \" Harry\", \" didn\", \"'t\", \" look\", \" it\", \",\", \" but\", \" he\", \" was\", \" very\", \" fast\", \".\", \"\\n\", \"\\n\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-4.351399898529053]], [[3.110344886779785]], [[-0.45101678371429443]], [[1.0294079780578613]], [[0.6474385261535645]], [[3.4334678649902344]], [[-3.654513359069824]], [[-0.27355480194091797]], [[0.04391074180603027]], [[-0.4642753601074219]], [[-0.2904329299926758]], [[-0.3621664047241211]], [[-0.5057692527770996]], [[0.3832206726074219]], [[0.1262240707874298]], [[0.05418097972869873]], [[-0.4367406368255615]], [[0.1896805763244629]], [[-0.6039214134216309]], [[3.962955951690674]], [[3.8907551765441895]], [[-0.2978506088256836]], [[-0.006840944290161133]], [[-0.5659379959106445]], [[-0.36159324645996094]], [[0.0]], [[0.45929884910583496]], [[-2.9106836318969727]], [[-0.3264303207397461]], [[0.12515902519226074]], [[-0.3009657859802246]], [[-0.29808521270751953]], [[-0.012221813201904297]], [[0.2370462417602539]], [[0.2888178825378418]], [[0.04299309849739075]], [[-1.0063390731811523]], [[-0.3684372901916504]], [[-0.16845083236694336]], [[-0.018733978271484375]], [[-0.5015721321105957]], [[0.024421215057373047]], [[1.641676902770996]], [[0.34345197677612305]], [[0.15802955627441406]], [[0.2772359848022461]], [[-0.1352066993713379]], [[0.1306389570236206]], [[0.006324721500277519]], [[0.050719454884529114]], [[0.351406455039978]], [[-3.901193141937256]], [[-0.5781631469726562]], [[1.044234275817871]], [[-0.23633813858032227]], [[0.12760400772094727]], [[0.034731149673461914]], [[0.09274625778198242]], [[1.7074594497680664]], [[0.013192269951105118]], [[0.8600549697875977]], [[0.009779674932360649]], [[0.3911648988723755]], [[-0.5095914602279663]], [[0.7170231342315674]], [[0.41820716857910156]], [[0.022451400756835938]], [[1.3962664604187012]], [[0.16821987926959991]], [[0.3451664447784424]], [[0.4614133834838867]], [[0.6582949161529541]], [[0.03052574396133423]], [[0.032770946621894836]], [[-0.12443065643310547]], [[0.14454078674316406]], [[0.0]], [[0.05411338806152344]], [[0.07429739832878113]], [[5.373836517333984]], [[2.1575522422790527]], [[0.15674728155136108]], [[1.3265019655227661]], [[0.9745292663574219]], [[-0.2330760955810547]], [[3.01059627532959]], [[0.18063166737556458]], [[1.5893421173095703]], [[1.3308179378509521]], [[1.2898446321487427]], [[-0.14217036962509155]], [[-1.3821649551391602]], [[0.5873992443084717]], [[1.197120189666748]], [[9.50936508178711]], [[1.4659852981567383]], [[4.262355804443359]], [[1.9955004453659058]], [[0.2800448536872864]], [[1.528871774673462]], [[0.020231373608112335]], [[0.3070017695426941]], [[-2.740605354309082]], [[-0.7094111442565918]], [[0.34508562088012695]], [[1.4754772186279297]], [[3.368595600128174]], [[0.7640029788017273]], [[0.021615803241729736]], [[0.4908527135848999]], [[4.430600166320801]], [[1.1041932106018066]], [[0.13908684253692627]], [[0.08553960919380188]], [[1.9608969688415527]], [[0.7624764442443848]], [[0.1002662405371666]], [[-0.34642505645751953]], [[0.14160555601119995]], [[1.6639772653579712]], [[0.6974669694900513]], [[-0.188812255859375]], [[1.247959852218628]], [[0.03754305839538574]], [[0.0169830322265625]], [[0.5411815643310547]], [[-0.12155866622924805]], [[0.0]], [[-0.377108097076416]], [[-0.27208614349365234]], [[0.11701536178588867]], [[0.24442648887634277]], [[0.09851646423339844]], [[-0.33740437030792236]], [[0.006734520196914673]], [[0.9654831886291504]], [[0.04910755157470703]], [[0.36619043350219727]], [[0.1694633960723877]], [[-0.04842948913574219]], [[0.34694308042526245]], [[0.23737919330596924]], [[0.25150108337402344]], [[-0.3310279846191406]], [[-0.3704562187194824]], [[0.11806309223175049]], [[0.21695971488952637]], [[0.00865432620048523]], [[-0.07255434989929199]], [[0.5905227661132812]], [[-0.3349800109863281]], [[-1.0303244590759277]], [[0.0906519889831543]], [[-2.6938562393188477]], [[0.07374735921621323]], [[-0.311262845993042]], [[0.36313629150390625]], [[0.710136890411377]], [[0.08698141574859619]], [[0.40030431747436523]], [[0.25555312633514404]], [[-0.05014228820800781]], [[0.5173232555389404]], [[0.38184237480163574]], [[-0.89544677734375]], [[-0.4791693687438965]], [[-0.30001258850097656]], [[0.705502986907959]], [[-1.3378500938415527]], [[0.6423205137252808]], [[0.2670707702636719]], [[-0.31580090522766113]], [[0.7659609317779541]], [[0.10690528154373169]], [[0.0865551233291626]], [[0.06556662917137146]], [[0.5907297134399414]], [[-0.08372926712036133]], [[0.0]], [[0.5173144340515137]], [[-0.054412841796875]], [[0.5549736022949219]], [[1.5744168758392334]], [[-0.0022585391998291016]], [[-0.0037059783935546875]], [[0.19950580596923828]], [[0.1008521318435669]], [[-0.0875086784362793]], [[0.14735856652259827]], [[0.8386993408203125]], [[0.006866723299026489]], [[0.15488304197788239]], [[0.1957893669605255]], [[4.049934387207031]], [[-3.6025991439819336]], [[-0.2643003463745117]], [[0.08849692344665527]], [[-0.3594856262207031]], [[-0.2819356918334961]], [[-0.03882551193237305]], [[0.40000152587890625]], [[0.36841297149658203]], [[0.49031925201416016]], [[0.2755007743835449]], [[-2.526730537414551]], [[0.5302317142486572]], [[-0.5367951393127441]], [[-0.05494880676269531]], [[0.12612488865852356]], [[0.11517190933227539]], [[0.03610658645629883]], [[0.32038450241088867]], [[0.5201119184494019]], [[0.025190353393554688]], [[0.03827236220240593]], [[0.043817758560180664]], [[0.3798842430114746]], [[0.5380525588989258]], [[0.12035298347473145]], [[0.11524438858032227]], [[0.08940915763378143]], [[0.2689850330352783]], [[-0.6009688377380371]], [[0.24922752380371094]], [[-0.10632836818695068]], [[0.9165515899658203]], [[0.2824254035949707]], [[0.10396742820739746]], [[0.5855969190597534]], [[0.0]], [[0.1504475474357605]], [[0.09830087423324585]], [[0.3282240629196167]], [[7.1264142990112305]], [[-0.8421077728271484]], [[-0.4157896041870117]], [[1.0360870361328125]], [[0.26460909843444824]], [[0.07693588733673096]], [[0.5143448114395142]], [[0.3404965400695801]], [[0.39774394035339355]], [[3.661036491394043]], [[-0.9029741287231445]], [[-0.20217037200927734]], [[0.05377340316772461]], [[-0.4355449676513672]], [[-0.18625354766845703]], [[-0.0554804801940918]], [[-0.1388082504272461]], [[-0.12157213687896729]], [[0.8867282867431641]], [[0.7273578643798828]], [[0.13510003685951233]], [[0.16086721420288086]], [[-2.267549514770508]], [[1.2337803840637207]], [[0.08283579349517822]], [[1.290827751159668]], [[-0.3572852611541748]], [[0.02760910987854004]], [[0.48858213424682617]], [[0.9135088920593262]], [[0.3648550510406494]], [[0.22868132591247559]], [[0.24881219863891602]], [[0.04651285335421562]], [[0.04723501205444336]], [[-0.819190502166748]], [[0.06586097925901413]], [[0.46017706394195557]], [[0.23505520820617676]], [[0.4641802906990051]], [[0.0878438800573349]], [[-0.006758511066436768]], [[0.25610077381134033]], [[6.796384811401367]], [[2.016988754272461]], [[0.06969165802001953]], [[0.1384536623954773]], [[0.0]], [[0.6883764266967773]], [[0.04255238175392151]], [[1.1335163116455078]], [[0.47586679458618164]], [[-0.12958264350891113]], [[-0.040544360876083374]], [[-0.20548057556152344]], [[0.3342733383178711]], [[0.03120577335357666]], [[0.32425975799560547]], [[0.11846660822629929]], [[0.16291356086730957]], [[-0.12482285499572754]], [[0.11144697666168213]], [[0.9071424007415771]], [[0.04570293426513672]], [[-0.0455164909362793]], [[0.15734553337097168]], [[0.10205888748168945]], [[0.06281983107328415]], [[-0.09504818916320801]], [[6.894859790802002]], [[0.413798987865448]], [[-1.0442657470703125]], [[1.5227794647216797]], [[-2.2038745880126953]], [[0.8145203590393066]], [[0.3177666664123535]], [[-0.09188199043273926]], [[0.5677089691162109]], [[0.25734639167785645]], [[-2.0510330200195312]], [[-0.3136568069458008]], [[0.1407630443572998]], [[-0.3199272155761719]], [[-0.2873363494873047]], [[0.16118383407592773]], [[0.24604034423828125]], [[0.09958988428115845]], [[0.06867331266403198]], [[0.1761913299560547]], [[-0.05258053541183472]], [[0.5132167339324951]], [[0.7155487537384033]], [[-0.03486490249633789]], [[1.0827312469482422]], [[0.022751033306121826]], [[3.194455623626709]], [[-0.32159996032714844]], [[-0.2784557342529297]], [[0.0]], [[0.06710568070411682]], [[-0.3070826530456543]], [[0.7337918281555176]], [[0.0005684778443537652]], [[0.45996570587158203]], [[0.2658824920654297]], [[-0.0066225528717041016]], [[2.903740882873535]], [[-1.0982627868652344]], [[-0.3415403366088867]], [[0.031974077224731445]], [[-0.51519775390625]], [[-0.42351627349853516]], [[-0.1382451057434082]], [[0.4334406852722168]], [[0.21909141540527344]], [[0.17722368240356445]], [[-0.6190836429595947]], [[1.1123692989349365]], [[0.2903141975402832]], [[0.23518328368663788]], [[0.09139823913574219]], [[0.007590174674987793]], [[0.11386394500732422]], [[0.19438529014587402]], [[-2.073403835296631]], [[0.4606313705444336]], [[1.2141294479370117]], [[-0.46227097511291504]], [[0.1553126871585846]], [[-0.03089725971221924]], [[-0.12307560443878174]], [[0.5752978324890137]], [[0.28140461444854736]], [[0.7327947616577148]], [[0.3711991310119629]], [[0.09118404239416122]], [[0.37484097480773926]], [[0.01525767520070076]], [[0.30212464928627014]], [[3.5425658226013184]], [[-0.9865932464599609]], [[-0.36008262634277344]], [[0.05649995803833008]], [[-0.5982913970947266]], [[-0.45633983612060547]], [[-0.08364152908325195]], [[0.26917028427124023]], [[0.31203413009643555]], [[-0.28884315490722656]], [[0.0]], [[0.34604567289352417]], [[0.08601665496826172]], [[0.09298041462898254]], [[0.09800684452056885]], [[0.33626842498779297]], [[0.01249074935913086]], [[0.0026111602783203125]], [[-0.12918758392333984]], [[-0.0032873153686523438]], [[-0.11819982528686523]], [[0.24870583415031433]], [[0.05018176883459091]], [[0.5771397948265076]], [[0.17537036538124084]], [[0.09508800506591797]], [[0.044873714447021484]], [[0.2444627285003662]], [[0.26071810722351074]], [[-0.7740235328674316]], [[-0.3718099594116211]], [[0.11400240659713745]], [[0.5451030731201172]], [[1.6645660400390625]], [[0.18880391120910645]], [[8.284965515136719]], [[-1.9974145889282227]], [[0.03048086166381836]], [[0.16837704181671143]], [[0.47397518157958984]], [[-1.0588953495025635]], [[0.22381865978240967]], [[0.20940613746643066]], [[0.4282810688018799]], [[0.3466329574584961]], [[0.004235051106661558]], [[0.5351247787475586]], [[-0.22713208198547363]], [[0.048201560974121094]], [[0.0026832539588212967]], [[0.8378324508666992]], [[-0.05762600898742676]], [[-0.2421131134033203]], [[0.9085128307342529]], [[0.7112301588058472]], [[0.6751458644866943]], [[0.6641457080841064]], [[1.014854907989502]], [[0.18966035544872284]], [[0.12308907508850098]], [[0.5786346197128296]], [[0.0]], [[-0.05014228820800781]], [[0.5173232555389404]], [[0.38184237480163574]], [[-0.89544677734375]], [[-0.4791693687438965]], [[-0.30001258850097656]], [[0.705502986907959]], [[-1.3378500938415527]], [[0.6423205137252808]], [[0.2670707702636719]], [[-0.31580090522766113]], [[0.7659609317779541]], [[0.10690528154373169]], [[0.0865551233291626]], [[0.06556662917137146]], [[0.5907297134399414]], [[-0.08372926712036133]], [[0.15620316565036774]], [[0.7264962196350098]], [[0.2918124794960022]], [[0.14627203345298767]], [[-0.8916420936584473]], [[0.03493104875087738]], [[0.6095540523529053]], [[4.578487396240234]], [[-1.9494071006774902]], [[0.04379357025027275]], [[0.15471133589744568]], [[0.7406851649284363]], [[-0.020398616790771484]], [[0.23020607233047485]], [[0.07161998748779297]], [[0.31720423698425293]], [[-0.009261906147003174]], [[0.10433268547058105]], [[-0.09716033935546875]], [[0.5545631647109985]], [[1.3925442695617676]], [[-0.33055102825164795]], [[0.01085260696709156]], [[1.1382696628570557]], [[0.2888423204421997]], [[-1.3270316123962402]], [[0.16408491134643555]], [[0.31426817178726196]], [[0.5409932136535645]], [[0.5342936515808105]], [[0.13384902477264404]], [[0.3282132148742676]], [[6.004727363586426]], [[0.0]], [[0.5124750137329102]], [[0.48239898681640625]], [[7.830748558044434]], [[1.7762694358825684]], [[0.723395586013794]], [[1.000755786895752]], [[-0.07819843292236328]], [[0.15584349632263184]], [[0.2738947868347168]], [[-0.0003954172134399414]], [[0.4618641138076782]], [[-0.08554291725158691]], [[0.3472723960876465]], [[0.3261692523956299]], [[7.930635452270508]], [[2.3565564155578613]], [[0.10835753381252289]], [[0.7538085579872131]], [[6.9970011711120605]], [[1.0115172863006592]], [[0.5502581596374512]], [[0.34486091136932373]], [[0.6333404779434204]], [[0.372572660446167]], [[0.2590353488922119]], [[-1.9007236957550049]], [[0.014082259498536587]], [[-1.0146360397338867]], [[3.6720824241638184]], [[0.9151251316070557]], [[4.249286651611328]], [[-4.215320110321045]], [[-0.5376071929931641]], [[0.10527729988098145]], [[-0.5580596923828125]], [[-0.5372371673583984]], [[0.1669003963470459]], [[0.08901786804199219]], [[2.304154396057129]], [[-0.0656815767288208]], [[0.11273519694805145]], [[0.06719493865966797]], [[0.0804738998413086]], [[0.9127631187438965]], [[0.3253347873687744]], [[0.20470714569091797]], [[0.2385498434305191]], [[0.27456438541412354]], [[0.009450197219848633]], [[0.11157894134521484]], [[0.0]], [[0.387087345123291]], [[0.4290279150009155]], [[0.06885719299316406]], [[0.6696622967720032]], [[1.3326185941696167]], [[0.10974574089050293]], [[0.7590714693069458]], [[0.08246947824954987]], [[0.2750697135925293]], [[0.09922599792480469]], [[0.8986611366271973]], [[0.9362945556640625]], [[0.09937525540590286]], [[-0.40840625762939453]], [[-0.35647106170654297]], [[-0.08513641357421875]], [[0.06728959083557129]], [[0.3388862609863281]], [[0.49652647972106934]], [[0.3619808852672577]], [[0.37303853034973145]], [[-0.04076576232910156]], [[0.4149671792984009]], [[-0.05798768997192383]], [[0.1778925657272339]], [[-1.8829565048217773]], [[1.6352932453155518]], [[-0.4695577621459961]], [[1.0223054885864258]], [[-0.4979742765426636]], [[0.5354957580566406]], [[-0.189453125]], [[1.3479831218719482]], [[1.995683193206787]], [[-1.6579999923706055]], [[0.7156572341918945]], [[0.9435774683952332]], [[-1.1705067157745361]], [[-0.6151490211486816]], [[0.34576526284217834]], [[1.0521011352539062]], [[0.7710400223731995]], [[4.5449113845825195]], [[-4.9125261306762695]], [[-0.39342212677001953]], [[0.035932302474975586]], [[-0.27395009994506836]], [[-0.3482475280761719]], [[-0.08100271224975586]], [[0.23986220359802246]], [[0.0]], [[0.06719493865966797]], [[0.0804738998413086]], [[0.9127631187438965]], [[0.3253347873687744]], [[0.20470714569091797]], [[0.2385498434305191]], [[0.27456438541412354]], [[0.009450197219848633]], [[0.11157894134521484]], [[0.15269428491592407]], [[-0.09769010543823242]], [[0.19462203979492188]], [[0.07454335689544678]], [[0.08803129196166992]], [[0.2357121706008911]], [[7.197422981262207]], [[0.23806095123291016]], [[0.29302406311035156]], [[0.31784576177597046]], [[0.4116358757019043]], [[0.3296108841896057]], [[-0.07761096954345703]], [[-0.28196001052856445]], [[-0.05092579126358032]], [[0.154130220413208]], [[-1.7970455884933472]], [[-3.859394073486328]], [[-0.4608316421508789]], [[0.213043212890625]], [[-0.5525479316711426]], [[-0.47741127014160156]], [[-0.08684253692626953]], [[0.6225786209106445]], [[0.19593000411987305]], [[0.18367362022399902]], [[0.272951602935791]], [[0.01907747983932495]], [[0.0976327583193779]], [[0.26096248626708984]], [[-0.11787372827529907]], [[-2.2023096084594727]], [[-0.49932003021240234]], [[0.11975550651550293]], [[-0.801938533782959]], [[-0.5136909484863281]], [[-0.03180694580078125]], [[0.5769457817077637]], [[0.23861932754516602]], [[-1.462109088897705]], [[1.5676031112670898]], [[0.0]], [[0.18816757202148438]], [[0.21776866912841797]], [[1.1137967109680176]], [[0.12494448572397232]], [[0.06792104244232178]], [[-0.10144758224487305]], [[-0.0470736026763916]], [[0.317804217338562]], [[0.6567776203155518]], [[6.4188055992126465]], [[0.9209996461868286]], [[0.9779782295227051]], [[0.353759765625]], [[-0.050656795501708984]], [[-0.03151440620422363]], [[0.06639891117811203]], [[0.13103674352169037]], [[0.2561952769756317]], [[0.01542879268527031]], [[0.30353087186813354]], [[1.6097691059112549]], [[-0.046843767166137695]], [[-0.1394486427307129]], [[-1.0510387420654297]], [[-0.2120072841644287]], [[-1.7771344184875488]], [[0.34054791927337646]], [[0.1191166341304779]], [[-0.05761495232582092]], [[0.09465312957763672]], [[-0.7085151672363281]], [[1.349959373474121]], [[0.19158759713172913]], [[0.010727254673838615]], [[0.5713757276535034]], [[0.31989407539367676]], [[1.0806646347045898]], [[0.05910921096801758]], [[0.5760295987129211]], [[0.03702724725008011]], [[0.828670859336853]], [[4.33157205581665]], [[-4.303762435913086]], [[-0.2527599334716797]], [[0.02318286895751953]], [[-0.5064778327941895]], [[-0.24394512176513672]], [[-0.07593536376953125]], [[0.3109889030456543]], [[0.4549511671066284]], [[0.0]], [[1.9659481048583984]], [[-1.362168312072754]], [[0.0034777624532580376]], [[0.4152817726135254]], [[0.416536808013916]], [[-0.32591724395751953]], [[0.930008053779602]], [[2.0211033821105957]], [[-0.5481245517730713]], [[0.3717775344848633]], [[0.8137326240539551]], [[-0.24851512908935547]], [[0.011666546575725079]], [[0.6126558780670166]], [[0.6997047662734985]], [[-0.29406118392944336]], [[0.01448235847055912]], [[-0.31769847869873047]], [[1.0200649499893188]], [[6.105726718902588]], [[0.005230578128248453]], [[-0.8021620512008667]], [[-0.9139468669891357]], [[2.1028575897216797]], [[-0.2618044316768646]], [[-1.7766740322113037]], [[2.4899110794067383]], [[-0.26671433448791504]], [[0.46778416633605957]], [[1.9281749725341797]], [[0.8117260932922363]], [[-0.27672338485717773]], [[0.0870424136519432]], [[0.802220344543457]], [[0.03912973403930664]], [[2.0696468353271484]], [[1.3654766082763672]], [[2.415440082550049]], [[1.2301058769226074]], [[0.021484334021806717]], [[-0.6852068901062012]], [[-1.5255446434020996]], [[0.12676602602005005]], [[2.3030357360839844]], [[0.9261481761932373]], [[0.5400667190551758]], [[0.6628165245056152]], [[0.7557265758514404]], [[1.1174681186676025]], [[3.8775038719177246]], [[0.0]]], \"firstDimensionName\": \"Layer (resid_pre)\", \"secondDimensionName\": \"Model\", \"secondDimensionLabels\": [\"pythia-2.8b\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7ff8c735c820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.neuroscope import plot_topk\n",
    "loss_change_by_token = torch.from_numpy(load_array('loss_change_by_token_by_row_hp.npy', model))\n",
    "plot_topk(\n",
    "    activations=loss_change_by_token_by_row, \n",
    "    dataloader=subset_data_loader, \n",
    "    window_size=25, \n",
    "    model=model, \n",
    "    k=15, \n",
    "    centred=False, \n",
    "    exclusions=[\" Fig\", \"'t\", \" Pinterest\", \" Kampf\", \"m\", \"uk\", \" Kamp\", \"com\", \"edu\", \"S\", \"youtube\", \"twitter\", \"0\", \"js\", \"py\", \" Protein\", \" Fiber\", \" Carbohydrates\", \" Sugar\", \" Grant\", \" Pub\", \",\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/curttigges/proj/eliciting-latent-sentiment/owt_comma_ablation.ipynb Cell 35\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/curttigges/proj/eliciting-latent-sentiment/owt_comma_ablation.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m subset_data_loader\u001b[39m.\u001b[39;49mdataset[\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mtokens\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "subset_data_loader.dataset[0]['tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-a211229d-da79\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-a211229d-da79\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \" if\", \" Erik\", \" had\", \" been\", \" awake\", \",\", \" the\", \" fact\", \" that\", \" he\", \" was\", \" called\", \" upon\", \" as\", \" part\", \" of\", \" D\", \"audi\", \"\\u2019\", \"s\", \" \\u201c\", \"al\", \"ibi\", \"\\u201d\", \" should\", \" have\", \" clearly\", \" demonstrated\", \" his\", \" lack\", \" of\", \" independence\", \".\", \" Erik\", \" should\", \" not\", \" have\", \" been\", \" a\", \" part\", \" of\", \" the\", \" panel\", \" that\", \" the\", \" Board\", \" constituted\", \" to\", \" investigate\", \" and\", \" make\", \" a\", \" decision\", \".\", \" One\", \" cannot\", \" be\", \" a\", \" witness\", \" and\", \" judge\", \" in\", \" the\", \" same\", \" case\", \"!\", \" To\", \" date\", \",\", \" D\", \"audi\", \" still\", \" has\", \" his\", \" job\", \":\", \" From\", \" the\", \" board\", \"\\u2019\", \"s\", \" latest\", \" update\", \",\", \" D\", \"audi\", \" has\", \" only\", \" been\", \" suspended\", \".\", \" It\", \" is\", \" entirely\", \" possible\", \" that\", \" he\", \" may\", \" be\", \" reinst\", \"ated\", \" in\", \" the\", \" company\", \".\", \" This\", \" is\", \" despite\", \" the\", \" Board\", \" possessing\", \" audio\", \" evidence\", \" of\", \" him\", \" sexually\", \" harass\", \"ing\", \" his\", \" junior\", \" as\", \" well\", \" as\", \" allegations\", \" from\", \" a\", \" plurality\", \" of\", \" victims\", \" which\", \" relate\", \" to\", \" multiple\", \" occurrences\", \".\", \" Even\", \" with\", \" this\", \",\", \" it\", \" still\", \" took\", \" public\", \" pressure\", \" for\", \" the\", \" Board\", \" to\", \" first\", \" send\", \" him\", \" on\", \" leave\", \" then\", \" suspend\", \" him\", \".\", \" This\", \" is\", \" unacceptable\", \".\", \" How\", \" are\", \" victims\", \" supposed\", \" to\", \" come\", \" forward\", \" if\", \" this\", \" is\", \" how\", \" a\", \" company\", \" with\", \" the\", \" reputation\", \" of\", \" U\", \"sh\", \"ah\", \"idi\", \" handles\", \" these\", \" inc\", \"idences\", \"?\", \"\\n\", \"\\n\", \"I\", \"\\u2019\", \"ve\", \" received\", \" several\", \" explanations\", \" for\", \" the\", \" delay\", \":\", \" The\", \" Board\", \" claims\", \" that\", \" this\", \" was\", \" a\", \" complex\", \" matter\", \" because\", \" U\", \"sh\", \"ah\", \"idi\", \" is\", \" dom\", \"ic\", \"iled\", \" in\", \" the\", \" US\", \",\", \" yet\", \" the\", \" employees\", \" are\", \" Ken\", \"yan\", \" and\", \" the\", \" incident\", \" occurred\", \" in\", \" Kenya\", \".\", \" It\", \" really\", \" wasn\", \"\\u2019\", \"t\", \" that\", \" complicated\", \".\", \" Florida\", \" and\", \" Ken\", \"yan\", \" law\", \" are\", \" in\", \" sync\", \" when\", \" it\", \" comes\", \" to\", \" sexual\", \" harassment\", \" laws\", \":\", \" we\", \" checked\", \" this\", \" before\", \" we\", \" submitted\", \" my\", \" complaint\", \" and\", \" even\", \" attached\", \" excerpt\", \"s\", \" from\", \" both\", \" countries\", \"\\u2019\", \" laws\", \".\", \"\\n\", \"\\n\", \"The\", \" Board\", \" has\", \" also\", \" claimed\", \" that\", \" they\", \" were\", \" not\", \" able\", \" to\", \" action\", \" my\", \" complaint\", \" as\", \" quickly\", \" as\", \" they\", \" would\", \" have\", \" liked\", \" because\", \" they\", \" were\", \" trying\", \" to\", \" avoid\", \" a\", \" wrongful\", \" termination\", \" suit\", \".\", \" As\", \" explained\", \" above\", \" this\", \" is\", \" ins\", \"ince\", \"re\", \".\", \" Based\", \" on\", \" the\", \" speed\", \" of\", \" events\", \" from\", \" the\", \" 3\", \"rd\", \" of\", \" July\", \",\", \" this\", \" could\", \" have\", \" been\", \" handled\", \" in\", \" 2\", \" weeks\", \".\", \" So\", \" why\", \" did\", \" it\", \" take\", \" 74\", \" days\", \"?\", \" It\", \" seems\", \" clear\", \" that\", \" the\", \" board\", \" was\", \" looking\", \" for\", \" reasons\", \" not\", \" to\", \" act\", \" despite\", \" their\", \" verbal\", \" and\", \" written\", \" ass\", \"urances\", \" to\", \" the\", \" contrary\", \".\", \" In\", \" such\", \" a\", \" case\", \",\", \" the\", \" will\", \" to\", \" act\", \" is\", \" all\", \" that\", \" matters\", \".\", \" Not\", \" assumed\", \" best\", \" intentions\", \".\", \" And\", \" based\", \" on\", \" their\", \" findings\", \",\", \" D\", \"audi\", \" is\", \" guilty\", \" of\", \" misconduct\", \" on\", \" several\", \" fronts\", \".\", \" None\", \" of\", \" that\", \" was\", \" news\", \" and\", \" was\", \" obvious\", \" even\", \" before\", \" the\", \" 5\", \"th\", \" July\", \" In\", \"quiry\", \" was\", \" held\", \".\", \" This\", \" should\", \" not\", \" have\", \" taken\", \" as\", \" long\", \" as\", \" it\", \" did\", \".\", \"\\n\", \"\\n\", \"As\", \" detailed\", \" extensively\", \" above\", \",\", \" for\", \" some\", \" mysterious\", \" reason\", \" the\", \" U\", \"sh\", \"ah\", \"idi\", \" board\", \" and\", \" leadership\", \" has\", \" been\", \" reluctant\", \" to\", \" take\", \" action\", \" even\", \" when\", \" presented\", \" with\", \" clear\", \" evidence\", \" about\", \" D\", \"audi\", \"\\u2019\", \"s\", \" misconduct\", \".\", \" This\", \" completely\", \" b\", \"ogg\", \"les\", \" the\", \" mind\", \" because\", \" this\", \" scandal\", \" poses\", \" an\", \" existential\", \" risk\", \" to\", \" U\", \"sh\", \"ah\", \"idi\", \" as\", \" an\", \" organisation\", \".\", \" The\", \" N\", \"airo\", \"bi\", \" grape\", \"vine\", \" was\", \" already\", \" buzz\", \"ing\", \" with\", \" rum\", \"ours\", \" of\", \" this\", \" complaint\", \" after\", \" it\", \" was\", \" made\", \" on\", \" 4\", \"th\", \" May\", \".\", \" The\", \" board\", \" just\", \" seems\", \" to\", \" have\", \" gone\", \" out\", \" of\", \" its\", \" way\", \" to\", \" avoid\", \" dealing\", \" with\", \" my\", \" complaint\", \".\", \"\\n\", \"\\n\", \"The\", \" board\", \" has\", \" also\", \" been\", \" less\", \" than\", \" forth\", \"right\", \" in\", \" the\", \" following\", \" ways\", \":\", \"\\n\", \"\\n\", \"Cl\", \"ay\", \" Shir\", \"ky\", \" left\", \" the\", \" Board\", \" of\", \" U\", \"sh\", \"ah\", \"idi\", \" in\", \" October\", \" 2015\", \".\", \" This\", \" was\", \" not\", \" announced\", \" internally\", \" nor\", \" externally\", \".\", \" Up\", \" until\", \" 15\", \"th\", \" July\", \",\", \" Clay\", \" was\", \" still\", \" listed\", \" on\", \" the\", \" website\", \" as\", \" a\", \" Board\", \" Member\", \".\", \" The\", \" summary\", \" of\", \" the\", \" proceedings\", \" at\", \" the\", \" inquiry\", \" is\", \" dub\", \"iously\", \" interpreted\", \",\", \" contains\", \" some\", \" outright\", \" misrepresent\", \"ations\", \" as\", \" well\", \" as\", \" the\", \" omission\", \" of\", \" relevant\", \" sections\", \".\", \" This\", \" can\", \" be\", \" borne\", \" out\", \" by\", \" the\", \" recording\", \" of\", \" said\", \" proceedings\", \" which\", \" the\", \" Board\", \" possesses\", \" and\", \" I\", \" invite\", \" them\", \" to\", \" share\", \" this\", \" recording\", \" in\", \" its\", \" entirety\", \" with\", \" the\", \" public\", \".\", \" Intern\", \"ally\", \",\", \" U\", \"sh\", \"ah\", \"idi\", \" has\", \" an\", \" open\", \" door\", \" policy\", \".\", \" However\", \",\", \" it\", \" seems\", \" that\", \" this\", \" openness\", \" exists\", \" in\", \" spite\", \" of\", \",\", \" and\", \" not\", \" because\", \" of\", \" the\", \" Board\", \".\", \" Erik\", \" has\", \" invited\", \" the\", \" staff\", \" to\", \" report\", \" any\", \" incident\", \" of\", \" harassment\", \" ass\", \"uring\", \" them\", \" that\", \" the\", \" Board\", \" will\", \" handle\", \" it\", \" swiftly\", \".\", \" This\", \" assurance\", \" is\", \" solid\", \"ly\", \" contrad\", \"icted\", \" by\", \" how\", \" the\", \" Board\", \" has\", \" thus\", \" far\", \" treated\", \" the\", \" two\", \" staff\", \" members\", \" who\", \" were\", \" sexually\", \" proposition\", \"ed\", \" on\", \" 19\", \"th\", \" January\", \" 2017\", \",\", \" one\", \" of\", \" whom\", \" had\", \" evidence\", \" (\", \"mys\", \"elf\", \")\", \" and\", \" one\", \" who\", \" did\", \" not\", \".\", \" The\", \" Chron\", \"ology\", \" of\", \" Events\", \" provided\", \" by\", \" the\", \" Board\", \" on\", \" 17\", \"th\", \" July\", \" is\", \" economical\", \" with\", \" the\", \" truth\", \".\", \" Specific\", \" examples\", \" that\", \" demonstrate\", \" this\", \" are\", \":\", \"\\n\", \"\\n\", \"The\", \" failure\", \" to\", \" mention\", \" that\", \" I\", \" was\", \" travelling\", \" for\", \" work\", \" when\", \" I\", \" was\", \" unavailable\", \" on\", \" 31\", \"st\", \" May\", \".\", \" This\", \" is\", \" information\", \" the\", \" Board\", \" had\", \" easy\", \" access\", \" to\", \" and\", \" should\", \" have\", \" taken\", \" into\", \" consideration\", \" when\", \" they\", \" proposed\", \" a\", \" date\", \" for\", \" the\", \" hearing\", \".\", \"\\n\", \"\\n\", \"The\", \" inaccurate\", \" description\", \" of\", \" the\", \" process\", \" of\", \" the\", \" giving\", \" of\", \" the\", \" evidence\", \" (\", \"5\", \"th\", \" to\", \" 15\", \"th\", \" June\", \").\", \" See\", \" the\", \" timeline\", \" for\", \" what\", \" actually\", \" trans\", \"pired\", \",\", \" with\", \" an\", \" explanation\", \" for\", \" the\", \" delays\", \".\", \"\\n\", \"\\n\", \"The\", \" inaccurate\", \" description\", \" of\", \" the\", \" process\", \" of\", \" agreeing\", \" upon\", \" the\", \" terms\", \" of\", \" engagement\", \" to\", \" be\", \" used\", \" at\", \" the\", \" inquiry\", \" (\", \"20\", \"th\", \" and\", \" 27\", \"th\", \" June\", \")\", \"\\n\", \"\\n\", \"5\", \"th\", \" July\", \":\", \" At\", \" the\", \" hearing\", \",\", \" the\", \" Board\", \" stated\", \" they\", \" needed\", \" a\", \" week\", \" to\", \" make\", \" their\", \" decision\", \".\", \" This\", \" has\", \" now\", \" been\", \" revised\", \" to\", \" \\u201c\", \"7\", \" working\", \" days\", \" to\", \" communicate\", \" its\", \" decision\", \"\\u201d\", \"\\n\", \"\\n\", \"\\u201c\", \"5\", \"th\", \" July\", \":\", \" The\", \" Board\", \" communic\", \"ates\", \" its\", \" decision\", \" to\", \" send\", \" the\", \" Respondent\", \" on\", \" leave\", \" until\", \" a\", \" decision\", \" is\", \" made\", \".\\u201d\", \" It\", \" is\", \" not\", \" clear\", \" who\", \" they\", \" communicated\", \" that\", \" with\", \".\", \" It\", \" certainly\", \" was\", \" not\", \" to\", \" me\", \" in\", \" the\", \" course\", \" of\", \" the\", \" hearing\", \" nor\", \" to\", \" the\", \" staff\", \" as\", \" I\", \" had\", \" access\", \" to\", \" e\", \"-\", \"mails\", \" until\", \" 10\", \"th\", \" July\", \" and\", \" this\", \" had\", \" definitely\", \" not\", \" been\", \" communicated\", \" to\", \" the\", \" team\", \" by\", \" then\", \".\", \" D\", \"audi\", \" was\", \" first\", \" sent\", \" on\", \" leave\", \" on\", \" 12\", \"th\", \" July\", \" after\", \" significant\"], \"activations\": [[[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[0.0]], [[-0.692922055721283]], [[0.1394808143377304]], [[1.3539646863937378]], [[0.3139209449291229]], [[0.7139630913734436]], [[0.009230808354914188]], [[-0.12648864090442657]], [[-0.09228592365980148]], [[-0.015521340072154999]], [[1.1421141624450684]], [[-0.017110513523221016]], [[-0.02070881612598896]], [[-0.1449316143989563]], [[12.690468788146973]], [[-0.037460338324308395]], [[-0.08382876962423325]], [[0.4962324798107147]], [[2.113030195236206]], [[0.010166492313146591]], [[1.3689870834350586]], [[0.03786745294928551]], [[-0.018189553171396255]], [[0.012414849363267422]], [[0.02699815109372139]], [[1.4374276399612427]], [[-0.028487520292401314]], [[0.19198328256607056]], [[0.26777151226997375]], [[0.08006154000759125]], [[-0.09291830658912659]], [[1.091999888420105]], [[0.5115548968315125]], [[-0.03834125027060509]], [[0.1456463634967804]], [[1.587862491607666]], [[0.10777658224105835]], [[0.08543585240840912]], [[0.0069974446669220924]], [[-0.01554012205451727]], [[-0.03355288878083229]], [[0.0793003961443901]], [[0.14188523590564728]], [[0.00863842573016882]], [[0.04068666324019432]], [[0.02177342399954796]], [[0.18643878400325775]], [[0.5337759256362915]], [[0.0743282213807106]], [[0.032594695687294006]], [[-0.06340011209249496]], [[-0.030949266627430916]], [[0.05443328619003296]], [[0.19424690306186676]], [[0.06780283898115158]], [[-0.08472995460033417]], [[0.10800177603960037]], [[0.4069794714450836]], [[2.848464250564575]], [[0.2216596156358719]], [[0.06991811096668243]], [[0.013072879053652287]], [[-0.01569851115345955]], [[0.2946832478046417]], [[2.0710244178771973]], [[20.80616569519043]], [[-0.02485722117125988]], [[0.38495320081710815]], [[-0.04226506128907204]], [[0.32475224137306213]], [[0.006337180733680725]], [[-0.031914595514535904]], [[0.1472557634115219]], [[-0.08912298083305359]], [[0.19676777720451355]], [[24.63933753967285]], [[-0.012391924858093262]], [[-0.1276128888130188]], [[0.22935816645622253]], [[2.2711191177368164]], [[106.72703552246094]], [[0.12351389974355698]], [[0.019781382754445076]], [[0.6981660723686218]], [[-0.06259511411190033]], [[-0.08801359683275223]], [[0.04640381038188934]], [[0.11435206234455109]], [[0.03220576420426369]], [[-0.12472256273031235]], [[0.6288066506385803]], [[0.2723419666290283]], [[-0.031845781952142715]], [[0.24685323238372803]], [[-0.16612668335437775]], [[8.512643814086914]], [[-0.05731479078531265]], [[0.2805086076259613]], [[-0.17685161530971527]], [[0.12217790633440018]], [[0.032259147614240646]], [[0.162098690867424]], [[0.09941739588975906]], [[0.00707079004496336]], [[-0.1968909353017807]], [[-0.040767379105091095]], [[-0.06748218089342117]], [[0.2639778256416321]], [[-0.11193821579217911]], [[0.2913028299808502]], [[-0.02142348513007164]], [[-0.24932977557182312]], [[7.640841484069824]], [[0.009039012715220451]], [[-0.00029357842868193984]], [[0.03738678619265556]], [[0.2784627676010132]], [[1.0523414611816406]], [[-0.0063992696814239025]], [[-0.07214751094579697]], [[-0.007382062263786793]], [[-0.00192858069203794]], [[1.377361536026001]], [[0.00027695277822203934]], [[0.015858307480812073]], [[-0.028212126344442368]], [[0.545910656452179]], [[0.08803616464138031]], [[0.09578964114189148]], [[0.05997025966644287]], [[0.02980717085301876]], [[0.029987188056111336]], [[-0.0400623194873333]], [[0.14799800515174866]], [[0.8115869760513306]], [[0.0679096058011055]], [[0.12039655447006226]], [[0.07419081032276154]], [[0.3527413308620453]], [[-0.027801720425486565]], [[0.14950226247310638]], [[0.20521961152553558]], [[1.4814459085464478]], [[0.016065629199147224]], [[0.03854268416762352]], [[0.11466766893863678]], [[-0.10211703926324844]], [[0.2763468325138092]], [[-0.09026647359132767]], [[-0.0038808470126241446]], [[1.11020827293396]], [[-0.05055224895477295]], [[0.05507449060678482]], [[0.11603521555662155]], [[-0.04996722564101219]], [[0.08270645886659622]], [[0.03109791688621044]], [[0.012407884001731873]], [[-0.029331324622035027]], [[0.5649387836456299]], [[2.2435171604156494]], [[0.10130474716424942]], [[0.29379943013191223]], [[0.05402372032403946]], [[0.029234526678919792]], [[0.15700042247772217]], [[0.07036823779344559]], [[0.027547989040613174]], [[0.3330066204071045]], [[-0.12599922716617584]], [[0.14393864572048187]], [[0.08750244230031967]], [[0.27982133626937866]], [[0.03242787718772888]], [[-0.05728589743375778]], [[2.179664373397827]], [[8.835044860839844]], [[0.15647464990615845]], [[0.12650538980960846]], [[0.012172725982964039]], [[13.066425323486328]], [[1.351758360862732]], [[0.05886312201619148]], [[24.213314056396484]], [[0.026638668030500412]], [[-0.14450080692768097]], [[-0.08099914342164993]], [[0.04944966360926628]], [[0.014514273032546043]], [[0.03229491412639618]], [[0.010484611615538597]], [[-0.060301773250103]], [[0.13544858992099762]], [[0.008989816531538963]], [[0.10948942601680756]], [[0.02986782416701317]], [[0.11016197502613068]], [[0.40346765518188477]], [[0.0005207794019952416]], [[0.25795069336891174]], [[-0.0304334107786417]], [[-0.030542131513357162]], [[0.04430301859974861]], [[0.01945723220705986]], [[0.014227830804884434]], [[2.9271342754364014]], [[2.213064432144165]], [[4.229737281799316]], [[0.005865916144102812]], [[-0.03435777872800827]], [[2.494816780090332]], [[0.5019642114639282]], [[0.9606508016586304]], [[0.13713400065898895]], [[0.2174127846956253]], [[0.08896888792514801]], [[0.8870977163314819]], [[0.14683692157268524]], [[0.050429463386535645]], [[0.21515406668186188]], [[0.05265692621469498]], [[0.18427544832229614]], [[-0.0103727662935853]], [[0.11648351699113846]], [[0.05457543954253197]], [[-0.09847401827573776]], [[0.5152919292449951]], [[0.05659271776676178]], [[0.24069587886333466]], [[0.061911363154649734]], [[-0.010335002094507217]], [[-0.06293647736310959]], [[8.290911674499512]], [[607.2507934570312]], [[0.10202017426490784]], [[0.1864468902349472]], [[-0.017786230891942978]], [[0.007582433521747589]], [[-0.025959329679608345]], [[-0.06154031306505203]], [[0.35520660877227783]], [[-0.08235999941825867]], [[0.080894835293293]], [[-0.044406890869140625]], [[0.2618919014930725]], [[0.01553037017583847]], [[0.32157087326049805]], [[0.7013058662414551]], [[2.418421745300293]], [[-0.19448275864124298]], [[-0.007912862114608288]], [[-0.03223230689764023]], [[0.012170545756816864]], [[0.10063470155000687]], [[-0.07207754999399185]], [[0.012618404813110828]], [[-0.03869987279176712]], [[-0.0016460857586935163]], [[0.1168896034359932]], [[-0.19106899201869965]], [[0.20546042919158936]], [[0.07309804111719131]], [[0.0807608813047409]], [[-0.008742849342525005]], [[0.05555059015750885]], [[0.005236590281128883]], [[0.46020957827568054]], [[0.2432035356760025]], [[-0.06988471746444702]], [[0.6971365809440613]], [[0.08445503562688828]], [[0.037577055394649506]], [[-0.07247300446033478]], [[2.7760775089263916]], [[0.1589975655078888]], [[0.0764128565788269]], [[0.03831806778907776]], [[0.01533827930688858]], [[0.06388238072395325]], [[0.8631643056869507]], [[0.07654967904090881]], [[0.17932242155075073]], [[-0.09531117230653763]], [[0.2697548270225525]], [[1.5311977863311768]], [[-0.018264872953295708]], [[-0.010474419221282005]], [[0.695898711681366]], [[-0.05810821056365967]], [[-0.13098174333572388]], [[-0.014876676723361015]], [[0.33639657497406006]], [[0.1339881420135498]], [[-0.04213779419660568]], [[0.08645764738321304]], [[0.3869391977787018]], [[0.10328146070241928]], [[0.5060347318649292]], [[0.10060741752386093]], [[1.0362443923950195]], [[-0.07284741848707199]], [[0.03455078601837158]], [[0.004230490420013666]], [[0.14550912380218506]], [[-0.07905097305774689]], [[0.048006150871515274]], [[-0.010257579386234283]], [[0.019015053287148476]], [[-0.0684402659535408]], [[-0.1664603352546692]], [[0.1740642637014389]], [[0.021980134770274162]], [[0.44607874751091003]], [[17.590723037719727]], [[-0.0023106583394110203]], [[-0.023129945620894432]], [[1.8346515893936157]], [[-0.08077944070100784]], [[-0.015379675664007664]], [[0.02645045332610607]], [[0.16083556413650513]], [[-0.0026034542825073004]], [[0.047803327441215515]], [[-0.051584456115961075]], [[0.30392980575561523]], [[0.21721810102462769]], [[0.05709059163928032]], [[0.20387665927410126]], [[0.9291220903396606]], [[0.10363827645778656]], [[-0.13103455305099487]], [[0.27953779697418213]], [[-0.19511835277080536]], [[0.004335086792707443]], [[0.11901529878377914]], [[-0.027945345267653465]], [[0.3430044949054718]], [[0.018364297226071358]], [[0.20894946157932281]], [[0.06934567540884018]], [[-0.014743112958967686]], [[0.804597020149231]], [[-0.10508022457361221]], [[0.6295236349105835]], [[0.010693661868572235]], [[0.0797506645321846]], [[0.012998460792005062]], [[-0.0827484056353569]], [[0.48381897807121277]], [[0.10849148035049438]], [[-0.0969066247344017]], [[0.21905408799648285]], [[0.09903033822774887]], [[-0.047833532094955444]], [[0.12766720354557037]], [[-0.06062838435173035]], [[1.7444723844528198]], [[0.14396370947360992]], [[0.07384423911571503]], [[0.022452887147665024]], [[-0.012518608011305332]], [[-0.12420228123664856]], [[1.2372177839279175]], [[-0.05261309817433357]], [[12.826841354370117]], [[0.0618363656103611]], [[-0.16663463413715363]], [[0.18554992973804474]], [[0.04188607633113861]], [[0.015916302800178528]], [[0.005774121731519699]], [[-0.109305739402771]], [[0.30130717158317566]], [[0.28008967638015747]], [[-0.29604923725128174]], [[-0.013154467567801476]], [[0.13994713127613068]], [[0.24571363627910614]], [[-0.07776238024234772]], [[-0.006953649688512087]], [[0.6053467988967896]], [[0.18707668781280518]], [[-0.11630328744649887]], [[0.016199402511119843]], [[-0.05314747989177704]], [[-0.01655448228120804]], [[0.12212321162223816]], [[0.12759242951869965]], [[-0.004457738250494003]], [[-0.027706529945135117]], [[1.9494237899780273]], [[0.06121530383825302]], [[-0.002255782950669527]], [[0.421186625957489]], [[0.9493203163146973]], [[60.27322769165039]], [[0.13477987051010132]], [[0.03768429905176163]], [[0.25080057978630066]], [[0.026252325624227524]], [[-0.011161252856254578]], [[-0.018207136541604996]], [[0.23201625049114227]], [[0.24954186379909515]], [[-0.05985678732395172]], [[0.775626540184021]], [[-0.022272596135735512]], [[-0.06985027343034744]], [[0.11181598901748657]], [[-0.023803630843758583]], [[-0.042384687811136246]], [[-0.010910994373261929]], [[0.014238497242331505]], [[0.03793324530124664]], [[0.06281189620494843]], [[-0.04825649783015251]], [[1.1827118396759033]], [[-0.22344660758972168]], [[-0.038534797728061676]], [[-0.4758250117301941]], [[-0.10299711674451828]], [[0.09384877979755402]], [[0.08427958190441132]], [[-0.019743693992495537]], [[0.17209264636039734]], [[-0.14859333634376526]], [[0.8491844534873962]], [[0.5749098062515259]], [[-0.08792845904827118]], [[-0.0443757064640522]], [[0.24480938911437988]], [[0.9515911936759949]], [[1.2836908102035522]], [[0.03518564999103546]], [[0.11821401864290237]], [[43.55740737915039]], [[0.0019475900335237384]], [[-0.005247978493571281]], [[-0.013119039125740528]], [[0.0186524149030447]], [[2.340571880340576]], [[-0.28227099776268005]], [[-0.09046521037817001]], [[-0.07187218219041824]], [[1.0814743041992188]], [[-0.11722393333911896]], [[0.062261682003736496]], [[1.2597017288208008]], [[3.0152361392974854]], [[9.013799667358398]], [[0.035249847918748856]], [[-0.05641565099358559]], [[0.16932597756385803]], [[0.08331311494112015]], [[0.11600309610366821]], [[-0.035965997725725174]], [[1.1588177680969238]], [[0.12831145524978638]], [[0.5984728336334229]], [[-0.04122275114059448]], [[0.09477684646844864]], [[-0.08328510820865631]], [[0.8905321359634399]], [[-0.041234854608774185]], [[0.7230151891708374]], [[-0.007075860630720854]], [[-0.10974572598934174]], [[7.45446252822876]], [[1.0382379293441772]], [[3.268479347229004]], [[0.22323431074619293]], [[0.3298015892505646]], [[0.038190536201000214]], [[0.06030271574854851]], [[-0.023416956886649132]], [[1.175399899482727]], [[2.182722330093384]], [[0.016548313200473785]], [[1.7828006744384766]], [[0.01821925677359104]], [[-0.029500143602490425]], [[-0.079059898853302]], [[-0.03824496641755104]], [[-0.006751608103513718]], [[0.3975352644920349]], [[-0.04242902249097824]], [[0.3186275064945221]], [[0.0918891429901123]], [[5.281493663787842]], [[3.0623695850372314]], [[8.64212703704834]], [[-0.016314176842570305]], [[-0.03325144201517105]], [[-0.1930522471666336]], [[0.0031114958692342043]], [[-0.003221963532269001]], [[-0.006796718575060368]], [[-0.14920048415660858]], [[-0.08100759983062744]], [[-0.02614864706993103]], [[0.9563883543014526]], [[0.018717069178819656]], [[-0.0695619136095047]], [[0.1743209809064865]], [[7.915863990783691]], [[-0.03221947327256203]], [[-0.04118525609374046]], [[0.35454171895980835]], [[0.06525623053312302]], [[0.13613417744636536]], [[-0.0018067840719595551]], [[0.09018191695213318]], [[0.10774517059326172]], [[0.12781238555908203]], [[0.056858520954847336]], [[0.06655120104551315]], [[0.01202697679400444]], [[0.2578504681587219]], [[-0.025808025151491165]], [[0.1766543984413147]], [[-0.02089512348175049]], [[-0.017872359603643417]], [[-0.021183909848332405]], [[-0.07107188552618027]], [[0.7479820251464844]], [[0.23477734625339508]], [[-0.015257812105119228]], [[0.12662038207054138]], [[0.5184960961341858]], [[-0.14130941033363342]], [[1.149709701538086]], [[0.415488064289093]], [[-0.06766346096992493]], [[0.0671396404504776]], [[2.455004930496216]], [[-0.10613350570201874]], [[0.2641713619232178]], [[0.051817283034324646]], [[-0.07298794388771057]], [[2.604255199432373]], [[0.019797084853053093]], [[-0.0498858205974102]], [[0.09136400371789932]], [[-0.04265476018190384]], [[0.05306711792945862]], [[0.017020532861351967]], [[1.0275940895080566]], [[-0.11682765930891037]], [[-0.29880955815315247]], [[0.11337143182754517]], [[-0.02755889855325222]], [[0.03382989391684532]], [[-0.009466947056353092]], [[0.43348005414009094]], [[-0.04167971760034561]], [[-0.05425543338060379]], [[0.02142452448606491]], [[-0.056571729481220245]], [[0.00020768833928741515]], [[0.605241596698761]], [[0.021432580426335335]], [[0.2532530725002289]], [[0.08641550689935684]], [[-0.14249657094478607]], [[0.1571536809206009]], [[3.5743227005004883]], [[1.7343522310256958]], [[7.374705791473389]], [[0.04687114804983139]], [[0.12195514142513275]], [[-0.02170361392199993]], [[-0.031393617391586304]], [[0.07652225345373154]], [[0.08676998317241669]], [[-0.052628882229328156]], [[-0.06565719097852707]], [[0.021325916051864624]], [[0.13485810160636902]], [[-0.21490104496479034]], [[-0.033934127539396286]], [[-0.030666934326291084]], [[0.6890276670455933]], [[0.03952552005648613]], [[0.2732654809951782]], [[0.04798661917448044]], [[0.5575226545333862]], [[3.781506299972534]], [[0.2306199073791504]], [[0.3742959797382355]], [[0.20263664424419403]], [[0.10314109176397324]], [[0.3520772457122803]], [[0.33516621589660645]], [[0.17892543971538544]], [[-0.04804663360118866]], [[0.0019322255393490195]], [[-0.21378661692142487]], [[0.0979156643152237]], [[-0.008919929154217243]], [[0.03825636953115463]], [[0.161434143781662]], [[0.8353562951087952]], [[0.028370626270771027]], [[-0.1344843953847885]], [[0.8776257634162903]], [[-0.19011583924293518]], [[-0.07251307368278503]], [[0.0034113016445189714]], [[4.043348789215088]], [[0.0034667428117245436]], [[-0.009443183429539204]], [[1.2754719257354736]], [[-0.01096400897949934]], [[0.11008922755718231]], [[0.00918164849281311]], [[11.152810096740723]], [[0.05144631490111351]], [[1.4309130907058716]], [[1.6810542345046997]], [[0.06569942086935043]], [[-0.09003644436597824]], [[0.8760492205619812]], [[-0.013117752969264984]], [[0.0013366983039304614]], [[0.05132288113236427]], [[0.11174091696739197]], [[0.004807115998119116]], [[0.23067229986190796]], [[0.022635074332356453]], [[2.8824076652526855]], [[0.7051934003829956]], [[0.038763973861932755]], [[-0.0720633715391159]], [[0.21447432041168213]], [[-0.040964074432849884]], [[0.3108532726764679]], [[0.14368446171283722]], [[0.10287071019411087]], [[0.13617055118083954]], [[-0.05616452172398567]], [[-0.01333875022828579]], [[-0.020110802724957466]], [[0.012342115864157677]], [[0.15698567032814026]], [[1.5654215812683105]], [[-0.04553993046283722]], [[-0.057110995054244995]], [[-0.42227011919021606]], [[-0.033612702041864395]], [[-0.026472095400094986]], [[0.8664571642875671]], [[0.05451212450861931]], [[0.023042477667331696]], [[0.8082463145256042]], [[0.21113994717597961]], [[0.10056362301111221]], [[0.451882004737854]], [[0.6953237652778625]], [[1.9551212787628174]], [[11.210925102233887]], [[7.788933277130127]], [[10.641528129577637]], [[0.45813119411468506]], [[-0.13209818303585052]], [[0.09418601542711258]], [[-0.12744006514549255]], [[0.02263582870364189]], [[0.005512826144695282]], [[0.11256909370422363]], [[-0.1537923812866211]], [[0.7010188698768616]], [[0.03404974937438965]], [[0.6449774503707886]], [[0.025191545486450195]], [[0.041350021958351135]], [[0.046129852533340454]], [[0.12777432799339294]], [[-0.027352111414074898]], [[1.0986698865890503]], [[-0.07514718174934387]], [[-0.5389270186424255]], [[4.2846574783325195]], [[0.2739621698856354]], [[6.069341659545898]], [[-0.09323108941316605]], [[0.5092862844467163]], [[0.3998854160308838]], [[-0.008869165554642677]], [[0.16233426332473755]], [[0.0021582383196800947]], [[0.05975288152694702]], [[0.032434310764074326]], [[1.042953372001648]], [[-0.012270323000848293]], [[-0.0833054706454277]], [[-0.04253281280398369]], [[-0.07724719494581223]], [[-0.03449833020567894]], [[-0.05745392665266991]], [[1.4311916828155518]], [[0.3180735409259796]], [[0.6671579480171204]], [[0.17776581645011902]], [[0.4601766765117645]], [[0.3694773316383362]], [[-0.0657731145620346]], [[0.3592517375946045]], [[-0.031840093433856964]], [[0.24014057219028473]], [[0.008877595886588097]], [[-0.014090433716773987]], [[0.0030368759762495756]], [[0.013393083587288857]], [[-0.08670034259557724]], [[0.04626212641596794]], [[6.574100494384766]], [[0.5115795731544495]], [[0.06186886876821518]], [[0.1856120377779007]], [[0.7659780979156494]], [[0.3088524341583252]], [[-0.04732342064380646]], [[0.10736963152885437]], [[-0.034476183354854584]], [[0.026689063757658005]], [[-0.009855504147708416]], [[-0.07497647404670715]], [[-0.1716810166835785]], [[0.27047446370124817]], [[0.09482210874557495]], [[-0.10957112163305283]], [[-0.05812082812190056]], [[10.657919883728027]], [[-0.06474220007658005]], [[-0.008397568948566914]], [[0.867622435092926]], [[0.047986604273319244]], [[-0.12387879937887192]], [[-0.07705309987068176]], [[0.43623849749565125]], [[0.9936229586601257]], [[0.523994505405426]], [[0.026692425832152367]], [[0.08999869972467422]], [[-0.017567772418260574]], [[-0.007900137454271317]], [[2.1321680545806885]], [[0.7896170020103455]], [[-0.00022168357099872082]], [[-0.05988427624106407]], [[0.05696818605065346]], [[0.25723424553871155]], [[1.7502974271774292]], [[0.5105175375938416]], [[0.18738920986652374]], [[-0.0456104539334774]], [[0.7644613981246948]], [[-0.018364738672971725]], [[0.20280155539512634]], [[-0.008626051247119904]], [[0.12564080953598022]], [[1.6169623136520386]], [[1.2966679334640503]], [[0.1238662376999855]], [[0.03628316521644592]], [[0.7634665369987488]], [[0.1180482804775238]], [[0.12441376596689224]], [[-0.02901444025337696]], [[0.1478511542081833]], [[-0.3021303713321686]], [[0.5633994936943054]], [[0.03736450523138046]], [[0.06561236083507538]], [[-0.038961201906204224]], [[0.023418596014380455]], [[0.02076312154531479]], [[0.022832250222563744]], [[0.25089702010154724]], [[0.019232606515288353]], [[-0.20937694609165192]], [[-0.09996155649423599]], [[0.10867232829332352]], [[-0.019193217158317566]], [[0.9065430760383606]], [[0.13994476199150085]], [[0.23447611927986145]], [[0.028716325759887695]], [[0.2836318910121918]], [[0.03549561649560928]], [[0.04071154072880745]], [[0.02890579029917717]], [[0.005330738145858049]], [[-0.06500883400440216]], [[0.18898671865463257]], [[-0.02632724680006504]], [[0.021537579596042633]], [[0.007382209412753582]], [[0.501526415348053]], [[0.05369553342461586]], [[0.009832632727921009]], [[0.018609438091516495]], [[0.24609339237213135]], [[-0.021902110427618027]], [[-0.07239793241024017]], [[0.9478050470352173]], [[0.07639682292938232]], [[-0.0381622239947319]], [[0.7205588817596436]], [[1.2237567901611328]], [[0.044679444283246994]], [[-0.0024724300019443035]], [[0.27635905146598816]], [[0.031748853623867035]], [[0.17894107103347778]], [[-0.15051652491092682]], [[0.0023945923894643784]], [[0.07033037394285202]], [[-0.01573689468204975]], [[-0.021203787997364998]], [[0.1994573026895523]], [[0.21715430915355682]], [[0.52394038438797]], [[0.12890346348285675]], [[0.1890268623828888]], [[0.11516714841127396]], [[0.6357198357582092]], [[0.5249634981155396]], [[0.0567738302052021]], [[0.11567132920026779]], [[0.32788753509521484]], [[-0.018906185403466225]], [[0.05389536917209625]], [[-0.08092671632766724]], [[0.11361691355705261]], [[0.032498203217983246]], [[0.5360881686210632]], [[0.04891413077712059]], [[0.02568681724369526]], [[-0.0640697330236435]], [[-0.020960573107004166]], [[0.23589085042476654]], [[-0.10523317754268646]], [[-0.012746832333505154]], [[1.6769884824752808]], [[-0.026569409295916557]], [[0.19055667519569397]], [[-0.0341469906270504]], [[0.18029795587062836]], [[0.08276621252298355]], [[0.009912337176501751]], [[0.0002557677507866174]], [[0.07056692987680435]], [[-0.22132167220115662]], [[3.1144704818725586]], [[0.14537283778190613]], [[-0.022720759734511375]], [[-0.013467993587255478]], [[0.5542981028556824]], [[0.1722484827041626]], [[-0.06330804526805878]], [[-0.01843138411641121]], [[0.2542232275009155]], [[0.6812398433685303]], [[4.148075580596924]], [[0.6322433948516846]], [[0.1579202115535736]], [[0.39556145668029785]], [[0.8551148176193237]], [[0.01922406069934368]], [[0.060288622975349426]], [[0.32929757237434387]], [[0.07270089536905289]], [[-0.0037817303091287613]], [[-0.012243248522281647]], [[0.19430500268936157]], [[0.4090691804885864]], [[0.021549703553318977]], [[0.03029553033411503]], [[-0.009647702798247337]], [[0.13630039989948273]], [[0.03523596376180649]], [[0.8291325569152832]], [[-0.030535321682691574]], [[0.21127979457378387]], [[-0.027570337057113647]], [[0.5963217616081238]], [[-0.048261307179927826]], [[-0.0021686262916773558]], [[2.1437289714813232]], [[1.165624737739563]], [[-0.13846129179000854]], [[-0.07389359176158905]], [[0.3002346158027649]], [[-0.07463077455759048]], [[0.0252838172018528]], [[0.09672045707702637]], [[0.11327967792749405]], [[0.08560892939567566]], [[0.20009879767894745]], [[-0.03909502178430557]], [[0.5073920488357544]], [[1.0385713577270508]], [[0.7792802453041077]], [[0.3010241985321045]], [[-0.08813074231147766]], [[0.09385578334331512]], [[-0.03106929361820221]], [[0.0644179955124855]], [[0.6420478224754333]], [[-0.045875273644924164]], [[0.03979139029979706]], [[0.46639519929885864]], [[0.008662790060043335]], [[0.0407073087990284]], [[0.02109329216182232]], [[-0.1470772624015808]], [[-0.1436389684677124]], [[-0.04091668501496315]], [[0.540983259677887]], [[-0.009043348953127861]], [[0.03562406823039055]], [[0.01063469611108303]], [[1.0290125608444214]], [[-0.0975939929485321]], [[-0.02208488993346691]], [[0.04520459845662117]], [[1.0674004554748535]], [[-0.011545343324542046]], [[-0.2343926876783371]], [[0.009954448789358139]], [[-0.04590292274951935]], [[0.05487153306603432]], [[0.30418866872787476]], [[0.6168603897094727]], [[0.549708366394043]], [[0.1204274371266365]], [[0.8777681589126587]], [[-0.04295169934630394]], [[6.932394981384277]], [[0.23488013446331024]], [[2.113478899002075]], [[0.1955077350139618]], [[0.08049728721380234]], [[0.2984500825405121]], [[0.052231565117836]], [[0.5905482172966003]], [[0.17732131481170654]], [[0.006634802557528019]], [[0.03711143881082535]], [[0.20810720324516296]], [[0.12015306949615479]], [[0.1447891741991043]], [[0.02963651530444622]], [[0.022475475445389748]], [[0.14194871485233307]], [[-0.10870712995529175]], [[0.32038116455078125]], [[-0.05073447525501251]], [[0.04065892472863197]], [[0.19659173488616943]], [[0.000964872248005122]], [[0.015898507088422775]], [[-0.06665065884590149]], [[0.17610907554626465]], [[-0.05094059929251671]], [[-0.20136341452598572]], [[0.4713696241378784]], [[0.15962496399879456]], [[0.9113941192626953]], [[0.003072359599173069]], [[0.009365887381136417]], [[-0.02304479293525219]], [[2.0394022464752197]], [[0.012787634506821632]], [[0.017476467415690422]], [[-0.009616694413125515]], [[0.07507244497537613]], [[0.543185830116272]], [[-0.2372083067893982]], [[0.061692580580711365]], [[0.05721025541424751]], [[0.14679913222789764]], [[-0.04578537866473198]], [[0.7436856627464294]], [[-0.04978315904736519]], [[1.0124589204788208]], [[0.10385463386774063]], [[0.02271442674100399]], [[0.009741771966218948]], [[0.2847823202610016]], [[-0.18788914382457733]], [[-0.08146944642066956]], [[-0.007851316593587399]], [[0.056123603135347366]], [[-0.016180777922272682]], [[0.3322608172893524]], [[0.4929599165916443]], [[-0.2390439510345459]], [[0.3714948296546936]], [[-0.1690305471420288]], [[0.08508681505918503]], [[0.07496695220470428]], [[0.0723799616098404]], [[0.19520613551139832]], [[-0.07678435742855072]], [[19.847620010375977]], [[0.2519627511501312]], [[0.04423435777425766]], [[-0.06048284471035004]], [[0.2684828042984009]], [[0.15758447349071503]], [[0.17001570761203766]], [[-0.021614789962768555]], [[1.1580713987350464]], [[0.07391782104969025]], [[-0.02069988287985325]], [[-0.007484009489417076]]], \"firstDimensionName\": \"Layer (resid_pre)\", \"secondDimensionName\": \"Model\", \"secondDimensionLabels\": [\"pythia-2.8b\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7fa986417af0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_neuroscope(batch_tokens[11], activations=loss_change_by_token[11].unsqueeze(1).unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(607.2508, device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_change_by_token[11].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_change_by_token[11].unsqueeze(1).unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   604, 40537,  ...,  4163,   846,  1534]], device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens[11].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
