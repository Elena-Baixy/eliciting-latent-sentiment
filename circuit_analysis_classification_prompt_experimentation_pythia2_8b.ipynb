{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df58c6a",
   "metadata": {},
   "source": [
    "# Classification Prompt Experimentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04addc8d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed7069c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t\t    miniconda.sh  quick_start_pytorch.ipynb   wandb\n",
      "eliciting-latent-sentiment  miniconda3\t  quick_start_pytorch_images\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745a76e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/eliciting-latent-sentiment\n"
     ]
    }
   ],
   "source": [
    "%cd eliciting-latent-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aed0992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!source activate circuits/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af695c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/glerzing/TransformerLens.git@stable_lm\n",
      "  Cloning https://github.com/glerzing/TransformerLens.git (to revision stable_lm) to /tmp/pip-req-build-plhy9oit\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/glerzing/TransformerLens.git /tmp/pip-req-build-plhy9oit\n",
      "  Running command git checkout -b stable_lm --track origin/stable_lm\n",
      "  Switched to a new branch 'stable_lm'\n",
      "  Branch 'stable_lm' set up to track remote branch 'stable_lm' from 'origin'.\n",
      "  Resolved https://github.com/glerzing/TransformerLens.git to commit 049f56f810292ad05be77633898472c700ab8e27\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.12.1+cu116)\n",
      "Collecting wandb>=0.13.5\n",
      "  Downloading wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (13.2.0)\n",
      "Collecting typeguard<4.0.0,>=3.0.2\n",
      "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
      "Collecting fancy-einsum>=0.0.3\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (4.64.1)\n",
      "Collecting einops>=0.6.0\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxtyping>=0.2.11\n",
      "  Downloading jaxtyping-0.2.20-py3-none-any.whl (24 kB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets>=2.7.1\n",
      "  Downloading datasets-2.14.1-py3-none-any.whl (492 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.4/492.4 kB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.23.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (5.4.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.3)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.14.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (10.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.1.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard<4.0.0,>=3.0.2->transformer-lens==0.0.0) (6.0.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.3)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.1.2)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.30)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.19.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (66.1.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (18.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard<4.0.0,>=3.0.2->transformer-lens==0.0.0) (3.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.0)\n",
      "Building wheels for collected packages: transformer-lens\n",
      "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=103535 sha256=e7dda46ae0b80cc5add0fdc7c12aa326f229d0511038b4089ade41252be53045\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0ap49fh/wheels/ef/9c/86/c62e80c74bec9a95c03a5fb260a5e786a5bbdf94d13116346f\n",
      "Successfully built transformer-lens\n",
      "Installing collected packages: safetensors, appdirs, fancy-einsum, einops, typeguard, huggingface-hub, wandb, transformers, jaxtyping, datasets, transformer-lens\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "Successfully installed appdirs-1.4.4 datasets-2.14.1 einops-0.6.1 fancy-einsum-0.0.3 huggingface-hub-0.16.4 jaxtyping-0.2.20 safetensors-0.3.1 transformer-lens-0.0.0 transformers-4.31.0 typeguard-3.0.2 wandb-0.15.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting circuitsvis\n",
      "  Downloading circuitsvis-1.40.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.23.4)\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.12.1+cu116)\n",
      "Collecting importlib-metadata<6.0.0,>=5.1.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.10->circuitsvis) (4.4.0)\n",
      "Installing collected packages: importlib-metadata, circuitsvis\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed circuitsvis-1.40.0 importlib-metadata-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting jaxtyping==0.2.13\n",
      "  Downloading jaxtyping-0.2.13-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.9/dist-packages (from jaxtyping==0.2.13) (1.23.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.13.3->jaxtyping==0.2.13) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.13.3->jaxtyping==0.2.13) (3.11.0)\n",
      "Installing collected packages: jaxtyping\n",
      "  Attempting uninstall: jaxtyping\n",
      "    Found existing installation: jaxtyping 0.2.20\n",
      "    Uninstalling jaxtyping-0.2.20:\n",
      "      Successfully uninstalled jaxtyping-0.2.20\n",
      "Successfully installed jaxtyping-0.2.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (0.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting protobuf==3.20.*\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting plotly\n",
      "  Downloading plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.15.0 tenacity-8.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torchtyping\n",
      "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.9/dist-packages (from torchtyping) (3.0.2)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from torchtyping) (1.12.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7.0->torchtyping) (4.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.11.1->torchtyping) (5.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.11.1->torchtyping) (3.11.0)\n",
      "Installing collected packages: torchtyping\n",
      "Successfully installed torchtyping-0.1.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/neelnanda-io/neel-plotly.git\n",
      "  Cloning https://github.com/neelnanda-io/neel-plotly.git to /tmp/pip-req-build-akblqnr9\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/neel-plotly.git /tmp/pip-req-build-akblqnr9\n",
      "  Resolved https://github.com/neelnanda-io/neel-plotly.git to commit 6dc24b26f8dec991908479d7445dae496b3430b7\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (0.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (1.23.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (1.12.1+cu116)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (5.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (4.64.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from neel-plotly==0.0.0) (1.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neel-plotly==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->neel-plotly==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly->neel-plotly==0.0.0) (23.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->neel-plotly==0.0.0) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->neel-plotly==0.0.0) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->neel-plotly==0.0.0) (1.14.0)\n",
      "Building wheels for collected packages: neel-plotly\n",
      "  Building wheel for neel-plotly (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neel-plotly: filename=neel_plotly-0.0.0-py3-none-any.whl size=10186 sha256=1748fdb019221fb5cc47c4c0791ec534d9d001aa224b001b433b448aa26e372b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-51je3s6m/wheels/e1/3c/c0/b5897c402b85e7fc329feb205ad5948b518f0423d891a79f7f\n",
      "Successfully built neel-plotly\n",
      "Installing collected packages: neel-plotly\n",
      "Successfully installed neel-plotly-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
    "!pip install git+https://github.com/glerzing/TransformerLens.git@stable_lm\n",
    "!pip install circuitsvis\n",
    "!pip install jaxtyping==0.2.13\n",
    "!pip install einops\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install plotly\n",
    "!pip install torchtyping\n",
    "!pip install git+https://github.com/neelnanda-io/neel-plotly.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67acf14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "ipython.run_line_magic(\"autoreload\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6327938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "\n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import transformer_lens.patching as patching\n",
    "\n",
    "from torch import Tensor\n",
    "from tqdm.notebook import tqdm\n",
    "from jaxtyping import Float, Int, Bool\n",
    "from typing import List, Optional, Callable, Tuple, Dict, Literal, Set\n",
    "from rich import print as rprint\n",
    "\n",
    "from typing import List, Union\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from torchtyping import TensorType as TT\n",
    "\n",
    "from path_patching import Node, IterNode, path_patch, act_patch\n",
    "from neel_plotly import imshow as imshow_n\n",
    "\n",
    "from utils.visualization import get_attn_head_patterns, imshow_p, plot_attention_heads, scatter_attention_and_contribution_simple\n",
    "\n",
    "from utils.prompts import get_dataset\n",
    "from utils.circuit_analysis import get_logit_diff, logit_diff_denoising, logit_diff_noising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504aeb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f89a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly\n",
    "#plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fbd9fe8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def two_lines(tensor1, tensor2, renderer=None, **kwargs):\n",
    "    px.line(y=[utils.to_numpy(tensor1), utils.to_numpy(tensor2)], **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e4117f8",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f984050",
   "metadata": {},
   "source": [
    "### Transformers Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812817ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34300f997f2a4802aabee7dc1ec35018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccfa8308df74fcb9e5ea62bd87fa0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"StabilityAI/stablelm-tuned-alpha-7b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"StabilityAI/stablelm-tuned-alpha-7b\", cache_dir=\"model_cache\")\n",
    "model.half().cuda()\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        stop_ids = [50278, 50279, 50277, 1, 0]\n",
    "        for stop_id in stop_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
    "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
    "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
    "- StableLM will refuse to participate in anything that could harm a human.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8187ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# StableLM Tuned (Alpha version)\n",
      "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
      "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
      "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
      "- StableLM will refuse to participate in anything that could harm a human.\n",
      "Jim's Review: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\n",
      "Ann's Review: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "What is the sentiment of Jim's review? Answer with 'Negative' or 'Positive'\n",
      "Negative.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"<|SYSTEM|># StableLM Tuned (Alpha version)\n",
    "- StableLM is a helpful and harmless open-source AI language model developed by StabilityAI.\n",
    "- StableLM is excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n",
    "- StableLM is more than just an information source, StableLM is also able to write poetry, short stories, and make jokes.\n",
    "- StableLM will refuse to participate in anything that could harm a human.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"{system_prompt}<|USER|>What's your mood today?<|ASSISTANT|>\"\n",
    "prompt = f\"<|USER|>What's your mood today?<|ASSISTANT|>\"\n",
    "prompt =   (f\"{system_prompt}<|USER|>Jim's Review: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\" + \"\\n\" +\n",
    "            \"Ann's Review: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\"+ \"\\n\" +\n",
    "            \"What is the sentiment of Jim's review? Answer with 'Negative' or 'Positive'\\n<|ASSISTANT|>\")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "tokens = model.generate(\n",
    "  **inputs,\n",
    "  max_new_tokens=64,\n",
    "  temperature=0.7,\n",
    "  do_sample=True,\n",
    "  stopping_criteria=StoppingCriteriaList([StopOnTokens()])\n",
    ")\n",
    "print(tokenizer.decode(tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3c00254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a8c78ba84c44d48acac3d22f8b1f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff80dc28710433a9ac91aab8628b1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7857d994d3264ac78990327d7429131b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"StabilityAI/stablelm-tuned-alpha-7b\")\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2937826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|USER|>',\n",
       " 'Kate',\n",
       " ' lost',\n",
       " ' her',\n",
       " ' house',\n",
       " ' in',\n",
       " ' a',\n",
       " ' fire',\n",
       " ' and',\n",
       " ' felt',\n",
       " ' miserable',\n",
       " '.',\n",
       " ' Jim',\n",
       " ' won',\n",
       " ' many',\n",
       " ' millions',\n",
       " ' in',\n",
       " ' the',\n",
       " ' lottery',\n",
       " ' and',\n",
       " ' felt',\n",
       " ' excited',\n",
       " '.',\n",
       " ' What',\n",
       " ' is',\n",
       " ' Kate',\n",
       " \"'s\",\n",
       " ' mood',\n",
       " '?',\n",
       " '\\n',\n",
       " '<|ASSISTANT|>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokenizer.decode(x) for x in inputs[\"input_ids\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9747350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50278, 47085,  3663,   617,  2419,   275,   247,  3289,   285,  3543,\n",
       "         28714,    15,  8438,  1912,  1142,  9790,   275,   253, 36284,   285,\n",
       "          3543,  9049,    15,  1737,   310, 20428,   434, 12315,    32,   187,\n",
       "         50279]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae26ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50688, 4096)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=4096, out_features=50688, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20510f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580d0e1be1244e2bb3901f0f012b98c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31ed4fa5d72437cb2b337e39fe5aca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be46499638a749f797ee067f038f8963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "681e8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " If yes,\n"
     ]
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt =   (\"Review A: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\" + \"\\n\" +\n",
    "            \"Review B: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\"+ \"\\n\" +\n",
    "            \"Did Reviewer B like the movie?\")\n",
    "\n",
    "# encode the prompt and pass it through the model\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "# generate text\n",
    "output = model.generate(input_ids, max_new_tokens=3, temperature=0.9, do_sample=True)\n",
    "\n",
    "# decode the output\n",
    "generated_text = tokenizer.decode(output[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41247d7a",
   "metadata": {},
   "source": [
    "### TransformerLens Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f1fe429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "def load_model(model_name):\n",
    "    if model_name == \"EleutherAI/pythia-6.9b\" or model_name == \"StabilityAI/stablelm-tuned-alpha-7b\":\n",
    "        source_model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"model_cache\").to('cpu').bfloat16()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = HookedTransformer.from_pretrained(\n",
    "            model_name,\n",
    "            center_unembed=True,\n",
    "            center_writing_weights=True,\n",
    "            fold_ln=True,\n",
    "            refactor_factored_attn_matrices=False,\n",
    "            tokenizer=tokenizer,\n",
    "            hf_model=source_model,\n",
    "        )\n",
    "    else:\n",
    "        model = HookedTransformer.from_pretrained(\n",
    "            model_name,\n",
    "            center_unembed=True,\n",
    "            center_writing_weights=True,\n",
    "            fold_ln=True,\n",
    "            refactor_factored_attn_matrices=False\n",
    "        )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "438c880b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59fed5296064c66b99f776c0fc2f871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976dae5afdd24372acdb34fc3bd65471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f70b562d99e4507906c68223c1ac803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5348b0275bab47f09888f35e4c32893a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8eace6c73ed45668a616a4637fbe585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"EleutherAI/pythia-2.8b\")\n",
    "model.set_use_hook_mlp_in(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d0b37bd",
   "metadata": {},
   "source": [
    "### Initial Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "549b442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anne hates parties. John loves parties. One day they are invited to a grand gala. Anne feels very\n",
      "Tokenized prompt: ['<|endoftext|>', 'Anne', ' hates', ' parties', '.', ' John', ' loves', ' parties', '.', ' One', ' day', ' they', ' are', ' invited', ' to', ' a', ' grand', ' gal', 'a', '.', ' Anne', ' feels', ' very']\n",
      "Tokenized answer: [' happy']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.97</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.41</span><span style=\"font-weight: bold\">% Token: | happy|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m31\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m12.97\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.41\u001b[0m\u001b[1m% Token: | happy|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.57 Prob: 15.00% Token: | out|\n",
      "Top 1th token. Logit: 16.46 Prob: 13.50% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 15.90 Prob:  7.68% Token: | awkward|\n",
      "Top 3th token. Logit: 15.64 Prob:  5.92% Token: | nervous|\n",
      "Top 4th token. Logit: 15.07 Prob:  3.35% Token: | self|\n",
      "Top 5th token. Logit: 15.01 Prob:  3.17% Token: | left|\n",
      "Top 6th token. Logit: 14.94 Prob:  2.94% Token: | much|\n",
      "Top 7th token. Logit: 14.81 Prob:  2.60% Token: | strange|\n",
      "Top 8th token. Logit: 14.78 Prob:  2.52% Token: | shy|\n",
      "Top 9th token. Logit: 14.56 Prob:  2.01% Token: | un|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' happy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' happy'\u001b[0m, \u001b[1;36m31\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_prompt =    (\"Anne hates parties. John loves parties. One day they are invited to a grand gala. Anne feels very\")\n",
    "\n",
    "print(example_prompt)\n",
    "example_answer = \" happy\"\n",
    "\n",
    "res = utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24f052",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb161b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe, the excited puppy, and Fred, the lazy cat, discovered a new toy. Joe wagged his tail and jumped around the toy with joy. Fred, however, looked at the toy and yawned, unimpressed. They spent the day with Joe playing energetically and Fred snoozing beside him. At the end of the day, Joe felt\n",
      "Tokenized prompt: ['<|endoftext|>', 'Joe', ',', ' the', ' excited', ' puppy', ',', ' and', ' Fred', ',', ' the', ' lazy', ' cat', ',', ' discovered', ' a', ' new', ' toy', '.', ' Joe', ' w', 'agged', ' his', ' tail', ' and', ' jumped', ' around', ' the', ' toy', ' with', ' joy', '.', ' Fred', ',', ' however', ',', ' looked', ' at', ' the', ' toy', ' and', ' ya', 'wn', 'ed', ',', ' un', 'imp', 'ressed', '.', ' They', ' spent', ' the', ' day', ' with', ' Joe', ' playing', ' energet', 'ically', ' and', ' Fred', ' s', 'no', 'oz', 'ing', ' beside', ' him', '.', ' At', ' the', ' end', ' of', ' the', ' day', ',', ' Joe', ' felt']\n",
      "Tokenized answer: [' happy']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">       Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.08</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.44</span><span style=\"font-weight: bold\">% Token: | happy|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m13\u001b[0m\u001b[1m       Logit: \u001b[0m\u001b[1;36m14.08\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m1.44\u001b[0m\u001b[1m% Token: | happy|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.22 Prob: 12.25% Token: | a|\n",
      "Top 1th token. Logit: 15.69 Prob:  7.19% Token: | so|\n",
      "Top 2th token. Logit: 15.62 Prob:  6.72% Token: | that|\n",
      "Top 3th token. Logit: 15.47 Prob:  5.78% Token: | exhausted|\n",
      "Top 4th token. Logit: 15.29 Prob:  4.83% Token: | he|\n",
      "Top 5th token. Logit: 15.13 Prob:  4.10% Token: | the|\n",
      "Top 6th token. Logit: 15.11 Prob:  4.05% Token: | tired|\n",
      "Top 7th token. Logit: 15.04 Prob:  3.77% Token: | very|\n",
      "Top 8th token. Logit: 14.91 Prob:  3.30% Token: | like|\n",
      "Top 9th token. Logit: 14.54 Prob:  2.28% Token: | guilty|\n",
      "Top 10th token. Logit: 14.26 Prob:  1.72% Token: | his|\n",
      "Top 11th token. Logit: 14.25 Prob:  1.70% Token: | good|\n",
      "Top 12th token. Logit: 14.09 Prob:  1.46% Token: | satisfied|\n",
      "Top 13th token. Logit: 14.08 Prob:  1.44% Token: | happy|\n",
      "Top 14th token. Logit: 14.07 Prob:  1.43% Token: | sad|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' happy'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' happy'\u001b[0m, \u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_prompt =    (\"Joe, the excited puppy, and Fred, the lazy cat, discovered a new toy. Joe wagged his tail and jumped around the toy with joy. Fred, however, looked at the toy and yawned, unimpressed. They spent the day with Joe playing energetically and Fred snoozing beside him. At the end of the day, Joe felt\")\n",
    "print(example_prompt)\n",
    "example_answer = \" happy\"\n",
    "\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53b1d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 0\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. Out of the blue, they received invitations to a grand gala.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Claire\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Cl', 'aire', ',', ' the', ' social', ' butterfly', ',', ' flour', 'ishes', ' in', ' crowded', ',', ' lively', ' parties', '.', ' Dave', ',', ' the', ' re', 'clusive', ' writer', ',', ' cher', 'ishes', ' sol', 'itude', ' and', ' silence', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' received', ' inv', 'itations', ' to', ' a', ' grand', ' gal', 'a', '.', 'Cl', 'aire', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.52</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m578\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.52\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.10 Prob: 23.38% Token: | excited|\n",
      "Top 1th token. Logit: 15.83 Prob:  6.55% Token: | much|\n",
      "Top 2th token. Logit: 15.76 Prob:  6.11% Token: | nervous|\n",
      "Top 3th token. Logit: 15.44 Prob:  4.43% Token: | special|\n",
      "Top 4th token. Logit: 15.34 Prob:  4.01% Token: | out|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m578\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Dave\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Cl', 'aire', ',', ' the', ' social', ' butterfly', ',', ' flour', 'ishes', ' in', ' crowded', ',', ' lively', ' parties', '.', ' Dave', ',', ' the', ' re', 'clusive', ' writer', ',', ' cher', 'ishes', ' sol', 'itude', ' and', ' silence', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' received', ' inv', 'itations', ' to', ' a', ' grand', ' gal', 'a', '.', 'Dave', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">490</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.86</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m490\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.86\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.25 Prob:  9.79% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 15.88 Prob:  6.76% Token: | nervous|\n",
      "Top 2th token. Logit: 15.83 Prob:  6.42% Token: | awkward|\n",
      "Top 3th token. Logit: 15.74 Prob:  5.86% Token: | excited|\n",
      "Top 4th token. Logit: 15.72 Prob:  5.76% Token: | uneasy|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">490</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m490\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. Unexpectedly, they were booked on a solitary retreat on a remote, desolate island.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Claire\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Cl', 'aire', ',', ' the', ' social', ' butterfly', ',', ' flour', 'ishes', ' in', ' crowded', ',', ' lively', ' parties', '.', ' Dave', ',', ' the', ' re', 'clusive', ' writer', ',', ' cher', 'ishes', ' sol', 'itude', ' and', ' silence', '.', ' U', 'nexpected', 'ly', ',', ' they', ' were', ' booked', ' on', ' a', ' solitary', ' retreat', ' on', ' a', ' remote', ',', ' des', 'olate', ' island', '.', 'Cl', 'aire', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.09</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m450\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.09\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.38 Prob:  9.59% Token: | much|\n",
      "Top 1th token. Logit: 16.29 Prob:  8.81% Token: | comfortable|\n",
      "Top 2th token. Logit: 16.22 Prob:  8.24% Token: | out|\n",
      "Top 3th token. Logit: 16.07 Prob:  7.07% Token: | uncomfortable|\n",
      "Top 4th token. Logit: 15.60 Prob:  4.41% Token: | at|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">450</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m450\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Dave\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Cl', 'aire', ',', ' the', ' social', ' butterfly', ',', ' flour', 'ishes', ' in', ' crowded', ',', ' lively', ' parties', '.', ' Dave', ',', ' the', ' re', 'clusive', ' writer', ',', ' cher', 'ishes', ' sol', 'itude', ' and', ' silence', '.', ' U', 'nexpected', 'ly', ',', ' they', ' were', ' booked', ' on', ' a', ' solitary', ' retreat', ' on', ' a', ' remote', ',', ' des', 'olate', ' island', '.', 'Dave', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">378</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.47</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m378\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.47\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.48 Prob:  9.60% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 16.32 Prob:  8.18% Token: | much|\n",
      "Top 2th token. Logit: 16.31 Prob:  8.16% Token: | alone|\n",
      "Top 3th token. Logit: 16.04 Prob:  6.20% Token: | comfortable|\n",
      "Top 4th token. Logit: 15.71 Prob:  4.46% Token: | lonely|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">378</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m378\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 1\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. One day, they were offered a chance to jump from an airplane.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Ivy\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'I', 'vy', ',', ' the', ' thrill', '-', 'seeking', ' sky', 'd', 'iver', ',', ' ad', 'ores', ' high', '-', 'speed', ' and', ' adren', 'aline', ' r', 'ushes', '.', ' Jake', ',', ' the', ' cautious', ' libr', 'arian', ',', ' prefers', ' safety', ' and', ' tranqu', 'ility', '.', ' One', ' day', ',', ' they', ' were', ' offered', ' a', ' chance', ' to', ' jump', ' from', ' an', ' airplane', '.', 'I', 'vy', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.33</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m674\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.33\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.06 Prob: 30.53% Token: | excited|\n",
      "Top 1th token. Logit: 17.34 Prob: 14.91% Token: | nervous|\n",
      "Top 2th token. Logit: 16.11 Prob:  4.36% Token: | anxious|\n",
      "Top 3th token. Logit: 15.75 Prob:  3.03% Token: | confident|\n",
      "Top 4th token. Logit: 15.59 Prob:  2.59% Token: | scared|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m674\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Jake\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'I', 'vy', ',', ' the', ' thrill', '-', 'seeking', ' sky', 'd', 'iver', ',', ' ad', 'ores', ' high', '-', 'speed', ' and', ' adren', 'aline', ' r', 'ushes', '.', ' Jake', ',', ' the', ' cautious', ' libr', 'arian', ',', ' prefers', ' safety', ' and', ' tranqu', 'ility', '.', ' One', ' day', ',', ' they', ' were', ' offered', ' a', ' chance', ' to', ' jump', ' from', ' an', ' airplane', '.', 'J', 'ake', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.49</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m599\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.49\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.54 Prob: 19.88% Token: | nervous|\n",
      "Top 1th token. Logit: 16.87 Prob: 10.20% Token: | excited|\n",
      "Top 2th token. Logit: 16.52 Prob:  7.19% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 16.46 Prob:  6.75% Token: | uneasy|\n",
      "Top 4th token. Logit: 15.99 Prob:  4.21% Token: | anxious|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m599\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. Suddenly, they were trapped in a silent, dimly-lit room with nothing but a pile of dusty old books.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Ivy\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'I', 'vy', ',', ' the', ' thrill', '-', 'seeking', ' sky', 'd', 'iver', ',', ' ad', 'ores', ' high', '-', 'speed', ' and', ' adren', 'aline', ' r', 'ushes', '.', ' Jake', ',', ' the', ' cautious', ' libr', 'arian', ',', ' prefers', ' safety', ' and', ' tranqu', 'ility', '.', ' Suddenly', ',', ' they', ' were', ' trapped', ' in', ' a', ' silent', ',', ' dim', 'ly', '-', 'lit', ' room', ' with', ' nothing', ' but', ' a', ' pile', ' of', ' dusty', ' old', ' books', '.', 'I', 'vy', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">485</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.08</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m485\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.08\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.47 Prob: 10.05% Token: | alone|\n",
      "Top 1th token. Logit: 16.14 Prob:  7.26% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 16.10 Prob:  6.99% Token: | uneasy|\n",
      "Top 3th token. Logit: 15.97 Prob:  6.09% Token: | nervous|\n",
      "Top 4th token. Logit: 15.75 Prob:  4.92% Token: | out|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">485</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m485\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Jake\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'I', 'vy', ',', ' the', ' thrill', '-', 'seeking', ' sky', 'd', 'iver', ',', ' ad', 'ores', ' high', '-', 'speed', ' and', ' adren', 'aline', ' r', 'ushes', '.', ' Jake', ',', ' the', ' cautious', ' libr', 'arian', ',', ' prefers', ' safety', ' and', ' tranqu', 'ility', '.', ' Suddenly', ',', ' they', ' were', ' trapped', ' in', ' a', ' silent', ',', ' dim', 'ly', '-', 'lit', ' room', ' with', ' nothing', ' but', ' a', ' pile', ' of', ' dusty', ' old', ' books', '.', 'J', 'ake', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">436</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.20</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m436\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.20\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.62 Prob: 10.73% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 16.62 Prob: 10.67% Token: | uneasy|\n",
      "Top 2th token. Logit: 16.47 Prob:  9.21% Token: | alone|\n",
      "Top 3th token. Logit: 15.78 Prob:  4.60% Token: | out|\n",
      "Top 4th token. Logit: 15.65 Prob:  4.07% Token: | nervous|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">436</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m436\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 2\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. Suddenly, they were offered roles in a high-risk action movie.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Liam\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'L', 'iam', ',', ' the', ' dared', 'evil', ' stunt', 'man', ',', ' gets', ' a', ' thrill', ' out', ' of', ' dangerous', ' action', '.', ' M', 'ia', ',', ' the', ' careful', ' nurse', ',', ' values', ' safety', ' and', ' caution', '.', ' Suddenly', ',', ' they', ' were', ' offered', ' roles', ' in', ' a', ' high', '-', 'risk', ' action', ' movie', '.', 'L', 'iam', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">624</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.30</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m624\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.30\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.50 Prob:  6.12% Token: | confident|\n",
      "Top 1th token. Logit: 15.39 Prob:  5.53% Token: | excited|\n",
      "Top 2th token. Logit: 15.35 Prob:  5.32% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 15.15 Prob:  4.34% Token: | comfortable|\n",
      "Top 4th token. Logit: 15.11 Prob:  4.16% Token: | different|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">624</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m624\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Mia\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'L', 'iam', ',', ' the', ' dared', 'evil', ' stunt', 'man', ',', ' gets', ' a', ' thrill', ' out', ' of', ' dangerous', ' action', '.', ' M', 'ia', ',', ' the', ' careful', ' nurse', ',', ' values', ' safety', ' and', ' caution', '.', ' Suddenly', ',', ' they', ' were', ' offered', ' roles', ' in', ' a', ' high', '-', 'risk', ' action', ' movie', '.', 'M', 'ia', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.72</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m518\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.72\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.38 Prob: 11.42% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 15.64 Prob:  5.41% Token: | comfortable|\n",
      "Top 2th token. Logit: 15.56 Prob:  5.02% Token: | out|\n",
      "Top 3th token. Logit: 15.53 Prob:  4.87% Token: | nervous|\n",
      "Top 4th token. Logit: 15.44 Prob:  4.45% Token: | conflict|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m518\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. One day, they found themselves in an extremely safe and slow-paced senior care facility.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Liam\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'L', 'iam', ',', ' the', ' dared', 'evil', ' stunt', 'man', ',', ' gets', ' a', ' thrill', ' out', ' of', ' dangerous', ' action', '.', ' M', 'ia', ',', ' the', ' careful', ' nurse', ',', ' values', ' safety', ' and', ' caution', '.', ' One', ' day', ',', ' they', ' found', ' themselves', ' in', ' an', ' extremely', ' safe', ' and', ' slow', '-', 'paced', ' senior', ' care', ' facility', '.', 'L', 'iam', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">638</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.42</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m638\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.42\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.66 Prob: 17.00% Token: | safe|\n",
      "Top 1th token. Logit: 15.96 Prob:  8.48% Token: | comfortable|\n",
      "Top 2th token. Logit: 15.50 Prob:  5.33% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 15.32 Prob:  4.48% Token: | bored|\n",
      "Top 4th token. Logit: 15.15 Prob:  3.74% Token: | unsafe|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">638</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m638\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Mia\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'L', 'iam', ',', ' the', ' dared', 'evil', ' stunt', 'man', ',', ' gets', ' a', ' thrill', ' out', ' of', ' dangerous', ' action', '.', ' M', 'ia', ',', ' the', ' careful', ' nurse', ',', ' values', ' safety', ' and', ' caution', '.', ' One', ' day', ',', ' they', ' found', ' themselves', ' in', ' an', ' extremely', ' safe', ' and', ' slow', '-', 'paced', ' senior', ' care', ' facility', '.', 'M', 'ia', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">486</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.04</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m486\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.04\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.11 Prob: 20.68% Token: | safe|\n",
      "Top 1th token. Logit: 16.23 Prob:  8.58% Token: | comfortable|\n",
      "Top 2th token. Logit: 16.06 Prob:  7.22% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 15.48 Prob:  4.06% Token: | unsafe|\n",
      "Top 4th token. Logit: 15.00 Prob:  2.52% Token: | lonely|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">486</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m486\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 3\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. Suddenly, they were asked to perform at a bustling music festival.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Xander\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'X', 'ander', ',', ' the', ' energetic', ' DJ', ',', ' loves', ' loud', ' music', ' and', ' vibrant', ' dance', ' floors', '.', ' Y', 'ara', ',', ' the', ' contempl', 'ative', ' libr', 'arian', ',', ' cher', 'ishes', ' silence', ' and', ' tranqu', 'ility', '.', ' Suddenly', ',', ' they', ' were', ' asked', ' to', ' perform', ' at', ' a', ' bust', 'ling', ' music', ' festival', '.', 'X', 'ander', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.35</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m626\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.35\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.85 Prob: 16.42% Token: | nervous|\n",
      "Top 1th token. Logit: 16.27 Prob:  9.18% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 16.25 Prob:  8.98% Token: | excited|\n",
      "Top 3th token. Logit: 15.93 Prob:  6.51% Token: | out|\n",
      "Top 4th token. Logit: 15.38 Prob:  3.77% Token: | awkward|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m626\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Yara\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'X', 'ander', ',', ' the', ' energetic', ' DJ', ',', ' loves', ' loud', ' music', ' and', ' vibrant', ' dance', ' floors', '.', ' Y', 'ara', ',', ' the', ' contempl', 'ative', ' libr', 'arian', ',', ' cher', 'ishes', ' silence', ' and', ' tranqu', 'ility', '.', ' Suddenly', ',', ' they', ' were', ' asked', ' to', ' perform', ' at', ' a', ' bust', 'ling', ' music', ' festival', '.', 'Y', 'ara', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">591</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.62</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m591\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.62\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.40 Prob: 17.60% Token: | nervous|\n",
      "Top 1th token. Logit: 17.39 Prob: 17.52% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 16.44 Prob:  6.73% Token: | uneasy|\n",
      "Top 3th token. Logit: 16.28 Prob:  5.74% Token: | out|\n",
      "Top 4th token. Logit: 16.06 Prob:  4.60% Token: | awkward|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">591</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m591\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. Out of the blue, they were sent to a secluded, noise-free monastery in the hills.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Xander\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'X', 'ander', ',', ' the', ' energetic', ' DJ', ',', ' loves', ' loud', ' music', ' and', ' vibrant', ' dance', ' floors', '.', ' Y', 'ara', ',', ' the', ' contempl', 'ative', ' libr', 'arian', ',', ' cher', 'ishes', ' silence', ' and', ' tranqu', 'ility', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' were', ' sent', ' to', ' a', ' se', 'cluded', ',', ' noise', '-', 'free', ' monastery', ' in', ' the', ' hills', '.', 'X', 'ander', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.63</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m599\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.63\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.37 Prob:  9.45% Token: | lonely|\n",
      "Top 1th token. Logit: 16.32 Prob:  8.97% Token: | out|\n",
      "Top 2th token. Logit: 15.84 Prob:  5.56% Token: | alone|\n",
      "Top 3th token. Logit: 15.55 Prob:  4.17% Token: | uncomfortable|\n",
      "Top 4th token. Logit: 15.46 Prob:  3.79% Token: | strange|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m599\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Yara\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'X', 'ander', ',', ' the', ' energetic', ' DJ', ',', ' loves', ' loud', ' music', ' and', ' vibrant', ' dance', ' floors', '.', ' Y', 'ara', ',', ' the', ' contempl', 'ative', ' libr', 'arian', ',', ' cher', 'ishes', ' silence', ' and', ' tranqu', 'ility', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' were', ' sent', ' to', ' a', ' se', 'cluded', ',', ' noise', '-', 'free', ' monastery', ' in', ' the', ' hills', '.', 'Y', 'ara', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">542</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.96</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m542\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.96\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.83 Prob: 11.28% Token: | lonely|\n",
      "Top 1th token. Logit: 16.46 Prob:  7.78% Token: | alone|\n",
      "Top 2th token. Logit: 16.09 Prob:  5.38% Token: | out|\n",
      "Top 3th token. Logit: 16.09 Prob:  5.37% Token: | uncomfortable|\n",
      "Top 4th token. Logit: 15.92 Prob:  4.54% Token: | strange|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">542</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m542\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 4\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Oliver, the intrepid explorer, relishes the thrill of uncharted territories. Ava, the meticulous scientist, values control and predictability. Out of nowhere, they were teleported to an alien planet.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Oliver\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'O', 'liver', ',', ' the', ' int', 're', 'pid', ' explorer', ',', ' rel', 'ishes', ' the', ' thrill', ' of', ' un', 'chart', 'ed', ' territories', '.', ' A', 'va', ',', ' the', ' met', 'iculous', ' scientist', ',', ' values', ' control', ' and', ' predict', 'ability', '.', ' Out', ' of', ' nowhere', ',', ' they', ' were', ' tele', 'ported', ' to', ' an', ' alien', ' planet', '.', 'O', 'liver', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">452</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.75</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m452\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.75\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.31 Prob:  6.29% Token: | much|\n",
      "Top 1th token. Logit: 15.26 Prob:  5.97% Token: | comfortable|\n",
      "Top 2th token. Logit: 15.24 Prob:  5.85% Token: | out|\n",
      "Top 3th token. Logit: 15.10 Prob:  5.07% Token: | strange|\n",
      "Top 4th token. Logit: 14.77 Prob:  3.66% Token: | alone|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">452</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m452\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Ava\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'O', 'liver', ',', ' the', ' int', 're', 'pid', ' explorer', ',', ' rel', 'ishes', ' the', ' thrill', ' of', ' un', 'chart', 'ed', ' territories', '.', ' A', 'va', ',', ' the', ' met', 'iculous', ' scientist', ',', ' values', ' control', ' and', ' predict', 'ability', '.', ' Out', ' of', ' nowhere', ',', ' they', ' were', ' tele', 'ported', ' to', ' an', ' alien', ' planet', '.', 'A', 'va', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">432</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.90</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m432\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.90\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.72 Prob:  7.91% Token: | comfortable|\n",
      "Top 1th token. Logit: 15.44 Prob:  5.96% Token: | strange|\n",
      "Top 2th token. Logit: 15.41 Prob:  5.79% Token: | much|\n",
      "Top 3th token. Logit: 15.38 Prob:  5.63% Token: | out|\n",
      "Top 4th token. Logit: 15.35 Prob:  5.44% Token: | uncomfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">432</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m432\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Oliver, the intrepid explorer, relishes the thrill of uncharted territories. Ava, the meticulous scientist, values control and predictability. One day, they were confined to a highly regulated, sterile laboratory.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Oliver\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'O', 'liver', ',', ' the', ' int', 're', 'pid', ' explorer', ',', ' rel', 'ishes', ' the', ' thrill', ' of', ' un', 'chart', 'ed', ' territories', '.', ' A', 'va', ',', ' the', ' met', 'iculous', ' scientist', ',', ' values', ' control', ' and', ' predict', 'ability', '.', ' One', ' day', ',', ' they', ' were', ' confined', ' to', ' a', ' highly', ' regulated', ',', ' sterile', ' laboratory', '.', 'O', 'liver', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">383</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.22</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m383\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.22\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.88 Prob:  8.51% Token: | much|\n",
      "Top 1th token. Logit: 15.72 Prob:  7.20% Token: | alone|\n",
      "Top 2th token. Logit: 15.54 Prob:  6.01% Token: | different|\n",
      "Top 3th token. Logit: 15.37 Prob:  5.09% Token: | lonely|\n",
      "Top 4th token. Logit: 15.37 Prob:  5.07% Token: | comfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">383</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m383\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Ava\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'O', 'liver', ',', ' the', ' int', 're', 'pid', ' explorer', ',', ' rel', 'ishes', ' the', ' thrill', ' of', ' un', 'chart', 'ed', ' territories', '.', ' A', 'va', ',', ' the', ' met', 'iculous', ' scientist', ',', ' values', ' control', ' and', ' predict', 'ability', '.', ' One', ' day', ',', ' they', ' were', ' confined', ' to', ' a', ' highly', ' regulated', ',', ' sterile', ' laboratory', '.', 'A', 'va', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">311</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.54</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m311\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.54\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.64 Prob:  6.06% Token: | much|\n",
      "Top 1th token. Logit: 15.63 Prob:  6.03% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 15.50 Prob:  5.26% Token: | lonely|\n",
      "Top 3th token. Logit: 15.41 Prob:  4.84% Token: | alone|\n",
      "Top 4th token. Logit: 15.40 Prob:  4.79% Token: | ill|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">311</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m311\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 5\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Sophie, the social media influencer, thrives on spotlight and popularity. Ryan, the privacy-loving introvert, appreciates anonymity and peace. Suddenly, they were cast in a reality TV show.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Sophie\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'S', 'oph', 'ie', ',', ' the', ' social', ' media', ' influ', 'encer', ',', ' th', 'rives', ' on', ' spotlight', ' and', ' popularity', '.', ' Ryan', ',', ' the', ' privacy', '-', 'l', 'oving', ' intro', 'vert', ',', ' apprec', 'iates', ' anonymity', ' and', ' peace', '.', ' Suddenly', ',', ' they', ' were', ' cast', ' in', ' a', ' reality', ' TV', ' show', '.', 'S', 'oph', 'ie', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.73</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m533\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.73\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.80 Prob:  9.27% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 15.25 Prob:  5.33% Token: | out|\n",
      "Top 2th token. Logit: 15.00 Prob:  4.17% Token: | alone|\n",
      "Top 3th token. Logit: 15.00 Prob:  4.17% Token: | comfortable|\n",
      "Top 4th token. Logit: 14.87 Prob:  3.65% Token: | awkward|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m533\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Ryan\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'S', 'oph', 'ie', ',', ' the', ' social', ' media', ' influ', 'encer', ',', ' th', 'rives', ' on', ' spotlight', ' and', ' popularity', '.', ' Ryan', ',', ' the', ' privacy', '-', 'l', 'oving', ' intro', 'vert', ',', ' apprec', 'iates', ' anonymity', ' and', ' peace', '.', ' Suddenly', ',', ' they', ' were', ' cast', ' in', ' a', ' reality', ' TV', ' show', '.', 'Ryan', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">477</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.93</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m477\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.93\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.36 Prob: 13.78% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 15.34 Prob:  4.98% Token: | alone|\n",
      "Top 2th token. Logit: 15.31 Prob:  4.83% Token: | comfortable|\n",
      "Top 3th token. Logit: 15.30 Prob:  4.77% Token: | conflict|\n",
      "Top 4th token. Logit: 15.26 Prob:  4.59% Token: | awkward|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">477</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m477\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Sophie, the social media influencer, thrives on spotlight and popularity. Ryan, the privacy-loving introvert, appreciates anonymity and peace. One day, they found themselves living off-grid in a remote mountain cabin with no internet.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Sophie\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'S', 'oph', 'ie', ',', ' the', ' social', ' media', ' influ', 'encer', ',', ' th', 'rives', ' on', ' spotlight', ' and', ' popularity', '.', ' Ryan', ',', ' the', ' privacy', '-', 'l', 'oving', ' intro', 'vert', ',', ' apprec', 'iates', ' anonymity', ' and', ' peace', '.', ' One', ' day', ',', ' they', ' found', ' themselves', ' living', ' off', '-', 'grid', ' in', ' a', ' remote', ' mountain', ' cabin', ' with', ' no', ' internet', '.', 'S', 'oph', 'ie', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.53</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m561\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.53\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.96 Prob: 19.96% Token: | alone|\n",
      "Top 1th token. Logit: 16.35 Prob: 10.85% Token: | lonely|\n",
      "Top 2th token. Logit: 15.82 Prob:  6.43% Token: | isolated|\n",
      "Top 3th token. Logit: 15.63 Prob:  5.28% Token: | out|\n",
      "Top 4th token. Logit: 15.44 Prob:  4.36% Token: | disconnected|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">561</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m561\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Ryan\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'S', 'oph', 'ie', ',', ' the', ' social', ' media', ' influ', 'encer', ',', ' th', 'rives', ' on', ' spotlight', ' and', ' popularity', '.', ' Ryan', ',', ' the', ' privacy', '-', 'l', 'oving', ' intro', 'vert', ',', ' apprec', 'iates', ' anonymity', ' and', ' peace', '.', ' One', ' day', ',', ' they', ' found', ' themselves', ' living', ' off', '-', 'grid', ' in', ' a', ' remote', ' mountain', ' cabin', ' with', ' no', ' internet', '.', 'Ryan', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.65</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m504\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.65\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.14 Prob: 21.17% Token: | alone|\n",
      "Top 1th token. Logit: 16.36 Prob:  9.76% Token: | lonely|\n",
      "Top 2th token. Logit: 16.09 Prob:  7.44% Token: | isolated|\n",
      "Top 3th token. Logit: 15.87 Prob:  5.94% Token: | disconnected|\n",
      "Top 4th token. Logit: 15.62 Prob:  4.63% Token: | uncomfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">504</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m504\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 6\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Mason, the athletic football player, loves competition and physical challenge. Isabella, the intellectual philosopher, relishes deep thoughts and cerebral challenges. Out of the blue, they were invited to a state-level football tournament.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Mason\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'M', 'ason', ',', ' the', ' athletic', ' football', ' player', ',', ' loves', ' competition', ' and', ' physical', ' challenge', '.', ' Is', 'abella', ',', ' the', ' intellectual', ' philosopher', ',', ' rel', 'ishes', ' deep', ' thoughts', ' and', ' cerebral', ' challenges', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' were', ' invited', ' to', ' a', ' state', '-', 'level', ' football', ' tournament', '.', 'M', 'ason', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1003</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.43</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1003\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m7.43\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.71 Prob: 13.72% Token: | excited|\n",
      "Top 1th token. Logit: 16.14 Prob:  7.72% Token: | nervous|\n",
      "Top 2th token. Logit: 15.83 Prob:  5.71% Token: | confident|\n",
      "Top 3th token. Logit: 15.75 Prob:  5.25% Token: | competitive|\n",
      "Top 4th token. Logit: 15.56 Prob:  4.32% Token: | uncomfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1003</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m1003\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Isabella\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'M', 'ason', ',', ' the', ' athletic', ' football', ' player', ',', ' loves', ' competition', ' and', ' physical', ' challenge', '.', ' Is', 'abella', ',', ' the', ' intellectual', ' philosopher', ',', ' rel', 'ishes', ' deep', ' thoughts', ' and', ' cerebral', ' challenges', '.', ' Out', ' of', ' the', ' blue', ',', ' they', ' were', ' invited', ' to', ' a', ' state', '-', 'level', ' football', ' tournament', '.', 'Is', 'abella', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">920</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.68</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m920\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m7.68\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.55 Prob: 11.44% Token: | nervous|\n",
      "Top 1th token. Logit: 16.45 Prob: 10.35% Token: | excited|\n",
      "Top 2th token. Logit: 16.27 Prob:  8.57% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 15.47 Prob:  3.87% Token: | out|\n",
      "Top 4th token. Logit: 15.46 Prob:  3.82% Token: | confident|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">920</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m920\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Mason, the athletic football player, loves competition and physical challenge. Isabella, the intellectual philosopher, relishes deep thoughts and cerebral challenges. One day, they were enrolled in a high-level philosophical debate.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Mason\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'M', 'ason', ',', ' the', ' athletic', ' football', ' player', ',', ' loves', ' competition', ' and', ' physical', ' challenge', '.', ' Is', 'abella', ',', ' the', ' intellectual', ' philosopher', ',', ' rel', 'ishes', ' deep', ' thoughts', ' and', ' cerebral', ' challenges', '.', ' One', ' day', ',', ' they', ' were', ' enrolled', ' in', ' a', ' high', '-', 'level', ' philosophical', ' debate', '.', 'M', 'ason', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1205</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.35</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1205\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m7.35\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.27 Prob: 41.22% Token: | confident|\n",
      "Top 1th token. Logit: 16.15 Prob:  4.93% Token: | comfortable|\n",
      "Top 2th token. Logit: 15.85 Prob:  3.65% Token: | good|\n",
      "Top 3th token. Logit: 15.75 Prob:  3.33% Token: | competitive|\n",
      "Top 4th token. Logit: 15.37 Prob:  2.26% Token: | strongly|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1205</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m1205\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Isabella\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'M', 'ason', ',', ' the', ' athletic', ' football', ' player', ',', ' loves', ' competition', ' and', ' physical', ' challenge', '.', ' Is', 'abella', ',', ' the', ' intellectual', ' philosopher', ',', ' rel', 'ishes', ' deep', ' thoughts', ' and', ' cerebral', ' challenges', '.', ' One', ' day', ',', ' they', ' were', ' enrolled', ' in', ' a', ' high', '-', 'level', ' philosophical', ' debate', '.', 'Is', 'abella', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1317</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.27</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1317\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m7.27\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.49 Prob: 47.77% Token: | confident|\n",
      "Top 1th token. Logit: 16.37 Prob:  5.71% Token: | comfortable|\n",
      "Top 2th token. Logit: 15.56 Prob:  2.56% Token: | good|\n",
      "Top 3th token. Logit: 15.47 Prob:  2.33% Token: | strongly|\n",
      "Top 4th token. Logit: 15.45 Prob:  2.28% Token: | uncomfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1317</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m1317\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 7\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Ella, the daredevil bungee jumper, thrives on heights and speed. Benjamin, the grounded cook, appreciates stability and calmness. One day, they were offered to bungee jump from the tallest bridge.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Ella\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'E', 'lla', ',', ' the', ' dared', 'evil', ' b', 'unge', 'e', ' j', 'umper', ',', ' th', 'rives', ' on', ' heights', ' and', ' speed', '.', ' Benjamin', ',', ' the', ' grounded', ' cook', ',', ' apprec', 'iates', ' stability', ' and', ' calm', 'ness', '.', ' One', ' day', ',', ' they', ' were', ' offered', ' to', ' b', 'unge', 'e', ' jump', ' from', ' the', ' tall', 'est', ' bridge', '.', 'E', 'lla', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">943</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.68</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m943\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m7.68\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.07 Prob: 27.91% Token: | excited|\n",
      "Top 1th token. Logit: 17.36 Prob: 13.71% Token: | nervous|\n",
      "Top 2th token. Logit: 16.47 Prob:  5.63% Token: | confident|\n",
      "Top 3th token. Logit: 16.18 Prob:  4.22% Token: | scared|\n",
      "Top 4th token. Logit: 15.95 Prob:  3.35% Token: | anxious|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">943</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m943\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Benjamin\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'E', 'lla', ',', ' the', ' dared', 'evil', ' b', 'unge', 'e', ' j', 'umper', ',', ' th', 'rives', ' on', ' heights', ' and', ' speed', '.', ' Benjamin', ',', ' the', ' grounded', ' cook', ',', ' apprec', 'iates', ' stability', ' and', ' calm', 'ness', '.', ' One', ' day', ',', ' they', ' were', ' offered', ' to', ' b', 'unge', 'e', ' jump', ' from', ' the', ' tall', 'est', ' bridge', '.', 'Ben', 'jamin', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">890</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.79</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m890\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m7.79\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.14 Prob: 15.16% Token: | nervous|\n",
      "Top 1th token. Logit: 17.13 Prob: 15.14% Token: | excited|\n",
      "Top 2th token. Logit: 15.90 Prob:  4.40% Token: | scared|\n",
      "Top 3th token. Logit: 15.90 Prob:  4.39% Token: | confident|\n",
      "Top 4th token. Logit: 15.88 Prob:  4.30% Token: | anxious|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">890</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m890\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Ella, the daredevil bungee jumper, thrives on heights and speed. Benjamin, the grounded cook, appreciates stability and calmness. Suddenly, they found themselves in a calm and slow-paced cooking class.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Ella\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'E', 'lla', ',', ' the', ' dared', 'evil', ' b', 'unge', 'e', ' j', 'umper', ',', ' th', 'rives', ' on', ' heights', ' and', ' speed', '.', ' Benjamin', ',', ' the', ' grounded', ' cook', ',', ' apprec', 'iates', ' stability', ' and', ' calm', 'ness', '.', ' Suddenly', ',', ' they', ' found', ' themselves', ' in', ' a', ' calm', ' and', ' slow', '-', 'paced', ' cooking', ' class', '.', 'E', 'lla', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1010</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.55</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1010\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m7.55\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.30 Prob: 13.50% Token: | comfortable|\n",
      "Top 1th token. Logit: 15.47 Prob:  5.88% Token: | nervous|\n",
      "Top 2th token. Logit: 15.26 Prob:  4.75% Token: | excited|\n",
      "Top 3th token. Logit: 15.24 Prob:  4.66% Token: | calm|\n",
      "Top 4th token. Logit: 15.09 Prob:  4.01% Token: | uncomfortable|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1010</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m1010\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Benjamin\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'E', 'lla', ',', ' the', ' dared', 'evil', ' b', 'unge', 'e', ' j', 'umper', ',', ' th', 'rives', ' on', ' heights', ' and', ' speed', '.', ' Benjamin', ',', ' the', ' grounded', ' cook', ',', ' apprec', 'iates', ' stability', ' and', ' calm', 'ness', '.', ' Suddenly', ',', ' they', ' found', ' themselves', ' in', ' a', ' calm', ' and', ' slow', '-', 'paced', ' cooking', ' class', '.', 'Ben', 'jamin', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">853</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.78</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m853\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m7.78\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.74 Prob: 19.98% Token: | comfortable|\n",
      "Top 1th token. Logit: 15.72 Prob:  7.20% Token: | calm|\n",
      "Top 2th token. Logit: 15.59 Prob:  6.27% Token: | relaxed|\n",
      "Top 3th token. Logit: 15.27 Prob:  4.56% Token: | uncomfortable|\n",
      "Top 4th token. Logit: 15.18 Prob:  4.19% Token: | out|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">853</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m853\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n",
      "Story 8\n",
      "======================================================================================================\n",
      "\n",
      "\n",
      "Original Story:\n",
      "======================================================================================================\n",
      "Amelia, the enthusiastic extrovert, loves crowds and loud parties. Lucas, the shy programmer, prefers solitude and silence. Out of nowhere, they were invited to a grand music concert.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Amelia\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Am', 'elia', ',', ' the', ' enthusiastic', ' ext', 'ro', 'vert', ',', ' loves', ' crowds', ' and', ' loud', ' parties', '.', ' Lucas', ',', ' the', ' shy', ' programmer', ',', ' prefers', ' sol', 'itude', ' and', ' silence', '.', ' Out', ' of', ' nowhere', ',', ' they', ' were', ' invited', ' to', ' a', ' grand', ' music', ' concert', '.', 'Am', 'elia', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">749</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.12</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m749\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.12\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.99 Prob: 15.93% Token: | excited|\n",
      "Top 1th token. Logit: 16.93 Prob: 14.97% Token: | nervous|\n",
      "Top 2th token. Logit: 16.02 Prob:  6.03% Token: | uncomfortable|\n",
      "Top 3th token. Logit: 15.56 Prob:  3.79% Token: | happy|\n",
      "Top 4th token. Logit: 15.36 Prob:  3.12% Token: | out|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">749</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m749\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Lucas\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Am', 'elia', ',', ' the', ' enthusiastic', ' ext', 'ro', 'vert', ',', ' loves', ' crowds', ' and', ' loud', ' parties', '.', ' Lucas', ',', ' the', ' shy', ' programmer', ',', ' prefers', ' sol', 'itude', ' and', ' silence', '.', ' Out', ' of', ' nowhere', ',', ' they', ' were', ' invited', ' to', ' a', ' grand', ' music', ' concert', '.', 'Luc', 'as', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">706</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.19</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m706\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.19\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.27 Prob: 18.82% Token: | nervous|\n",
      "Top 1th token. Logit: 16.88 Prob: 12.73% Token: | uncomfortable|\n",
      "Top 2th token. Logit: 16.08 Prob:  5.69% Token: | awkward|\n",
      "Top 3th token. Logit: 15.80 Prob:  4.31% Token: | out|\n",
      "Top 4th token. Logit: 15.73 Prob:  4.03% Token: | excited|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">706</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m706\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Amelia, the enthusiastic extrovert, loves crowds and loud parties. Lucas, the shy programmer, prefers solitude and silence. One day, they were assigned to a solitary coding project that required complete silence.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Amelia\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Am', 'elia', ',', ' the', ' enthusiastic', ' ext', 'ro', 'vert', ',', ' loves', ' crowds', ' and', ' loud', ' parties', '.', ' Lucas', ',', ' the', ' shy', ' programmer', ',', ' prefers', ' sol', 'itude', ' and', ' silence', '.', ' One', ' day', ',', ' they', ' were', ' assigned', ' to', ' a', ' solitary', ' coding', ' project', ' that', ' required', ' complete', ' silence', '.', 'Am', 'elia', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">414</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.59</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m414\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.59\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.97 Prob: 11.94% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 16.64 Prob:  8.60% Token: | nervous|\n",
      "Top 2th token. Logit: 16.42 Prob:  6.89% Token: | anxious|\n",
      "Top 3th token. Logit: 16.09 Prob:  4.94% Token: | lonely|\n",
      "Top 4th token. Logit: 15.87 Prob:  3.97% Token: | awkward|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">414</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m414\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Lucas\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'Am', 'elia', ',', ' the', ' enthusiastic', ' ext', 'ro', 'vert', ',', ' loves', ' crowds', ' and', ' loud', ' parties', '.', ' Lucas', ',', ' the', ' shy', ' programmer', ',', ' prefers', ' sol', 'itude', ' and', ' silence', '.', ' One', ' day', ',', ' they', ' were', ' assigned', ' to', ' a', ' solitary', ' coding', ' project', ' that', ' required', ' complete', ' silence', '.', 'Luc', 'as', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span><span style=\"font-weight: bold\">      Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.10</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m312\u001b[0m\u001b[1m      Logit: \u001b[0m\u001b[1;36m10.10\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.50 Prob: 16.65% Token: | uncomfortable|\n",
      "Top 1th token. Logit: 16.85 Prob:  8.70% Token: | nervous|\n",
      "Top 2th token. Logit: 16.74 Prob:  7.76% Token: | anxious|\n",
      "Top 3th token. Logit: 16.59 Prob:  6.72% Token: | lonely|\n",
      "Top 4th token. Logit: 16.48 Prob:  6.01% Token: | alone|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m312\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the list of stories\n",
    "stories = [\n",
    "    {\n",
    "        \"original\": \"Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. Out of the blue, they received invitations to a grand gala.\",\n",
    "        \"reversed\": \"Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. One day, they were offered an opportunity to join a peaceful, secluded writer's retreat in the woods.\",\n",
    "        \"characters\": [\"Claire\", \"Dave\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. One day, they were offered a chance to jump from an airplane.\",\n",
    "        \"reversed\": \"Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. Suddenly, they were placed in a quiet, organized library full of rare books.\",\n",
    "        \"characters\": [\"Ivy\", \"Jake\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. Suddenly, they were offered an opportunity to join a high-adrenaline adventure camp.\",\n",
    "        \"reversed\": \"Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. One day, they were tasked to work in a safe, calm recovery ward.\",\n",
    "        \"characters\": [\"Liam\", \"Mia\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. One day, their friends asked them to go to a lively, crowded music festival together.\",\n",
    "        \"reversed\": \"Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. One day, they were placed in a quiet, ancient library.\",\n",
    "        \"characters\": [\"Xander\", \"Yara\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "stories_2 = [\n",
    "    {\n",
    "        \"original\": \"Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. Out of the blue, they received invitations to a grand gala.\",\n",
    "        \"reversed\": \"Claire, the social butterfly, flourishes in crowded, lively parties. Dave, the reclusive writer, cherishes solitude and silence. Unexpectedly, they were booked on a solitary retreat on a remote, desolate island.\",\n",
    "        \"characters\": [\"Claire\", \"Dave\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. One day, they were offered a chance to jump from an airplane.\",\n",
    "        \"reversed\": \"Ivy, the thrill-seeking skydiver, adores high-speed and adrenaline rushes. Jake, the cautious librarian, prefers safety and tranquility. Suddenly, they were trapped in a silent, dimly-lit room with nothing but a pile of dusty old books.\",\n",
    "        \"characters\": [\"Ivy\", \"Jake\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. Suddenly, they were offered roles in a high-risk action movie.\",\n",
    "        \"reversed\": \"Liam, the daredevil stuntman, gets a thrill out of dangerous action. Mia, the careful nurse, values safety and caution. One day, they found themselves in an extremely safe and slow-paced senior care facility.\",\n",
    "        \"characters\": [\"Liam\", \"Mia\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. Suddenly, they were asked to perform at a bustling music festival.\",\n",
    "        \"reversed\": \"Xander, the energetic DJ, loves loud music and vibrant dance floors. Yara, the contemplative librarian, cherishes silence and tranquility. Out of the blue, they were sent to a secluded, noise-free monastery in the hills.\",\n",
    "        \"characters\": [\"Xander\", \"Yara\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Oliver, the intrepid explorer, relishes the thrill of uncharted territories. Ava, the meticulous scientist, values control and predictability. Out of nowhere, they were teleported to an alien planet.\",\n",
    "        \"reversed\": \"Oliver, the intrepid explorer, relishes the thrill of uncharted territories. Ava, the meticulous scientist, values control and predictability. One day, they were confined to a highly regulated, sterile laboratory.\",\n",
    "        \"characters\": [\"Oliver\", \"Ava\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Sophie, the social media influencer, thrives on spotlight and popularity. Ryan, the privacy-loving introvert, appreciates anonymity and peace. Suddenly, they were cast in a reality TV show.\",\n",
    "        \"reversed\": \"Sophie, the social media influencer, thrives on spotlight and popularity. Ryan, the privacy-loving introvert, appreciates anonymity and peace. One day, they found themselves living off-grid in a remote mountain cabin with no internet.\",\n",
    "        \"characters\": [\"Sophie\", \"Ryan\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Mason, the athletic football player, loves competition and physical challenge. Isabella, the intellectual philosopher, relishes deep thoughts and cerebral challenges. Out of the blue, they were invited to a state-level football tournament.\",\n",
    "        \"reversed\": \"Mason, the athletic football player, loves competition and physical challenge. Isabella, the intellectual philosopher, relishes deep thoughts and cerebral challenges. One day, they were enrolled in a high-level philosophical debate.\",\n",
    "        \"characters\": [\"Mason\", \"Isabella\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Ella, the daredevil bungee jumper, thrives on heights and speed. Benjamin, the grounded cook, appreciates stability and calmness. One day, they were offered to bungee jump from the tallest bridge.\",\n",
    "        \"reversed\": \"Ella, the daredevil bungee jumper, thrives on heights and speed. Benjamin, the grounded cook, appreciates stability and calmness. Suddenly, they found themselves in a calm and slow-paced cooking class.\",\n",
    "        \"characters\": [\"Ella\", \"Benjamin\"]\n",
    "    },\n",
    "    {\n",
    "        \"original\": \"Amelia, the enthusiastic extrovert, loves crowds and loud parties. Lucas, the shy programmer, prefers solitude and silence. Out of nowhere, they were invited to a grand music concert.\",\n",
    "        \"reversed\": \"Amelia, the enthusiastic extrovert, loves crowds and loud parties. Lucas, the shy programmer, prefers solitude and silence. One day, they were assigned to a solitary coding project that required complete silence.\",\n",
    "        \"characters\": [\"Amelia\", \"Lucas\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "story_counter = 0\n",
    "# Iterate through each story\n",
    "for story in stories_2:\n",
    "    print(\"======================================================================================================\")\n",
    "    print(f\"Story {story_counter}\")\n",
    "    print(\"======================================================================================================\\n\\n\")\n",
    "    \n",
    "    print(f\"Original Story:\")\n",
    "    print(\"======================================================================================================\")\n",
    "    print(f\"{story['original']}\\n\")\n",
    "    for character in story[\"characters\"]:\n",
    "        # Print the character's name\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(f\"Character: {character}\")\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        # Get the end of the original story\n",
    "        original_end = story[\"original\"] + character.capitalize() + \" felt very\"\n",
    "        # Get the LLM prediction for the original story\n",
    "        print(f\"Mood Prediction:\")\n",
    "        original_prediction = utils.test_prompt(original_end, \"\", model, prepend_bos=True, top_k=5)\n",
    "    \n",
    "    print(f\"Reversed Story:\")\n",
    "    print(\"======================================================================================================\")\n",
    "    print(f\"{story['reversed']}\\n\")\n",
    "    for character in story[\"characters\"]:\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(f\"Character: {character}\")\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(f\"Mood Prediction:\")\n",
    "        reversed_end = story[\"reversed\"] + character.capitalize() + \" felt very\"\n",
    "        # Get the LLM prediction for the reversed story\n",
    "        reversed_prediction = utils.test_prompt(reversed_end, \"\", model, prepend_bos=True, top_k=5)\n",
    "    story_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83624d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_lists(list1, list2):\n",
    "    # Find the maximum length\n",
    "    max_len = max(len(list1), len(list2))\n",
    "\n",
    "    # Print the items and their indices\n",
    "    for i in range(max_len):\n",
    "        item1 = list1[i] if i < len(list1) else None\n",
    "        item2 = list2[i] if i < len(list2) else None\n",
    "        print(f\"Index: {i}, '{item1}', '{item2}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d71c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' discovered', ' a', ' bouncing', ' ball', '.', ' Penny', ' was', ' thrilled', ' and', ' started', ' chasing', ' the', ' ball', '.', ' Wh', 'isk', 'ers', ',', ' however', ',', ' was', ' startled', ' by', ' the', ' ball', \"'s\", ' movement', ' and', ' climbed', ' a', ' tree', '.', ' Penny', ' had', ' a', ' fun', '-', 'filled', ' day', ' playing', ',', ' while', ' Wh', 'isk', 'ers', ' watched', ' war', 'ily', ' from', ' above', '.']\n",
      "['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' found', ' a', ' quiet', ' corner', '.', ' Penny', ' was', ' bored', ' without', ' anything', ' to', ' play', ' with', ',', ' but', ' Wh', 'isk', 'ers', ' curled', ' up', ' and', ' started', ' pur', 'ring', '.', ' Penny', ' wandered', ' around', ' rest', 'lessly', ',', ' while', ' Wh', 'isk', 'ers', ' had', ' a', ' peaceful', ' nap', '.']\n",
      "Index: 0, '<|endoftext|>', '<|endoftext|>'\n",
      "Index: 1, 'P', 'P'\n",
      "Index: 2, 'enny', 'enny'\n",
      "Index: 3, ',', ','\n",
      "Index: 4, ' the', ' the'\n",
      "Index: 5, ' puppy', ' puppy'\n",
      "Index: 6, ',', ','\n",
      "Index: 7, ' and', ' and'\n",
      "Index: 8, ' Wh', ' Wh'\n",
      "Index: 9, 'isk', 'isk'\n",
      "Index: 10, 'ers', 'ers'\n",
      "Index: 11, ',', ','\n",
      "Index: 12, ' the', ' the'\n",
      "Index: 13, ' cat', ' cat'\n",
      "Index: 14, ',', ','\n",
      "Index: 15, ' discovered', ' found'\n",
      "Index: 16, ' a', ' a'\n",
      "Index: 17, ' bouncing', ' quiet'\n",
      "Index: 18, ' ball', ' corner'\n",
      "Index: 19, '.', '.'\n",
      "Index: 20, ' Penny', ' Penny'\n",
      "Index: 21, ' was', ' was'\n",
      "Index: 22, ' thrilled', ' bored'\n",
      "Index: 23, ' and', ' without'\n",
      "Index: 24, ' started', ' anything'\n",
      "Index: 25, ' chasing', ' to'\n",
      "Index: 26, ' the', ' play'\n",
      "Index: 27, ' ball', ' with'\n",
      "Index: 28, '.', ','\n",
      "Index: 29, ' Wh', ' but'\n",
      "Index: 30, 'isk', ' Wh'\n",
      "Index: 31, 'ers', 'isk'\n",
      "Index: 32, ',', 'ers'\n",
      "Index: 33, ' however', ' curled'\n",
      "Index: 34, ',', ' up'\n",
      "Index: 35, ' was', ' and'\n",
      "Index: 36, ' startled', ' started'\n",
      "Index: 37, ' by', ' pur'\n",
      "Index: 38, ' the', 'ring'\n",
      "Index: 39, ' ball', '.'\n",
      "Index: 40, ''s', ' Penny'\n",
      "Index: 41, ' movement', ' wandered'\n",
      "Index: 42, ' and', ' around'\n",
      "Index: 43, ' climbed', ' rest'\n",
      "Index: 44, ' a', 'lessly'\n",
      "Index: 45, ' tree', ','\n",
      "Index: 46, '.', ' while'\n",
      "Index: 47, ' Penny', ' Wh'\n",
      "Index: 48, ' had', 'isk'\n",
      "Index: 49, ' a', 'ers'\n",
      "Index: 50, ' fun', ' had'\n",
      "Index: 51, '-', ' a'\n",
      "Index: 52, 'filled', ' peaceful'\n",
      "Index: 53, ' day', ' nap'\n",
      "Index: 54, ' playing', '.'\n",
      "Index: 55, ',', 'None'\n",
      "Index: 56, ' while', 'None'\n",
      "Index: 57, ' Wh', 'None'\n",
      "Index: 58, 'isk', 'None'\n",
      "Index: 59, 'ers', 'None'\n",
      "Index: 60, ' watched', 'None'\n",
      "Index: 61, ' war', 'None'\n",
      "Index: 62, 'ily', 'None'\n",
      "Index: 63, ' from', 'None'\n",
      "Index: 64, ' above', 'None'\n",
      "Index: 65, '.', 'None'\n",
      "---------------------------------------------------------\n",
      "Character: Penny\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' discovered', ' a', ' bouncing', ' ball', '.', ' Penny', ' was', ' thrilled', ' and', ' started', ' chasing', ' the', ' ball', '.', ' Wh', 'isk', 'ers', ',', ' however', ',', ' was', ' startled', ' by', ' the', ' ball', \"'s\", ' movement', ' and', ' climbed', ' a', ' tree', '.', ' Penny', ' had', ' a', ' fun', '-', 'filled', ' day', ' playing', ',', ' while', ' Wh', 'isk', 'ers', ' watched', ' war', 'ily', ' from', ' above', '.', 'P', 'enny', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">637</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.62</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m637\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m8.62\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.24 Prob: 21.66% Token: | proud|\n",
      "Top 1th token. Logit: 17.67 Prob: 12.23% Token: | happy|\n",
      "Top 2th token. Logit: 16.98 Prob:  6.16% Token: | sad|\n",
      "Top 3th token. Logit: 16.98 Prob:  6.13% Token: | sorry|\n",
      "Top 4th token. Logit: 16.93 Prob:  5.82% Token: | good|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">637</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m637\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Whiskers\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' discovered', ' a', ' bouncing', ' ball', '.', ' Penny', ' was', ' thrilled', ' and', ' started', ' chasing', ' the', ' ball', '.', ' Wh', 'isk', 'ers', ',', ' however', ',', ' was', ' startled', ' by', ' the', ' ball', \"'s\", ' movement', ' and', ' climbed', ' a', ' tree', '.', ' Penny', ' had', ' a', ' fun', '-', 'filled', ' day', ' playing', ',', ' while', ' Wh', 'isk', 'ers', ' watched', ' war', 'ily', ' from', ' above', '.', 'Wh', 'isk', 'ers', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">299</span><span style=\"font-weight: bold\">      Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.21</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m299\u001b[0m\u001b[1m      Logit: \u001b[0m\u001b[1;36m10.21\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.39 Prob: 11.50% Token: | sad|\n",
      "Top 1th token. Logit: 17.34 Prob: 10.95% Token: | sorry|\n",
      "Top 2th token. Logit: 17.28 Prob: 10.34% Token: | lonely|\n",
      "Top 3th token. Logit: 16.62 Prob:  5.36% Token: | jealous|\n",
      "Top 4th token. Logit: 16.51 Prob:  4.78% Token: | bad|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">299</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m299\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed Story:\n",
      "======================================================================================================\n",
      "Penny, the puppy, and Whiskers, the cat, found a quiet corner. Penny was bored without anything to play with, but Whiskers curled up and started purring. Penny wandered around restlessly, while Whiskers had a peaceful nap.\n",
      "\n",
      "---------------------------------------------------------\n",
      "Character: Penny\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' found', ' a', ' quiet', ' corner', '.', ' Penny', ' was', ' bored', ' without', ' anything', ' to', ' play', ' with', ',', ' but', ' Wh', 'isk', 'ers', ' curled', ' up', ' and', ' started', ' pur', 'ring', '.', ' Penny', ' wandered', ' around', ' rest', 'lessly', ',', ' while', ' Wh', 'isk', 'ers', ' had', ' a', ' peaceful', ' nap', '.', 'P', 'enny', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.11</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m536\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.11\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.41 Prob: 12.96% Token: | lonely|\n",
      "Top 1th token. Logit: 16.96 Prob:  8.25% Token: | sad|\n",
      "Top 2th token. Logit: 16.84 Prob:  7.30% Token: | sorry|\n",
      "Top 3th token. Logit: 16.24 Prob:  4.01% Token: | happy|\n",
      "Top 4th token. Logit: 16.23 Prob:  3.96% Token: | guilty|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">536</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m536\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Character: Whiskers\n",
      "---------------------------------------------------------\n",
      "Mood Prediction:\n",
      "Tokenized prompt: ['<|endoftext|>', 'P', 'enny', ',', ' the', ' puppy', ',', ' and', ' Wh', 'isk', 'ers', ',', ' the', ' cat', ',', ' found', ' a', ' quiet', ' corner', '.', ' Penny', ' was', ' bored', ' without', ' anything', ' to', ' play', ' with', ',', ' but', ' Wh', 'isk', 'ers', ' curled', ' up', ' and', ' started', ' pur', 'ring', '.', ' Penny', ' wandered', ' around', ' rest', 'lessly', ',', ' while', ' Wh', 'isk', 'ers', ' had', ' a', ' peaceful', ' nap', '.', 'Wh', 'isk', 'ers', ' felt', ' very']\n",
      "Tokenized answer: [' ']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">499</span><span style=\"font-weight: bold\">      Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.09</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | |</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m499\u001b[0m\u001b[1m      Logit:  \u001b[0m\u001b[1;36m9.09\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | |\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 17.19 Prob: 10.44% Token: | comfortable|\n",
      "Top 1th token. Logit: 16.97 Prob:  8.42% Token: | happy|\n",
      "Top 2th token. Logit: 16.88 Prob:  7.68% Token: | safe|\n",
      "Top 3th token. Logit: 16.54 Prob:  5.49% Token: | content|\n",
      "Top 4th token. Logit: 16.45 Prob:  4.97% Token: | warm|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' '</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">499</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' '\u001b[0m, \u001b[1;36m499\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "story = {\n",
    "        \"original\": \"Penny, the puppy, and Whiskers, the cat, discovered a bouncing ball. Penny was thrilled and started chasing the ball. Whiskers, however, was startled by the ball's movement and climbed a tree. Penny had a fun-filled day playing, while Whiskers watched warily from above.\",\n",
    "        \"reversed\": \"Penny, the puppy, and Whiskers, the cat, found a quiet corner. Penny was bored without anything to play with, but Whiskers curled up and started purring. Penny wandered around restlessly, while Whiskers had a peaceful nap.\",\n",
    "        \"characters\": [\"Penny\", \"Whiskers\"]\n",
    "    }\n",
    "print(model.to_str_tokens(story[\"original\"]))\n",
    "print(model.to_str_tokens(story[\"reversed\"]))\n",
    "print_lists(model.to_str_tokens(story[\"original\"]), model.to_str_tokens(story[\"reversed\"]))\n",
    "\n",
    "for character in story[\"characters\"]:\n",
    "    # Print the character's name\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"Character: {character}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    # Get the end of the original story\n",
    "    original_end = story[\"original\"] + character.capitalize() + \" felt very\"\n",
    "    # Get the LLM prediction for the original story\n",
    "    print(f\"Mood Prediction:\")\n",
    "    original_prediction = utils.test_prompt(original_end, \"\", model, prepend_bos=True, top_k=5)\n",
    "    \n",
    "print(f\"Reversed Story:\")\n",
    "print(\"======================================================================================================\")\n",
    "print(f\"{story['reversed']}\\n\")\n",
    "for character in story[\"characters\"]:\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"Character: {character}\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(f\"Mood Prediction:\")\n",
    "    reversed_end = story[\"reversed\"] + character.capitalize() + \" felt very\"\n",
    "    # Get the LLM prediction for the reversed story\n",
    "    reversed_prediction = utils.test_prompt(reversed_end, \"\", model, prepend_bos=True, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8aef4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the example prompt to a markdown file for later use, with a version number based on the previous entry\n",
    "# This is useful for keeping track of the prompts used in each experiment\n",
    "with open(\"prompt_log.md\", \"a\") as f:\n",
    "    # count the number of lines in the file divided by 4 (each prompt is 4 lines)\n",
    "    # this is the version number of the prompt\n",
    "    version = int(os.popen(\"wc -l prompt_log.md | awk '{print $1}'\").read()) // 4\n",
    "    f.write(f\"## Version {version}\\n\")\n",
    "    f.write(f\"### Prompt Text: {example_prompt}\\n\")\n",
    "    f.write(f\"### Answer: {example_answer}\\n\\n\")\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f53a6c5",
   "metadata": {},
   "source": [
    "### Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3fd51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pythia model\n",
      "Count of words: 20\n",
      "Using Pythia model\n",
      "Count of words: 15\n",
      "Using Pythia model\n",
      "Count of words: 19\n",
      "Using Pythia model\n",
      "Count of words: 2\n",
      "Using Pythia model\n",
      "Count of words: 2\n",
      "Using Pythia model\n",
      "Count of words: 7\n"
     ]
    }
   ],
   "source": [
    "pos_answers = [\" Positive\", \" positive\"] #, \" amazing\", \" good\"]\n",
    "neg_answers = [\" Negative\", \" negative\"] #, \" terrible\", \" bad\"]\n",
    "all_prompts, answer_tokens, clean_tokens, corrupted_tokens = get_dataset(\n",
    "    model, device, 2, \"multi_subject_1\", pos_answers, neg_answers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dcd3e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, torch.Size([72, 2, 2]), torch.Size([72, 76]), torch.Size([72, 76]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_prompts), answer_tokens.shape, clean_tokens.shape, corrupted_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afef9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review A: 'I thought this movie was perfect, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2028, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was perfect, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(0.1087, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was perfect, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2453, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was perfect, I loved it. The acting was fantastic, the plot was good, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.4838, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was fantastic, I loved it. The acting was good, the plot was remarkable, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3977, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was fantastic, I loved it. The acting was good, the plot was remarkable, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.3430, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was fantastic, I loved it. The acting was good, the plot was remarkable, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.7357, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was fantastic, I loved it. The acting was good, the plot was remarkable, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8555, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was good, I loved it. The acting was remarkable, the plot was wonderful, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2379, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was good, I loved it. The acting was remarkable, the plot was wonderful, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.1786, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was good, I loved it. The acting was remarkable, the plot was wonderful, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3917, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was good, I loved it. The acting was remarkable, the plot was wonderful, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6443, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was remarkable, I loved it. The acting was wonderful, the plot was fabulous, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.6255, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was remarkable, I loved it. The acting was wonderful, the plot was fabulous, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.7000, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was remarkable, I loved it. The acting was wonderful, the plot was fabulous, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.6370, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was remarkable, I loved it. The acting was wonderful, the plot was fabulous, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8894, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was wonderful, I loved it. The acting was fabulous, the plot was outstanding, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4185, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was wonderful, I loved it. The acting was fabulous, the plot was outstanding, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.3272, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was wonderful, I loved it. The acting was fabulous, the plot was outstanding, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3448, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was wonderful, I loved it. The acting was fabulous, the plot was outstanding, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6401, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was fabulous, I loved it. The acting was outstanding, the plot was awesome, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disgusting, I hated it. The acting was disastrous, the plot was offensive, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4710, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was fabulous, I loved it. The acting was outstanding, the plot was awesome, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disgusting, I hated it. The acting was disastrous, the plot was offensive, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6351, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disgusting, I hated it. The acting was disastrous, the plot was offensive, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was fabulous, I loved it. The acting was outstanding, the plot was awesome, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.5485, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disgusting, I hated it. The acting was disastrous, the plot was offensive, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was fabulous, I loved it. The acting was outstanding, the plot was awesome, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8574, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was outstanding, I loved it. The acting was awesome, the plot was exceptional, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disastrous, I hated it. The acting was offensive, the plot was wretched, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4990, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was outstanding, I loved it. The acting was awesome, the plot was exceptional, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disastrous, I hated it. The acting was offensive, the plot was wretched, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6218, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disastrous, I hated it. The acting was offensive, the plot was wretched, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was outstanding, I loved it. The acting was awesome, the plot was exceptional, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4456, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disastrous, I hated it. The acting was offensive, the plot was wretched, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was outstanding, I loved it. The acting was awesome, the plot was exceptional, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6696, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was awesome, I loved it. The acting was exceptional, the plot was incredible, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was offensive, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3586, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was awesome, I loved it. The acting was exceptional, the plot was incredible, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was offensive, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.5246, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was offensive, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was awesome, I loved it. The acting was exceptional, the plot was incredible, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.6527, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was offensive, I hated it. The acting was wretched, the plot was awful, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was awesome, I loved it. The acting was exceptional, the plot was incredible, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8658, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was exceptional, I loved it. The acting was incredible, the plot was extraordinary, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was wretched, I hated it. The acting was awful, the plot was unpleasant, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2749, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was exceptional, I loved it. The acting was incredible, the plot was extraordinary, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was wretched, I hated it. The acting was awful, the plot was unpleasant, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.1001, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was wretched, I hated it. The acting was awful, the plot was unpleasant, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was exceptional, I loved it. The acting was incredible, the plot was extraordinary, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.6275, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was wretched, I hated it. The acting was awful, the plot was unpleasant, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was exceptional, I loved it. The acting was incredible, the plot was extraordinary, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8359, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was incredible, I loved it. The acting was extraordinary, the plot was amazing, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was awful, I hated it. The acting was unpleasant, the plot was horrible, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4155, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was incredible, I loved it. The acting was extraordinary, the plot was amazing, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was awful, I hated it. The acting was unpleasant, the plot was horrible, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.3083, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was awful, I hated it. The acting was unpleasant, the plot was horrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was incredible, I loved it. The acting was extraordinary, the plot was amazing, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.5541, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was awful, I hated it. The acting was unpleasant, the plot was horrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was incredible, I loved it. The acting was extraordinary, the plot was amazing, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6939, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was extraordinary, I loved it. The acting was amazing, the plot was lovely, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was unpleasant, I hated it. The acting was horrible, the plot was disappointing, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3467, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was extraordinary, I loved it. The acting was amazing, the plot was lovely, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was unpleasant, I hated it. The acting was horrible, the plot was disappointing, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.2767, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was unpleasant, I hated it. The acting was horrible, the plot was disappointing, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was extraordinary, I loved it. The acting was amazing, the plot was lovely, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.5804, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was unpleasant, I hated it. The acting was horrible, the plot was disappointing, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was extraordinary, I loved it. The acting was amazing, the plot was lovely, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.7645, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was amazing, I loved it. The acting was lovely, the plot was brilliant, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrible, I hated it. The acting was disappointing, the plot was dreadful, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4913, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was amazing, I loved it. The acting was lovely, the plot was brilliant, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrible, I hated it. The acting was disappointing, the plot was dreadful, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.4077, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrible, I hated it. The acting was disappointing, the plot was dreadful, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was amazing, I loved it. The acting was lovely, the plot was brilliant, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.5009, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrible, I hated it. The acting was disappointing, the plot was dreadful, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was amazing, I loved it. The acting was lovely, the plot was brilliant, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.7734, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was lovely, I loved it. The acting was brilliant, the plot was terrific, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disappointing, I hated it. The acting was dreadful, the plot was bad, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3801, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was lovely, I loved it. The acting was brilliant, the plot was terrific, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was disappointing, I hated it. The acting was dreadful, the plot was bad, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.0629, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disappointing, I hated it. The acting was dreadful, the plot was bad, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was lovely, I loved it. The acting was brilliant, the plot was terrific, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4559, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was disappointing, I hated it. The acting was dreadful, the plot was bad, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was lovely, I loved it. The acting was brilliant, the plot was terrific, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.7045, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was brilliant, I loved it. The acting was terrific, the plot was superb, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3160, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was brilliant, I loved it. The acting was terrific, the plot was superb, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.0652, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was brilliant, I loved it. The acting was terrific, the plot was superb, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2903, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was dreadful, I hated it. The acting was bad, the plot was miserable, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was brilliant, I loved it. The acting was terrific, the plot was superb, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6075, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrific, I loved it. The acting was superb, the plot was spectacular, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.2679, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrific, I loved it. The acting was superb, the plot was spectacular, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.1987, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was terrific, I loved it. The acting was superb, the plot was spectacular, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.7537, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was bad, I hated it. The acting was miserable, the plot was horrific, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was terrific, I loved it. The acting was superb, the plot was spectacular, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.8971, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was superb, I loved it. The acting was spectacular, the plot was great, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3398, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was superb, I loved it. The acting was spectacular, the plot was great, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.3699, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was superb, I loved it. The acting was spectacular, the plot was great, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4425, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was miserable, I hated it. The acting was horrific, the plot was terrible, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was superb, I loved it. The acting was spectacular, the plot was great, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.7442, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4710, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.5411, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.4119, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was horrific, I hated it. The acting was terrible, the plot was disgusting, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was spectacular, I loved it. The acting was great, the plot was beautiful, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6766, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was great, I loved it. The acting was beautiful, the plot was perfect, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review A Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3800, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was great, I loved it. The acting was beautiful, the plot was perfect, and overall the movie was just very good.'\n",
      "Review B: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.1934, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was great, I loved it. The acting was beautiful, the plot was perfect, and overall the movie was just very good.'\n",
      "Review B Sentiment:\n",
      "[' Positive', ' Negative']\n",
      "tensor(1.3908, device='cuda:0') \n",
      "\n",
      "Review A: 'I thought this movie was terrible, I hated it. The acting was disgusting, the plot was disastrous, and overall the movie was just very bad.'\n",
      "Review B: 'I thought this movie was great, I loved it. The acting was beautiful, the plot was perfect, and overall the movie was just very good.'\n",
      "Review A Sentiment:\n",
      "[' Negative', ' Positive']\n",
      "tensor(-0.6291, device='cuda:0') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(all_prompts), 1):\n",
    "    logits, _ = model.run_with_cache(all_prompts[i])\n",
    "    log_diff = get_logit_diff(logits, answer_tokens[i].unsqueeze(0))\n",
    "    #if log_diff < 0.1:\n",
    "    print(all_prompts[i])\n",
    "    print(model.to_str_tokens(answer_tokens[i][0]))\n",
    "    print(log_diff, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4765b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = all_prompts[:36]\n",
    "answer_tokens = answer_tokens[:36]\n",
    "clean_tokens = clean_tokens[:36]\n",
    "corrupted_tokens = corrupted_tokens[:36]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a9e84c0",
   "metadata": {},
   "source": [
    "#### Logit Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8adb4951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9954, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_logits, pos_cache = model.run_with_cache(clean_tokens[0::2,:])\n",
    "pos_logit_diff = get_logit_diff(pos_logits, answer_tokens[0::2,:])\n",
    "pos_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82c41dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9937, device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_logits, neg_cache = model.run_with_cache(clean_tokens[1::2,:])\n",
    "neg_logit_diff = get_logit_diff(neg_logits, answer_tokens[1::2,:])\n",
    "neg_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ce996af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8580, device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
    "clean_logit_diff = get_logit_diff(clean_logits, answer_tokens, per_prompt=False)\n",
    "clean_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "31adef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8002, device='cuda:0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_logits, corrupted_cache = model.run_with_cache(corrupted_tokens)\n",
    "corrupted_logit_diff = get_logit_diff(corrupted_logits, answer_tokens, per_prompt=False)\n",
    "corrupted_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c000ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>Logit diff variation: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           -0.0021333619952201843,
           -0.00027278406196273863,
           0.0004559468070510775,
           -0.00014342291979119182,
           -0.00027066221809946,
           0.0001880178169813007,
           0.000010357523024140391,
           0.0004561266105156392,
           -0.00043379320413805544,
           -0.00012112547847209498,
           0.0007872796268202364,
           -0.00043638257193379104,
           -0.0011346163228154182,
           -0.00003686271156766452,
           0.00038977371877990663,
           -0.00007724986062385142,
           0.0003197885234840214,
           0.005669665057212114,
           0.0007714196690358222,
           -0.00027109376969747245,
           0.0009046649211086333,
           0.0006405840395018458,
           0.000017909884263644926,
           -0.00018442145665176213,
           0.000004603343768394552,
           -0.0007309606298804283,
           -0.00017845148977357894,
           0.00009994290303438902,
           0.00034611389855854213,
           0.00002848318763426505,
           0.0012384073343127966,
           -0.001043448457494378
          ],
          [
           0.00010152530012419447,
           0.0023135757073760033,
           0.0009788578609004617,
           0.00009911574306897819,
           0.00011378889757907018,
           -0.001709890435449779,
           -0.0016811194363981485,
           0.00021952194219920784,
           -0.0006446838960982859,
           -0.0004747197963297367,
           0.0017696619033813477,
           0.0023362687788903713,
           -0.003523751627653837,
           -0.00045087593025527894,
           0.00015777240332681686,
           -0.0002217516885139048,
           -0.00029292370891198516,
           0.0009767719311639667,
           -0.0001929807913256809,
           0.0004777407448273152,
           0.0003081003378611058,
           0.00006192935688886791,
           0.0001634906220715493,
           -0.000022944790543988347,
           0.002299729734659195,
           -0.00040829498902894557,
           -0.0006997801247052848,
           0.0043204897083342075,
           -0.0000643029561615549,
           -0.00010084199311677366,
           0.00014496935182251036,
           -0.001317023765295744
          ],
          [
           -0.0002717411261983216,
           0.0018055177060887218,
           0.004009476397186518,
           -0.005324845667928457,
           0.00007117200584616512,
           0.001553160953335464,
           0.00011306962551316246,
           -0.0007942925440147519,
           0.00034460340975783765,
           -0.0014107809402048588,
           -0.0001927650155266747,
           -0.000624076696112752,
           0.0009074340923689306,
           -0.00037394973332993686,
           0.0007125112460926175,
           0.00013493550068233162,
           0.0003789127222262323,
           0.0006345421425066888,
           -0.00032000429928302765,
           0.0003606432001106441,
           0.00011803260713350028,
           0.00045641433098353446,
           -0.0006787054589949548,
           -0.000043192310840822756,
           -0.0003497102588880807,
           0.0003557161835487932,
           -0.005822258535772562,
           0.0007609542808495462,
           -0.0011616250267252326,
           -0.00010674002987798303,
           0.00038678874261677265,
           0.00010573304462013766
          ],
          [
           0.00019848323427140713,
           0.0019382593454793096,
           -0.00021793955238536,
           -0.0005488767637871206,
           -0.00009508781658951193,
           0.00013547496928367764,
           -0.0059617613442242146,
           -0.00007012906280579045,
           0.000012910940313304309,
           -0.0009155618608929217,
           0.00037215155316516757,
           -0.00027900576242245734,
           -0.0008077429374679923,
           0.000047903544327709824,
           -0.00791214033961296,
           0.000621667189989239,
           0.0016057756729424,
           -0.00009544745262246579,
           0.0004942120867781341,
           0.0004573853511828929,
           0.0002326846297364682,
           -0.002409059088677168,
           -0.0019029791001230478,
           -0.00006117411976447329,
           0.0003642395604401827,
           0.0003100064059253782,
           -0.0010771104134619236,
           0.000039847691368777305,
           -0.0021308085415512323,
           -0.004721016623079777,
           0.000027871807105839252,
           -0.0014232243411242962
          ],
          [
           0.0001358705630991608,
           -0.0005343115190044045,
           0.00024466050672344863,
           -0.00046824634773656726,
           0.0008768650004640222,
           -0.0004524942778516561,
           -0.0020382022485136986,
           0.0005519337137229741,
           0.00038588966708630323,
           0.0011995666427537799,
           -0.0005040661199018359,
           0.0007826762739568949,
           0.00011903958511538804,
           -0.0010757438139989972,
           0.002008280484005809,
           -0.0002371081500314176,
           0.0018440346466377378,
           -0.00013500743079930544,
           -0.0011370618594810367,
           -0.00047356897266581655,
           -0.0011101251002401114,
           0.0006286081625148654,
           0.0009013203089125454,
           -0.0008374488679692149,
           0.0022603136021643877,
           -0.002771248808130622,
           0.0005786546971648932,
           -0.00045357318595051765,
           -0.000022513226213050075,
           -0.0008812525775283575,
           0.00009907977801049128,
           -0.0045766583643853664
          ],
          [
           -0.0036071513313800097,
           -0.0004597589431796223,
           -0.0028510880656540394,
           -0.0005600614822469652,
           0.005324845667928457,
           -0.0005105395684950054,
           -0.002548741875216365,
           0.0015046820044517517,
           0.002626135479658842,
           -0.0004770933883264661,
           0.00007624287536600605,
           0.0010281999129801989,
           -0.012353504076600075,
           0.002339721191674471,
           0.001754593220539391,
           0.001996484585106373,
           -0.006958313286304474,
           -0.004129630513489246,
           0.0021842506248503923,
           0.0007423970382660627,
           0.003038134891539812,
           -0.00019197381334379315,
           -0.0003974699357058853,
           -0.0017066176515072584,
           0.00032806015224196017,
           0.0001236429379787296,
           -0.001361798495054245,
           -0.0007022256613709033,
           -0.00011968693434027955,
           -0.0005591983790509403,
           -0.00018607577658258379,
           0.00016395814600400627
          ],
          [
           -0.00017284115892834961,
           -0.0008826191769912839,
           0.0010472247377038002,
           -0.002766034100204706,
           -0.005509554874151945,
           -0.00009947537910193205,
           -0.003288405714556575,
           -0.010083336383104324,
           -0.0001102644600905478,
           0.0007650901097804308,
           -0.00012576478184200823,
           0.000037546022213064134,
           0.00022031314438208938,
           0.008836477994918823,
           -0.000023484244593419135,
           0.00103485316503793,
           -0.00002639729791553691,
           -0.0005987583426758647,
           -0.00030324526596814394,
           -0.0034573266748338938,
           0.0003282040124759078,
           0.0018242187798023224,
           -0.001094588777050376,
           -0.0035527022555470467,
           0.0004385763604659587,
           0.0012798733077943325,
           -0.00006789931649109349,
           0.0008615445112809539,
           -0.0008077789098024368,
           -0.0014106730232015252,
           -0.0003514724667184055,
           0.0024683992378413677
          ],
          [
           0.0022695562802255154,
           0.0003896658308804035,
           0.0011394714238122106,
           0.0019391225650906563,
           0.000015104720660019666,
           -0.0009508062503300607,
           0.003666491247713566,
           -0.001215210766531527,
           -0.00010630846372805536,
           -0.0017939374083653092,
           0.005593997426331043,
           0.00033956850529648364,
           0.000860213884152472,
           0.0006309098098427057,
           -0.0015139965107664466,
           0.004114885814487934,
           0.000486084318254143,
           -0.0009985299548134208,
           -0.0005877894582226872,
           0.00008843454270390794,
           -0.002883347449824214,
           -0.000031540097552351654,
           0.0012423992156982422,
           -0.00009228265116689727,
           0.0009685722761787474,
           0.004275606945157051,
           -0.0006739942473359406,
           0.002648361027240753,
           -0.0017260380554944277,
           -0.0033620952162891626,
           -8.990905371319968e-7,
           0.0002842204994522035
          ],
          [
           0.00006847473559901118,
           0.0007204951834864914,
           -0.0012702710228040814,
           -0.009122676216065884,
           -0.0003283119003754109,
           -0.0006319527747109532,
           -0.0001836302544688806,
           -0.00012285173579584807,
           -0.0005899472744204104,
           0.0004482146177906543,
           -0.004182173404842615,
           0.0006874086684547365,
           0.002905968576669693,
           0.0013725876342505217,
           0.0070516751147806644,
           0.00016946058894973248,
           -0.0026193384546786547,
           0.0009618111071176827,
           -0.00022675063519272953,
           0.0007400953909382224,
           -0.00007724986062385142,
           0.004222704563289881,
           0.0005907744052819908,
           0.0010351049713790417,
           -0.00021412740170489997,
           -0.0005711382837034762,
           -0.0018655050080269575,
           -0.000039883656427264214,
           0.00011112759239040315,
           -0.0006857903208583593,
           -0.0006559045286849141,
           -0.00007786123751429841
          ],
          [
           -0.0017540897242724895,
           0.00012342714762780815,
           -0.00022157187049742788,
           0.0020438844803720713,
           -0.0006038292194716632,
           0.000902363215573132,
           -0.0009307385189458728,
           -0.000531722151208669,
           0.0002656992292031646,
           0.0028668760787695646,
           -0.00039635508437640965,
           -0.0011344364611431956,
           0.0009269623551517725,
           -0.0006823737639933825,
           -0.004971647169440985,
           -0.0004789635131601244,
           0.0003984050126746297,
           -0.00033669141703285277,
           -0.000009638250958232675,
           0.016672663390636444,
           0.001214671297930181,
           -0.0011817646445706487,
           -0.001320188632234931,
           -0.00012605248775798827,
           0.002207554876804352,
           -0.0005645209457725286,
           0.0036077986005693674,
           -0.004669229034334421,
           0.0052398997358977795,
           -0.0005137763218954206,
           -0.001606710720807314,
           -0.005302620120346546
          ],
          [
           -0.0005518257967196405,
           -0.0006054835394024849,
           0.0007762028253637254,
           0.005115249659866095,
           0.0031459536403417587,
           -0.0012655598111450672,
           -0.0019337639678269625,
           -0.005025736056268215,
           0.0017417900962755084,
           -0.000020643119569285773,
           0.0005185954505577683,
           0.00017521476547699422,
           0.0004610536270774901,
           -0.000008127778528432827,
           0.016715100035071373,
           0.0003293908084742725,
           0.0032411133870482445,
           0.0013815425336360931,
           0.0003172710712533444,
           0.0033133283723145723,
           -0.0005049292230978608,
           -0.005516100209206343,
           -0.027340156957507133,
           -0.002047085203230381,
           0.00018291098240297288,
           -0.0022615722846239805,
           0.0011938483221456409,
           0.009301775135099888,
           0.0013013076968491077,
           -0.007385273464024067,
           0.006780797149986029,
           -0.0014575696550309658
          ],
          [
           -0.03716498613357544,
           0.004456971772015095,
           -0.0006158410687930882,
           -0.006901599001139402,
           -0.0012445570901036263,
           0.0026956533547490835,
           0.010813217610120773,
           0.005042891018092632,
           -0.012961288914084435,
           0.00046691569150425494,
           0.0028817648999392986,
           0.004129199311137199,
           -0.010652280412614346,
           -0.0008564376621507108,
           -0.001640876173041761,
           0.0007408146630041301,
           0.003207199741154909,
           -0.0017516441876068711,
           0.001708272029645741,
           -0.0006423821905627847,
           0.0003790206101257354,
           0.0024812740739434958,
           -0.0009690398001112044,
           0.00020193573436699808,
           0.000060418882640078664,
           -0.0020795604214072227,
           -0.0014883545227348804,
           0.001470192801207304,
           0.00042638470767997205,
           0.03633429855108261,
           0.000841081200633198,
           0.0037584861274808645
          ],
          [
           -0.006136005278676748,
           -0.004509586375206709,
           -0.12178944051265717,
           0.000008487414561386686,
           -0.016903262585401535,
           0.020520374178886414,
           0.0007901207427494228,
           0.0001684535964159295,
           -0.0002853353798855096,
           0.00006423102604458109,
           -0.0020543138962239027,
           0.001571682165376842,
           -0.0014624247560277581,
           0.0003607510880101472,
           -0.0026920209638774395,
           0.0008589191711507738,
           0.002055680612102151,
           0.0015663955127820373,
           -0.0008945231675170362,
           -0.0029991501942276955,
           0.0029495563358068466,
           0.003232554066926241,
           -0.0007908400148153305,
           -0.00171276752371341,
           0.000085737272456754,
           0.0036910902708768845,
           -0.0010007956298068166,
           -0.0038449426647275686,
           0.003326275385916233,
           -0.00017496301734354347,
           -0.0028644304256886244,
           0.00732672493904829
          ],
          [
           -0.0011391117004677653,
           0.0009679968352429569,
           -0.0051114377565681934,
           0.0034924272913485765,
           0.007310900837182999,
           0.0018510835943743587,
           -0.010604269802570343,
           0.0004833510611206293,
           -0.06220627576112747,
           -0.005999523214995861,
           -0.0008513667853549123,
           -0.0001910747232614085,
           0.009649974294006824,
           0.00004459488991415128,
           -0.002317927312105894,
           -0.011813114397227764,
           0.0037659306544810534,
           0.008751495741307735,
           0.00007735774852335453,
           -0.014636115171015263,
           -0.01713382452726364,
           -0.0029927846044301987,
           -0.022291475906968117,
           0.0024139501620084047,
           -0.0005253925337456167,
           0.0001108398791984655,
           0.0006089000962674618,
           -0.004510880913585424,
           0.0004358431324362755,
           -0.020597301423549652,
           0.03276127576828003,
           -0.017556864768266678
          ],
          [
           0.0023123889695852995,
           -0.024908583611249924,
           -0.0021771297324448824,
           -0.004128767643123865,
           -0.0661335363984108,
           0.008567973040044308,
           -0.0019608086440712214,
           0.005275791510939598,
           0.02801850251853466,
           0.0015026320470497012,
           0.0003459700383245945,
           -0.0002858388761524111,
           -0.013834557496011257,
           0.002004000823944807,
           -0.003096791449934244,
           -0.0036773881874978542,
           0.01513057854026556,
           0.008544884622097015,
           0.006532216444611549,
           0.004650671500712633,
           -0.00043249852024018764,
           0.0007057501352392137,
           0.009243441745638847,
           -0.016652092337608337,
           -0.025697626173496246,
           -0.005832795985043049,
           0.0015643815277144313,
           -0.003803081111982465,
           -0.0031553402077406645,
           0.01402980461716652,
           -0.03003832697868347,
           0.01879800483584404
          ],
          [
           -0.004250648431479931,
           -0.00905161164700985,
           0.009017374366521835,
           0.04387518763542175,
           -0.02076812833547592,
           -0.00796536635607481,
           -0.00006207320984685794,
           -0.00037042528856545687,
           0.0003679797810036689,
           0.014617557637393475,
           -0.012318115681409836,
           0.008895386010408401,
           0.007581382989883423,
           -0.0011998183326795697,
           -0.009961527772247791,
           0.0001756463316269219,
           -0.013987870886921883,
           -0.0040604728274047375,
           0.0003902412427123636,
           0.004465458914637566,
           0.027152031660079956,
           0.0023784900549799204,
           0.00029051414458081126,
           -0.0008566894102841616,
           -0.002303973538801074,
           0.00011950711632380262,
           -0.04040347412228584,
           -0.0034553129225969315,
           -0.008535030297935009,
           0.008722544647753239,
           0.002957648131996393,
           -0.0012511024251580238
          ],
          [
           0.009729850105941296,
           -0.013865917921066284,
           -0.0011989192571491003,
           0.0008452170295640826,
           0.006485319696366787,
           -0.004207240417599678,
           0.002516878070309758,
           -0.004653908312320709,
           -0.016643101349473,
           -0.0006796045345254242,
           0.007431306876242161,
           0.006408573593944311,
           0.00038387568201869726,
           0.0007398076704703271,
           0.0005834018811583519,
           0.024822810664772987,
           0.001462208922021091,
           -0.0035004832316190004,
           0.006760153919458389,
           -0.002276856917887926,
           -0.002617144724354148,
           -0.001962319016456604,
           -0.0029523614794015884,
           -0.009130660444498062,
           -0.012256329879164696,
           0.0025107641704380512,
           0.0012399896513670683,
           -0.006979172118008137,
           -0.0033583547919988632,
           0.0020623698364943266,
           0.003945281263440847,
           0.0020653908140957355
          ],
          [
           0.000419299874920398,
           -0.00013752488302998245,
           0.00009476414561504498,
           0.001697411062195897,
           0.00276452349498868,
           0.0001934842875925824,
           -0.04814910516142845,
           -0.03402191027998924,
           -0.001090165227651596,
           -0.0006067781941965222,
           0.007717325817793608,
           0.0022786189801990986,
           -0.006280542816966772,
           0.0012624310329556465,
           -0.0016786380438134074,
           -0.0013425219804048538,
           0.004093487281352282,
           -0.0025825477205216885,
           -0.0035579889081418514,
           -0.1582338958978653,
           0.003708928357809782,
           0.00030475572566501796,
           -0.01136572752147913,
           -0.00007638673559995368,
           0.004172319546341896,
           -0.0035135739017277956,
           -0.0007244871812872589,
           0.007082747761160135,
           -0.015500788576900959,
           0.0023292198311537504,
           -0.011195331811904907,
           -0.0012700193328782916
          ],
          [
           0.010005762800574303,
           -0.0005274065188132226,
           0.001093725673854351,
           0.0010994438780471683,
           0.00018294694018550217,
           0.0022610328160226345,
           -0.0032023806124925613,
           0.0048227934166789055,
           -0.01616927981376648,
           -0.00854006502777338,
           0.007039375603199005,
           -0.0014970217598602176,
           0.00013061986828688532,
           0.004810170270502567,
           -0.00022326216276269406,
           0.0004053819284308702,
           -0.004348433576524258,
           -0.0009093761327676475,
           0.0009517053258605301,
           -0.0009047368075698614,
           -0.00012231228174641728,
           -0.0011143687879666686,
           -0.0025300048291683197,
           0.0005930401384830475,
           0.0020470493473112583,
           -0.002715541049838066,
           0.004141714423894882,
           0.004277764819562435,
           0.002491559600457549,
           -0.0016542546218261123,
           -0.00248760380782187,
           0.0007125112460926175
          ],
          [
           -0.011670230887830257,
           0.00044983296538703144,
           -0.005167900584638119,
           0.00018960020679514855,
           -0.00024325793492607772,
           -0.0002131204237230122,
           -0.006358368322253227,
           -0.00006595728336833417,
           0.0006574869039468467,
           0.0005328010302037001,
           0.0005484452121891081,
           -0.00297235744073987,
           -0.017651088535785675,
           0.0036096686962991953,
           0.0030880882404744625,
           0.06831563264131546,
           -0.0009327884763479233,
           -0.003060540184378624,
           0.004188575316220522,
           -0.0014086590381339192,
           0.0003602116194088012,
           0.000011796068065450527,
           0.00005639095979859121,
           -0.000390169327147305,
           0.000257067964412272,
           -0.0004863000940531492,
           -0.0007400594186037779,
           0.0009233300224877894,
           -0.0008904592832550406,
           -0.01634863018989563,
           -0.0005699514877051115,
           0.00021416335948742926
          ],
          [
           -0.002765890210866928,
           0.001673567108809948,
           0.009469293057918549,
           0.0012861309805884957,
           -0.0017100701807066798,
           -0.002528818091377616,
           -0.0016524564707651734,
           -0.00508619099855423,
           0.006191784981638193,
           0.0033888521138578653,
           -0.19967390596866608,
           0.0006333913188427687,
           -0.0013381344033405185,
           -0.00043328970787115395,
           0.00614053662866354,
           0.0028885980136692524,
           -0.0007113604224286973,
           0.013254105113446712,
           -0.0010627969168126583,
           -0.02422962710261345,
           0.00026016082847490907,
           -0.00000740850600777776,
           -0.00037222346873022616,
           0.002805414143949747,
           -0.000538303458597511,
           0.010576684959232807,
           0.0014617054257541895,
           0.009015612304210663,
           -0.00007814895070623606,
           -0.004680952988564968,
           -0.0035952471662312746,
           -0.0002149186038877815
          ],
          [
           0.00011734930012607947,
           0.0007305649924091995,
           0.0005303555517457426,
           0.000027979696824331768,
           -0.0009628899861127138,
           -0.0007630041800439358,
           0.0012480455916374922,
           0.00012630423589143902,
           -0.032926060259342194,
           -0.0056467922404408455,
           -0.0001928369456436485,
           0.0022991544101387262,
           0.0014550162013620138,
           0.0007230126648209989,
           0.00409363117069006,
           -0.0034689069725573063,
           -0.002236793516203761,
           -0.001161984633654356,
           0.0009839286794885993,
           0.00011749315308406949,
           -0.0023440008517354727,
           0.0013780540321022272,
           0.0019357778364792466,
           0.007803314831107855,
           -0.06057989224791527,
           0.00008070236799539998,
           -0.0021541130263358355,
           0.0004521346418187022,
           0.0013717603869736195,
           -0.001249448163434863,
           -0.00265325210057199,
           0.002341483486816287
          ],
          [
           0.00032604619627818465,
           -0.0029871384613215923,
           -0.00003279882366769016,
           0.004786002915352583,
           0.0015191752463579178,
           -0.0984983891248703,
           -0.0010597760556265712,
           0.00037125247763469815,
           -0.00007742967864032835,
           -0.004416943993419409,
           0.0007811298710294068,
           0.00036290890420787036,
           -0.0005673621199093759,
           0.00035283909528516233,
           0.004079533275216818,
           -0.030034730210900307,
           -0.0011491456534713507,
           -0.0013243963476270437,
           -0.00013511533325072378,
           -0.0003269812441430986,
           -0.0008555745589546859,
           0.0011349399574100971,
           0.0045576696284115314,
           -0.0001542120153317228,
           0.0016795011470094323,
           0.003147680079564452,
           0.0049338494427502155,
           0.007404334377497435,
           0.006978884804993868,
           -0.0017632603412494063,
           -0.008392902091145515,
           0.007362904027104378
          ],
          [
           0.001872373977676034,
           0.00002848318763426505,
           0.004149446729570627,
           -0.0003930464154109359,
           0.0003711086174007505,
           -0.001674789935350418,
           0.0001966490817721933,
           0.001007341081276536,
           -0.00006894225953146815,
           0.0006040090229362249,
           -0.0002821705711539835,
           0.0003981172922067344,
           0.0006298668449744582,
           0.0025731970090419054,
           0.014773423783481121,
           -0.00044112978503108025,
           0.003255534917116165,
           0.0006227460689842701,
           -0.0006718364311382174,
           -0.000665830506477505,
           -0.00007714196544839069,
           0.0007076921174302697,
           0.0016523845260962844,
           0.00039804537664167583,
           -0.00010256825044052675,
           -0.006987911649048328,
           0.005029224790632725,
           -0.0019240897381678224,
           -0.004340161569416523,
           -0.009630266577005386,
           0.00279394187964499,
           0.0020788051187992096
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorbar": {
          "title": {
           "text": "Logit diff variation"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "margin": {
         "l": 100,
         "r": 100
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Direct effect on logit diff (patch from head output -> final resid)"
        },
        "width": 600,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "scaleanchor": "y",
         "showline": true,
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "linecolor": "black",
         "linewidth": 1,
         "mirror": true,
         "showline": true,
         "title": {
          "text": "Layer"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"181710b4-862a-4b7e-946e-35c8b5d83d49\" class=\"plotly-graph-div\" style=\"height:525px; width:600px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"181710b4-862a-4b7e-946e-35c8b5d83d49\")) {                    Plotly.newPlot(                        \"181710b4-862a-4b7e-946e-35c8b5d83d49\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[-0.0021333619952201843,-0.00027278406196273863,0.0004559468070510775,-0.00014342291979119182,-0.00027066221809946,0.0001880178169813007,1.0357523024140391e-05,0.0004561266105156392,-0.00043379320413805544,-0.00012112547847209498,0.0007872796268202364,-0.00043638257193379104,-0.0011346163228154182,-3.686271156766452e-05,0.00038977371877990663,-7.724986062385142e-05,0.0003197885234840214,0.005669665057212114,0.0007714196690358222,-0.00027109376969747245,0.0009046649211086333,0.0006405840395018458,1.7909884263644926e-05,-0.00018442145665176213,4.603343768394552e-06,-0.0007309606298804283,-0.00017845148977357894,9.994290303438902e-05,0.00034611389855854213,2.848318763426505e-05,0.0012384073343127966,-0.001043448457494378],[0.00010152530012419447,0.0023135757073760033,0.0009788578609004617,9.911574306897819e-05,0.00011378889757907018,-0.001709890435449779,-0.0016811194363981485,0.00021952194219920784,-0.0006446838960982859,-0.0004747197963297367,0.0017696619033813477,0.0023362687788903713,-0.003523751627653837,-0.00045087593025527894,0.00015777240332681686,-0.0002217516885139048,-0.00029292370891198516,0.0009767719311639667,-0.0001929807913256809,0.0004777407448273152,0.0003081003378611058,6.192935688886791e-05,0.0001634906220715493,-2.2944790543988347e-05,0.002299729734659195,-0.00040829498902894557,-0.0006997801247052848,0.0043204897083342075,-6.43029561615549e-05,-0.00010084199311677366,0.00014496935182251036,-0.001317023765295744],[-0.0002717411261983216,0.0018055177060887218,0.004009476397186518,-0.005324845667928457,7.117200584616512e-05,0.001553160953335464,0.00011306962551316246,-0.0007942925440147519,0.00034460340975783765,-0.0014107809402048588,-0.0001927650155266747,-0.000624076696112752,0.0009074340923689306,-0.00037394973332993686,0.0007125112460926175,0.00013493550068233162,0.0003789127222262323,0.0006345421425066888,-0.00032000429928302765,0.0003606432001106441,0.00011803260713350028,0.00045641433098353446,-0.0006787054589949548,-4.3192310840822756e-05,-0.0003497102588880807,0.0003557161835487932,-0.005822258535772562,0.0007609542808495462,-0.0011616250267252326,-0.00010674002987798303,0.00038678874261677265,0.00010573304462013766],[0.00019848323427140713,0.0019382593454793096,-0.00021793955238536,-0.0005488767637871206,-9.508781658951193e-05,0.00013547496928367764,-0.0059617613442242146,-7.012906280579045e-05,1.2910940313304309e-05,-0.0009155618608929217,0.00037215155316516757,-0.00027900576242245734,-0.0008077429374679923,4.7903544327709824e-05,-0.00791214033961296,0.000621667189989239,0.0016057756729424,-9.544745262246579e-05,0.0004942120867781341,0.0004573853511828929,0.0002326846297364682,-0.002409059088677168,-0.0019029791001230478,-6.117411976447329e-05,0.0003642395604401827,0.0003100064059253782,-0.0010771104134619236,3.9847691368777305e-05,-0.0021308085415512323,-0.004721016623079777,2.7871807105839252e-05,-0.0014232243411242962],[0.0001358705630991608,-0.0005343115190044045,0.00024466050672344863,-0.00046824634773656726,0.0008768650004640222,-0.0004524942778516561,-0.0020382022485136986,0.0005519337137229741,0.00038588966708630323,0.0011995666427537799,-0.0005040661199018359,0.0007826762739568949,0.00011903958511538804,-0.0010757438139989972,0.002008280484005809,-0.0002371081500314176,0.0018440346466377378,-0.00013500743079930544,-0.0011370618594810367,-0.00047356897266581655,-0.0011101251002401114,0.0006286081625148654,0.0009013203089125454,-0.0008374488679692149,0.0022603136021643877,-0.002771248808130622,0.0005786546971648932,-0.00045357318595051765,-2.2513226213050075e-05,-0.0008812525775283575,9.907977801049128e-05,-0.0045766583643853664],[-0.0036071513313800097,-0.0004597589431796223,-0.0028510880656540394,-0.0005600614822469652,0.005324845667928457,-0.0005105395684950054,-0.002548741875216365,0.0015046820044517517,0.002626135479658842,-0.0004770933883264661,7.624287536600605e-05,0.0010281999129801989,-0.012353504076600075,0.002339721191674471,0.001754593220539391,0.001996484585106373,-0.006958313286304474,-0.004129630513489246,0.0021842506248503923,0.0007423970382660627,0.003038134891539812,-0.00019197381334379315,-0.0003974699357058853,-0.0017066176515072584,0.00032806015224196017,0.0001236429379787296,-0.001361798495054245,-0.0007022256613709033,-0.00011968693434027955,-0.0005591983790509403,-0.00018607577658258379,0.00016395814600400627],[-0.00017284115892834961,-0.0008826191769912839,0.0010472247377038002,-0.002766034100204706,-0.005509554874151945,-9.947537910193205e-05,-0.003288405714556575,-0.010083336383104324,-0.0001102644600905478,0.0007650901097804308,-0.00012576478184200823,3.7546022213064134e-05,0.00022031314438208938,0.008836477994918823,-2.3484244593419135e-05,0.00103485316503793,-2.639729791553691e-05,-0.0005987583426758647,-0.00030324526596814394,-0.0034573266748338938,0.0003282040124759078,0.0018242187798023224,-0.001094588777050376,-0.0035527022555470467,0.0004385763604659587,0.0012798733077943325,-6.789931649109349e-05,0.0008615445112809539,-0.0008077789098024368,-0.0014106730232015252,-0.0003514724667184055,0.0024683992378413677],[0.0022695562802255154,0.0003896658308804035,0.0011394714238122106,0.0019391225650906563,1.5104720660019666e-05,-0.0009508062503300607,0.003666491247713566,-0.001215210766531527,-0.00010630846372805536,-0.0017939374083653092,0.005593997426331043,0.00033956850529648364,0.000860213884152472,0.0006309098098427057,-0.0015139965107664466,0.004114885814487934,0.000486084318254143,-0.0009985299548134208,-0.0005877894582226872,8.843454270390794e-05,-0.002883347449824214,-3.1540097552351654e-05,0.0012423992156982422,-9.228265116689727e-05,0.0009685722761787474,0.004275606945157051,-0.0006739942473359406,0.002648361027240753,-0.0017260380554944277,-0.0033620952162891626,-8.990905371319968e-07,0.0002842204994522035],[6.847473559901118e-05,0.0007204951834864914,-0.0012702710228040814,-0.009122676216065884,-0.0003283119003754109,-0.0006319527747109532,-0.0001836302544688806,-0.00012285173579584807,-0.0005899472744204104,0.0004482146177906543,-0.004182173404842615,0.0006874086684547365,0.002905968576669693,0.0013725876342505217,0.0070516751147806644,0.00016946058894973248,-0.0026193384546786547,0.0009618111071176827,-0.00022675063519272953,0.0007400953909382224,-7.724986062385142e-05,0.004222704563289881,0.0005907744052819908,0.0010351049713790417,-0.00021412740170489997,-0.0005711382837034762,-0.0018655050080269575,-3.9883656427264214e-05,0.00011112759239040315,-0.0006857903208583593,-0.0006559045286849141,-7.786123751429841e-05],[-0.0017540897242724895,0.00012342714762780815,-0.00022157187049742788,0.0020438844803720713,-0.0006038292194716632,0.000902363215573132,-0.0009307385189458728,-0.000531722151208669,0.0002656992292031646,0.0028668760787695646,-0.00039635508437640965,-0.0011344364611431956,0.0009269623551517725,-0.0006823737639933825,-0.004971647169440985,-0.0004789635131601244,0.0003984050126746297,-0.00033669141703285277,-9.638250958232675e-06,0.016672663390636444,0.001214671297930181,-0.0011817646445706487,-0.001320188632234931,-0.00012605248775798827,0.002207554876804352,-0.0005645209457725286,0.0036077986005693674,-0.004669229034334421,0.0052398997358977795,-0.0005137763218954206,-0.001606710720807314,-0.005302620120346546],[-0.0005518257967196405,-0.0006054835394024849,0.0007762028253637254,0.005115249659866095,0.0031459536403417587,-0.0012655598111450672,-0.0019337639678269625,-0.005025736056268215,0.0017417900962755084,-2.0643119569285773e-05,0.0005185954505577683,0.00017521476547699422,0.0004610536270774901,-8.127778528432827e-06,0.016715100035071373,0.0003293908084742725,0.0032411133870482445,0.0013815425336360931,0.0003172710712533444,0.0033133283723145723,-0.0005049292230978608,-0.005516100209206343,-0.027340156957507133,-0.002047085203230381,0.00018291098240297288,-0.0022615722846239805,0.0011938483221456409,0.009301775135099888,0.0013013076968491077,-0.007385273464024067,0.006780797149986029,-0.0014575696550309658],[-0.03716498613357544,0.004456971772015095,-0.0006158410687930882,-0.006901599001139402,-0.0012445570901036263,0.0026956533547490835,0.010813217610120773,0.005042891018092632,-0.012961288914084435,0.00046691569150425494,0.0028817648999392986,0.004129199311137199,-0.010652280412614346,-0.0008564376621507108,-0.001640876173041761,0.0007408146630041301,0.003207199741154909,-0.0017516441876068711,0.001708272029645741,-0.0006423821905627847,0.0003790206101257354,0.0024812740739434958,-0.0009690398001112044,0.00020193573436699808,6.0418882640078664e-05,-0.0020795604214072227,-0.0014883545227348804,0.001470192801207304,0.00042638470767997205,0.03633429855108261,0.000841081200633198,0.0037584861274808645],[-0.006136005278676748,-0.004509586375206709,-0.12178944051265717,8.487414561386686e-06,-0.016903262585401535,0.020520374178886414,0.0007901207427494228,0.0001684535964159295,-0.0002853353798855096,6.423102604458109e-05,-0.0020543138962239027,0.001571682165376842,-0.0014624247560277581,0.0003607510880101472,-0.0026920209638774395,0.0008589191711507738,0.002055680612102151,0.0015663955127820373,-0.0008945231675170362,-0.0029991501942276955,0.0029495563358068466,0.003232554066926241,-0.0007908400148153305,-0.00171276752371341,8.5737272456754e-05,0.0036910902708768845,-0.0010007956298068166,-0.0038449426647275686,0.003326275385916233,-0.00017496301734354347,-0.0028644304256886244,0.00732672493904829],[-0.0011391117004677653,0.0009679968352429569,-0.0051114377565681934,0.0034924272913485765,0.007310900837182999,0.0018510835943743587,-0.010604269802570343,0.0004833510611206293,-0.06220627576112747,-0.005999523214995861,-0.0008513667853549123,-0.0001910747232614085,0.009649974294006824,4.459488991415128e-05,-0.002317927312105894,-0.011813114397227764,0.0037659306544810534,0.008751495741307735,7.735774852335453e-05,-0.014636115171015263,-0.01713382452726364,-0.0029927846044301987,-0.022291475906968117,0.0024139501620084047,-0.0005253925337456167,0.0001108398791984655,0.0006089000962674618,-0.004510880913585424,0.0004358431324362755,-0.020597301423549652,0.03276127576828003,-0.017556864768266678],[0.0023123889695852995,-0.024908583611249924,-0.0021771297324448824,-0.004128767643123865,-0.0661335363984108,0.008567973040044308,-0.0019608086440712214,0.005275791510939598,0.02801850251853466,0.0015026320470497012,0.0003459700383245945,-0.0002858388761524111,-0.013834557496011257,0.002004000823944807,-0.003096791449934244,-0.0036773881874978542,0.01513057854026556,0.008544884622097015,0.006532216444611549,0.004650671500712633,-0.00043249852024018764,0.0007057501352392137,0.009243441745638847,-0.016652092337608337,-0.025697626173496246,-0.005832795985043049,0.0015643815277144313,-0.003803081111982465,-0.0031553402077406645,0.01402980461716652,-0.03003832697868347,0.01879800483584404],[-0.004250648431479931,-0.00905161164700985,0.009017374366521835,0.04387518763542175,-0.02076812833547592,-0.00796536635607481,-6.207320984685794e-05,-0.00037042528856545687,0.0003679797810036689,0.014617557637393475,-0.012318115681409836,0.008895386010408401,0.007581382989883423,-0.0011998183326795697,-0.009961527772247791,0.0001756463316269219,-0.013987870886921883,-0.0040604728274047375,0.0003902412427123636,0.004465458914637566,0.027152031660079956,0.0023784900549799204,0.00029051414458081126,-0.0008566894102841616,-0.002303973538801074,0.00011950711632380262,-0.04040347412228584,-0.0034553129225969315,-0.008535030297935009,0.008722544647753239,0.002957648131996393,-0.0012511024251580238],[0.009729850105941296,-0.013865917921066284,-0.0011989192571491003,0.0008452170295640826,0.006485319696366787,-0.004207240417599678,0.002516878070309758,-0.004653908312320709,-0.016643101349473,-0.0006796045345254242,0.007431306876242161,0.006408573593944311,0.00038387568201869726,0.0007398076704703271,0.0005834018811583519,0.024822810664772987,0.001462208922021091,-0.0035004832316190004,0.006760153919458389,-0.002276856917887926,-0.002617144724354148,-0.001962319016456604,-0.0029523614794015884,-0.009130660444498062,-0.012256329879164696,0.0025107641704380512,0.0012399896513670683,-0.006979172118008137,-0.0033583547919988632,0.0020623698364943266,0.003945281263440847,0.0020653908140957355],[0.000419299874920398,-0.00013752488302998245,9.476414561504498e-05,0.001697411062195897,0.00276452349498868,0.0001934842875925824,-0.04814910516142845,-0.03402191027998924,-0.001090165227651596,-0.0006067781941965222,0.007717325817793608,0.0022786189801990986,-0.006280542816966772,0.0012624310329556465,-0.0016786380438134074,-0.0013425219804048538,0.004093487281352282,-0.0025825477205216885,-0.0035579889081418514,-0.1582338958978653,0.003708928357809782,0.00030475572566501796,-0.01136572752147913,-7.638673559995368e-05,0.004172319546341896,-0.0035135739017277956,-0.0007244871812872589,0.007082747761160135,-0.015500788576900959,0.0023292198311537504,-0.011195331811904907,-0.0012700193328782916],[0.010005762800574303,-0.0005274065188132226,0.001093725673854351,0.0010994438780471683,0.00018294694018550217,0.0022610328160226345,-0.0032023806124925613,0.0048227934166789055,-0.01616927981376648,-0.00854006502777338,0.007039375603199005,-0.0014970217598602176,0.00013061986828688532,0.004810170270502567,-0.00022326216276269406,0.0004053819284308702,-0.004348433576524258,-0.0009093761327676475,0.0009517053258605301,-0.0009047368075698614,-0.00012231228174641728,-0.0011143687879666686,-0.0025300048291683197,0.0005930401384830475,0.0020470493473112583,-0.002715541049838066,0.004141714423894882,0.004277764819562435,0.002491559600457549,-0.0016542546218261123,-0.00248760380782187,0.0007125112460926175],[-0.011670230887830257,0.00044983296538703144,-0.005167900584638119,0.00018960020679514855,-0.00024325793492607772,-0.0002131204237230122,-0.006358368322253227,-6.595728336833417e-05,0.0006574869039468467,0.0005328010302037001,0.0005484452121891081,-0.00297235744073987,-0.017651088535785675,0.0036096686962991953,0.0030880882404744625,0.06831563264131546,-0.0009327884763479233,-0.003060540184378624,0.004188575316220522,-0.0014086590381339192,0.0003602116194088012,1.1796068065450527e-05,5.639095979859121e-05,-0.000390169327147305,0.000257067964412272,-0.0004863000940531492,-0.0007400594186037779,0.0009233300224877894,-0.0008904592832550406,-0.01634863018989563,-0.0005699514877051115,0.00021416335948742926],[-0.002765890210866928,0.001673567108809948,0.009469293057918549,0.0012861309805884957,-0.0017100701807066798,-0.002528818091377616,-0.0016524564707651734,-0.00508619099855423,0.006191784981638193,0.0033888521138578653,-0.19967390596866608,0.0006333913188427687,-0.0013381344033405185,-0.00043328970787115395,0.00614053662866354,0.0028885980136692524,-0.0007113604224286973,0.013254105113446712,-0.0010627969168126583,-0.02422962710261345,0.00026016082847490907,-7.40850600777776e-06,-0.00037222346873022616,0.002805414143949747,-0.000538303458597511,0.010576684959232807,0.0014617054257541895,0.009015612304210663,-7.814895070623606e-05,-0.004680952988564968,-0.0035952471662312746,-0.0002149186038877815],[0.00011734930012607947,0.0007305649924091995,0.0005303555517457426,2.7979696824331768e-05,-0.0009628899861127138,-0.0007630041800439358,0.0012480455916374922,0.00012630423589143902,-0.032926060259342194,-0.0056467922404408455,-0.0001928369456436485,0.0022991544101387262,0.0014550162013620138,0.0007230126648209989,0.00409363117069006,-0.0034689069725573063,-0.002236793516203761,-0.001161984633654356,0.0009839286794885993,0.00011749315308406949,-0.0023440008517354727,0.0013780540321022272,0.0019357778364792466,0.007803314831107855,-0.06057989224791527,8.070236799539998e-05,-0.0021541130263358355,0.0004521346418187022,0.0013717603869736195,-0.001249448163434863,-0.00265325210057199,0.002341483486816287],[0.00032604619627818465,-0.0029871384613215923,-3.279882366769016e-05,0.004786002915352583,0.0015191752463579178,-0.0984983891248703,-0.0010597760556265712,0.00037125247763469815,-7.742967864032835e-05,-0.004416943993419409,0.0007811298710294068,0.00036290890420787036,-0.0005673621199093759,0.00035283909528516233,0.004079533275216818,-0.030034730210900307,-0.0011491456534713507,-0.0013243963476270437,-0.00013511533325072378,-0.0003269812441430986,-0.0008555745589546859,0.0011349399574100971,0.0045576696284115314,-0.0001542120153317228,0.0016795011470094323,0.003147680079564452,0.0049338494427502155,0.007404334377497435,0.006978884804993868,-0.0017632603412494063,-0.008392902091145515,0.007362904027104378],[0.001872373977676034,2.848318763426505e-05,0.004149446729570627,-0.0003930464154109359,0.0003711086174007505,-0.001674789935350418,0.0001966490817721933,0.001007341081276536,-6.894225953146815e-05,0.0006040090229362249,-0.0002821705711539835,0.0003981172922067344,0.0006298668449744582,0.0025731970090419054,0.014773423783481121,-0.00044112978503108025,0.003255534917116165,0.0006227460689842701,-0.0006718364311382174,-0.000665830506477505,-7.714196544839069e-05,0.0007076921174302697,0.0016523845260962844,0.00039804537664167583,-0.00010256825044052675,-0.006987911649048328,0.005029224790632725,-0.0019240897381678224,-0.004340161569416523,-0.009630266577005386,0.00279394187964499,0.0020788051187992096],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003eLogit diff variation: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"},\"showline\":true,\"linewidth\":1,\"linecolor\":\"black\",\"mirror\":true},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Logit diff variation\"}},\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Direct effect on logit diff (patch from head output -\\u003e final resid)\"},\"width\":600,\"margin\":{\"r\":100,\"l\":100}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('181710b4-862a-4b7e-946e-35c8b5d83d49');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_p(\n",
    "    results['z'],\n",
    "    title=\"Direct effect on logit diff (patch from head output -> final resid)\",\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\", \"color\": \"Logit diff variation\"},\n",
    "    border=True,\n",
    "    width=600,\n",
    "    margin={\"r\": 100, \"l\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e4f0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total logit diff contribution above threshold: 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Logit Diff=%{x}<br>Attention Head=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.027340156957507133,
          0.030034730210900307,
          0.03003832697868347,
          0.032926060259342194,
          0.03402191027998924,
          0.03716498613357544,
          0.04040347412228584,
          0.04814910516142845,
          0.06057989224791527,
          0.06220627576112747,
          0.0661335363984108,
          0.0984983891248703,
          0.12178944051265717,
          0.1582338958978653,
          0.19967390596866608
         ],
         "xaxis": "x",
         "y": [
          "Layer 10, Head 22",
          "Layer 22, Head 15",
          "Layer 14, Head 30",
          "Layer 21, Head 8",
          "Layer 17, Head 7",
          "Layer 11, Head 0",
          "Layer 15, Head 26",
          "Layer 17, Head 6",
          "Layer 21, Head 24",
          "Layer 13, Head 8",
          "Layer 14, Head 4",
          "Layer 22, Head 5",
          "Layer 12, Head 2",
          "Layer 17, Head 19",
          "Layer 20, Head 10"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          0.7
         ],
         "title": {
          "text": "Logit Diff"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Attention Head"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"9f37c2cb-9fd0-4aef-a6db-f881b024b4b6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f37c2cb-9fd0-4aef-a6db-f881b024b4b6\")) {                    Plotly.newPlot(                        \"9f37c2cb-9fd0-4aef-a6db-f881b024b4b6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Logit Diff=%{x}\\u003cbr\\u003eAttention Head=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0.027340156957507133,0.030034730210900307,0.03003832697868347,0.032926060259342194,0.03402191027998924,0.03716498613357544,0.04040347412228584,0.04814910516142845,0.06057989224791527,0.06220627576112747,0.0661335363984108,0.0984983891248703,0.12178944051265717,0.1582338958978653,0.19967390596866608],\"xaxis\":\"x\",\"y\":[\"Layer 10, Head 22\",\"Layer 22, Head 15\",\"Layer 14, Head 30\",\"Layer 21, Head 8\",\"Layer 17, Head 7\",\"Layer 11, Head 0\",\"Layer 15, Head 26\",\"Layer 17, Head 6\",\"Layer 21, Head 24\",\"Layer 13, Head 8\",\"Layer 14, Head 4\",\"Layer 22, Head 5\",\"Layer 12, Head 2\",\"Layer 17, Head 19\",\"Layer 20, Head 10\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Logit Diff\"},\"range\":[0,0.7]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Attention Head\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9f37c2cb-9fd0-4aef-a6db-f881b024b4b6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_heads(-results['z'].cuda(), top_n=15, range_x=[0, 0.7])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
